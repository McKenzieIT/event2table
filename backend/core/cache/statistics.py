#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼“å­˜ç»Ÿè®¡æ¨¡å—
============

æä¾›è¯¦ç»†çš„ç¼“å­˜ç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§

ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2026-02-20

åŠŸèƒ½:
- å‘½ä¸­ç‡ç»Ÿè®¡ï¼ˆL1/L2/æ€»ä½“ï¼‰
- æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡ï¼ˆå“åº”æ—¶é—´ã€QPSï¼‰
- ç¼“å­˜é”®è®¿é—®é¢‘ç‡ç»Ÿè®¡
- ç»Ÿè®¡å†å²è®°å½•
- çƒ­ç‚¹ç¼“å­˜é”®åˆ†æ
"""

from collections import defaultdict
from datetime import datetime, timedelta
from typing import Any, Dict, List
import threading
import logging

from backend.core.cache.cache_system import hierarchical_cache, get_redis_client

logger = logging.getLogger(__name__)


class CacheStatistics:
    """
    ç¼“å­˜ç»Ÿè®¡æ¨¡å—
    
    æä¾›è¯¦ç»†çš„ç¼“å­˜ç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§:
    1. å‘½ä¸­ç‡ç»Ÿè®¡ - L1/L2/æ€»ä½“å‘½ä¸­ç‡
    2. æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡ - å“åº”æ—¶é—´ã€QPS
    3. ç¼“å­˜é”®è®¿é—®é¢‘ç‡ç»Ÿè®¡ - çƒ­ç‚¹é”®åˆ†æ
    4. ç»Ÿè®¡å†å²è®°å½• - æ€§èƒ½è¶‹åŠ¿åˆ†æ
    """
    
    def __init__(self, history_size: int = 1000):
        """
        åˆå§‹åŒ–ç¼“å­˜ç»Ÿè®¡æ¨¡å—
        
        Args:
            history_size: å†å²è®°å½•å¤§å°
        """
        self.history_size = history_size
        
        # è®¿é—®é¢‘ç‡ç»Ÿè®¡
        self.access_counts: Dict[str, int] = defaultdict(int)
        self._access_lock = threading.Lock()
        
        # æ€§èƒ½å†å²è®°å½•
        self.performance_history: List[Dict] = []
        self._history_lock = threading.Lock()
        
        # å“åº”æ—¶é—´ç»Ÿè®¡
        self.response_times: Dict[str, List[float]] = {
            "l1": [],
            "l2": [],
            "miss": [],
        }
        self._response_lock = threading.Lock()
        
        # ç»Ÿè®¡å¿«ç…§ï¼ˆç”¨äºè®¡ç®—å¢é‡ï¼‰
        self.last_snapshot = None
        
        logger.info("âœ… ç¼“å­˜ç»Ÿè®¡æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
    
    # ========================================================================
    # è®¿é—®è®°å½•
    # ========================================================================
    
    def record_access(
        self,
        key: str,
        hit: bool,
        level: str,
        response_time: float
    ):
        """
        è®°å½•ç¼“å­˜è®¿é—®
        
        Args:
            key: ç¼“å­˜é”®
            hit: æ˜¯å¦å‘½ä¸­
            level: ç¼“å­˜å±‚çº§ï¼ˆl1/l2/missï¼‰
            response_time: å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        """
        # è®°å½•è®¿é—®é¢‘ç‡
        with self._access_lock:
            self.access_counts[key] += 1
        
        # è®°å½•å“åº”æ—¶é—´
        with self._response_lock:
            if level in self.response_times:
                self.response_times[level].append(response_time)
                # ä¿ç•™æœ€è¿‘1000æ¡è®°å½•
                if len(self.response_times[level]) > 1000:
                    self.response_times[level] = self.response_times[level][-1000:]
    
    def record_performance_snapshot(self):
        """è®°å½•æ€§èƒ½å¿«ç…§"""
        try:
            # è·å–å½“å‰ç»Ÿè®¡
            cache_stats = hierarchical_cache.get_stats()
            
            # è·å–Redisç»Ÿè®¡
            redis_client = get_redis_client()
            redis_stats = {}
            if redis_client:
                try:
                    info = redis_client.info()
                    redis_stats = {
                        "keyspace_hits": info.get("keyspace_hits", 0),
                        "keyspace_misses": info.get("keyspace_misses", 0),
                        "used_memory": info.get("used_memory", 0),
                        "connected_clients": info.get("connected_clients", 0),
                        "instantaneous_ops_per_sec": info.get("instantaneous_ops_per_sec", 0),
                    }
                except Exception:
                    pass
            
            # åˆ›å»ºå¿«ç…§
            snapshot = {
                "timestamp": datetime.now().isoformat(),
                "l1_stats": {
                    "size": cache_stats["l1_size"],
                    "hits": cache_stats["l1_hits"],
                    "evictions": cache_stats["l1_evictions"],
                },
                "l2_stats": redis_stats,
                "overall_stats": {
                    "total_requests": cache_stats["total_requests"],
                    "hit_rate": cache_stats["hit_rate"],
                    "l1_hits": cache_stats["l1_hits"],
                    "l2_hits": cache_stats["l2_hits"],
                    "misses": cache_stats["misses"],
                },
            }
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            with self._history_lock:
                self.performance_history.append(snapshot)
                # ä¿ç•™æœ€è¿‘çš„å†å²è®°å½•
                if len(self.performance_history) > self.history_size:
                    self.performance_history = self.performance_history[-self.history_size:]
            
        except Exception as e:
            logger.error(f"è®°å½•æ€§èƒ½å¿«ç…§å¤±è´¥: {e}")
    
    # ========================================================================
    # ç»Ÿè®¡æŸ¥è¯¢
    # ========================================================================
    
    def get_hit_rate_stats(self) -> Dict:
        """
        è·å–å‘½ä¸­ç‡ç»Ÿè®¡
        
        Returns:
            å‘½ä¸­ç‡ç»Ÿè®¡å­—å…¸
        """
        try:
            cache_stats = hierarchical_cache.get_stats()
            
            total_requests = cache_stats["total_requests"]
            if total_requests == 0:
                return {
                    "l1_hit_rate": "0.00%",
                    "l2_hit_rate": "0.00%",
                    "overall_hit_rate": "0.00%",
                    "miss_rate": "0.00%",
                }
            
            l1_hit_rate = cache_stats["l1_hits"] / total_requests * 100
            l2_hit_rate = cache_stats["l2_hits"] / total_requests * 100
            overall_hit_rate = (cache_stats["l1_hits"] + cache_stats["l2_hits"]) / total_requests * 100
            miss_rate = cache_stats["misses"] / total_requests * 100
            
            return {
                "l1_hit_rate": f"{l1_hit_rate:.2f}%",
                "l2_hit_rate": f"{l2_hit_rate:.2f}%",
                "overall_hit_rate": f"{overall_hit_rate:.2f}%",
                "miss_rate": f"{miss_rate:.2f}%",
                "l1_hits": cache_stats["l1_hits"],
                "l2_hits": cache_stats["l2_hits"],
                "misses": cache_stats["misses"],
                "total_requests": total_requests,
            }
        
        except Exception as e:
            logger.error(f"è·å–å‘½ä¸­ç‡ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    def get_performance_stats(self) -> Dict:
        """
        è·å–æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡
        
        Returns:
            æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        try:
            # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
            avg_response_times = {}
            
            with self._response_lock:
                for level, times in self.response_times.items():
                    if times:
                        avg_time = sum(times) / len(times)
                        avg_response_times[f"{level}_avg_ms"] = round(avg_time, 3)
                    else:
                        avg_response_times[f"{level}_avg_ms"] = 0.0
            
            # è·å–Redisæ€§èƒ½æŒ‡æ ‡
            redis_client = get_redis_client()
            redis_perf = {}
            if redis_client:
                try:
                    info = redis_client.info()
                    redis_perf = {
                        "ops_per_sec": info.get("instantaneous_ops_per_sec", 0),
                        "used_memory_mb": info.get("used_memory", 0) / 1024 / 1024,
                        "connected_clients": info.get("connected_clients", 0),
                    }
                except Exception:
                    pass
            
            return {
                "response_times": avg_response_times,
                "redis_performance": redis_perf,
                "timestamp": datetime.now().isoformat(),
            }
        
        except Exception as e:
            logger.error(f"è·å–æ€§èƒ½ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    def get_hot_keys(self, limit: int = 10) -> List[Dict]:
        """
        è·å–çƒ­ç‚¹ç¼“å­˜é”®
        
        Args:
            limit: è¿”å›çš„é”®æ•°é‡
        
        Returns:
            çƒ­ç‚¹é”®åˆ—è¡¨
        """
        try:
            with self._access_lock:
                # æŒ‰è®¿é—®æ¬¡æ•°æ’åº
                sorted_keys = sorted(
                    self.access_counts.items(),
                    key=lambda x: x[1],
                    reverse=True
                )
                
                # è¿”å›Top N
                hot_keys = []
                for key, count in sorted_keys[:limit]:
                    hot_keys.append({
                        "key": key,
                        "access_count": count,
                    })
                
                return hot_keys
        
        except Exception as e:
            logger.error(f"è·å–çƒ­ç‚¹é”®å¤±è´¥: {e}")
            return []
    
    def get_performance_trend(self, hours: int = 24) -> Dict:
        """
        è·å–æ€§èƒ½è¶‹åŠ¿
        
        Args:
            hours: æŸ¥è¯¢çš„å°æ—¶æ•°
        
        Returns:
            æ€§èƒ½è¶‹åŠ¿å­—å…¸
        """
        try:
            cutoff_time = datetime.now() - timedelta(hours=hours)
            
            with self._history_lock:
                # è¿‡æ»¤æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„å¿«ç…§
                recent_snapshots = [
                    s for s in self.performance_history
                    if datetime.fromisoformat(s["timestamp"]) >= cutoff_time
                ]
            
            if not recent_snapshots:
                return {
                    "message": f"æœ€è¿‘{hours}å°æ—¶æ— æ€§èƒ½æ•°æ®",
                    "snapshots": [],
                }
            
            # æå–è¶‹åŠ¿æ•°æ®
            trend_data: Dict[str, List[Any]] = {
                "timestamps": [],
                "hit_rates": [],
                "l1_sizes": [],
                "ops_per_sec": [],
            }
            
            for snapshot in recent_snapshots:
                trend_data["timestamps"].append(snapshot["timestamp"])
                trend_data["hit_rates"].append(snapshot["overall_stats"]["hit_rate"])
                trend_data["l1_sizes"].append(snapshot["l1_stats"]["size"])
                
                if "instantaneous_ops_per_sec" in snapshot.get("l2_stats", {}):
                    trend_data["ops_per_sec"].append(snapshot["l2_stats"]["instantaneous_ops_per_sec"])
            
            return {
                "period_hours": hours,
                "snapshot_count": len(recent_snapshots),
                "trend": trend_data,
                "latest": recent_snapshots[-1] if recent_snapshots else None,
            }
        
        except Exception as e:
            logger.error(f"è·å–æ€§èƒ½è¶‹åŠ¿å¤±è´¥: {e}")
            return {}
    
    def get_detailed_stats(self) -> Dict:
        """
        è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            è¯¦ç»†ç»Ÿè®¡å­—å…¸
        """
        try:
            return {
                "timestamp": datetime.now().isoformat(),
                "hit_rate_stats": self.get_hit_rate_stats(),
                "performance_stats": self.get_performance_stats(),
                "hot_keys": self.get_hot_keys(limit=20),
                "access_key_count": len(self.access_counts),
                "history_size": len(self.performance_history),
            }
        
        except Exception as e:
            logger.error(f"è·å–è¯¦ç»†ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    # ========================================================================
    # ç»Ÿè®¡ç®¡ç†
    # ========================================================================
    
    def reset_stats(self):
        """é‡ç½®æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # é‡ç½®è®¿é—®é¢‘ç‡
            with self._access_lock:
                self.access_counts.clear()
            
            # é‡ç½®å“åº”æ—¶é—´
            with self._response_lock:
                for level in self.response_times:
                    self.response_times[level].clear()
            
            # é‡ç½®å†å²è®°å½•
            with self._history_lock:
                self.performance_history.clear()
            
            # é‡ç½®ç¼“å­˜ç»Ÿè®¡
            hierarchical_cache.reset_stats()
            
            logger.info("ğŸ“Š ç¼“å­˜ç»Ÿè®¡å·²é‡ç½®")
        
        except Exception as e:
            logger.error(f"é‡ç½®ç»Ÿè®¡å¤±è´¥: {e}")
    
    def cleanup_old_records(self, max_age_hours: int = 24):
        """
        æ¸…ç†æ—§è®°å½•
        
        Args:
            max_age_hours: æœ€å¤§ä¿ç•™æ—¶é—´ï¼ˆå°æ—¶ï¼‰
        """
        try:
            cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
            
            with self._history_lock:
                # è¿‡æ»¤æ‰æ—§è®°å½•
                self.performance_history = [
                    s for s in self.performance_history
                    if datetime.fromisoformat(s["timestamp"]) >= cutoff_time
                ]
            
            logger.info(f"æ¸…ç†æ—§è®°å½•: ä¿ç•™æœ€è¿‘{max_age_hours}å°æ—¶")
        
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§è®°å½•å¤±è´¥: {e}")


# å…¨å±€ç¼“å­˜ç»Ÿè®¡å®ä¾‹
cache_statistics = CacheStatistics()


logger.info("âœ… ç¼“å­˜ç»Ÿè®¡æ¨¡å—å·²åŠ è½½ (1.0.0)")
