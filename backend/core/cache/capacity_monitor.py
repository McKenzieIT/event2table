#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼“å­˜å®¹é‡ç›‘æ§ç³»ç»Ÿ
================

ç›‘æ§L1å’ŒL2ç¼“å­˜å®¹é‡ä½¿ç”¨æƒ…å†µï¼Œæä¾›å‘Šè­¦å’Œè‡ªåŠ¨æ‰©å®¹åŠŸèƒ½ã€‚

æ ¸å¿ƒåŠŸèƒ½:
- L1å®¹é‡ç›‘æ§ï¼ˆ85%è­¦å‘Šï¼Œ95%ä¸¥é‡ï¼‰
- L2 Rediså®¹é‡ç›‘æ§ï¼ˆ80%è­¦å‘Šï¼Œ90%ä¸¥é‡ï¼‰
- L1è‡ªåŠ¨æ‰©å®¹ï¼ˆ95%æ—¶æ‰©å®¹50%ï¼‰
- å®¹é‡è¶‹åŠ¿é¢„æµ‹ï¼ˆçº¿æ€§å›å½’ï¼‰
- PrometheusæŒ‡æ ‡å¯¼å‡º

ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2026-02-24
"""

import logging
import threading
import time
from collections import deque
from datetime import datetime
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


class CapacityTrendPredictor:
    """å®¹é‡è¶‹åŠ¿é¢„æµ‹å™¨ï¼ˆçº¿æ€§å›å½’ï¼‰"""

    def __init__(self, window_size: int = 1440):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨

        Args:
            window_size: å†å²æ•°æ®çª—å£å¤§å°ï¼ˆé»˜è®¤1440 = 24å°æ—¶ Ã— 60åˆ†é’Ÿï¼‰
        """
        self.window_size = window_size
        self.l1_history: deque = deque(maxlen=window_size)
        self.l2_history: deque = deque(maxlen=window_size)

    def add_sample(self, l1_usage: float, l2_usage: float, timestamp: Optional[float] = None):
        """
        æ·»åŠ å®¹é‡æ ·æœ¬

        Args:
            l1_usage: L1ä½¿ç”¨ç‡ï¼ˆ0.0-1.0ï¼‰
            l2_usage: L2ä½¿ç”¨ç‡ï¼ˆ0.0-1.0ï¼‰
            timestamp: æ—¶é—´æˆ³ï¼ˆé»˜è®¤å½“å‰æ—¶é—´ï¼‰
        """
        if timestamp is None:
            timestamp = time.time()

        self.l1_history.append((timestamp, l1_usage))
        self.l2_history.append((timestamp, l2_usage))

    def predict_exhaustion(self, history: deque, threshold: float = 0.95) -> Optional[float]:
        """
        é¢„æµ‹ä½•æ—¶è¾¾åˆ°å®¹é‡ä¸Šé™

        ä½¿ç”¨çº¿æ€§å›å½’é¢„æµ‹å®¹é‡ä½¿ç”¨è¶‹åŠ¿

        Args:
            history: å†å²æ•°æ® [(timestamp, usage), ...]
            threshold: å®¹é‡ä¸Šé™é˜ˆå€¼ï¼ˆé»˜è®¤95%ï¼‰

        Returns:
            é¢„æµ‹çš„è€—å°½æ—¶é—´æˆ³ï¼Œå¦‚æœæ— æ³•é¢„æµ‹åˆ™è¿”å›None
        """
        if len(history) < 10:
            # æ•°æ®ä¸è¶³ï¼Œæ— æ³•é¢„æµ‹
            return None

        try:
            # æå–æ—¶é—´å’Œä½¿ç”¨ç‡
            # ä½¿ç”¨ç›¸å¯¹æ—¶é—´ï¼ˆç§’ï¼‰è€Œä¸æ˜¯ç»å¯¹æ—¶é—´æˆ³ï¼Œé¿å…æ•°å€¼ä¸ç¨³å®š
            base_timestamp = history[0][0]
            timestamps = [(t - base_timestamp) / 3600 for t, _ in history]  # è½¬æ¢ä¸ºå°æ—¶
            usages = [u for _, u in history]

            # çº¿æ€§å›å½’ï¼šy = ax + b
            # x = ç›¸å¯¹æ—¶é—´ï¼ˆå°æ—¶ï¼‰, y = usage
            n = len(timestamps)

            sum_x = sum(timestamps)
            sum_y = sum(usages)
            sum_xy = sum(t * u for t, u in zip(timestamps, usages))
            sum_x2 = sum(t ** 2 for t in timestamps)

            # è®¡ç®—æ–œç‡å’Œæˆªè·
            denominator = n * sum_x2 - sum_x ** 2
            if denominator == 0:
                return None

            slope = (n * sum_xy - sum_x * sum_y) / denominator
            intercept = (sum_y - slope * sum_x) / n

            # å¦‚æœæ–œç‡<=0ï¼Œè¡¨ç¤ºå®¹é‡ä¸ä¼šå¢é•¿
            if slope <= 1e-10:  # ä½¿ç”¨å°çš„æ­£æ•°é˜ˆå€¼è€Œä¸æ˜¯0
                return None

            # è®¡ç®—ä½•æ—¶è¾¾åˆ°threshold
            # threshold = slope * x + intercept
            # x = (threshold - intercept) / slope
            hours_until_exhaustion = (threshold - intercept) / slope

            if hours_until_exhaustion > 0:
                # è½¬æ¢å›ç»å¯¹æ—¶é—´æˆ³ï¼ˆä»base_timestampå¼€å§‹è®¡ç®—ï¼‰
                exhaustion_time: float = base_timestamp + hours_until_exhaustion * 3600
                return exhaustion_time

        except Exception as e:
            logger.warning(f"å®¹é‡é¢„æµ‹å¤±è´¥: {e}")

        return None

    def predict_l1_exhaustion(self, threshold: float = 0.95) -> Optional[datetime]:
        """
        é¢„æµ‹L1ç¼“å­˜ä½•æ—¶è€—å°½

        Args:
            threshold: å®¹é‡ä¸Šé™é˜ˆå€¼ï¼ˆé»˜è®¤95%ï¼‰

        Returns:
            é¢„æµ‹çš„è€—å°½æ—¶é—´ï¼Œå¦‚æœæ— æ³•é¢„æµ‹åˆ™è¿”å›None
        """
        exhaustion_ts = self.predict_exhaustion(self.l1_history, threshold)
        if exhaustion_ts:
            return datetime.fromtimestamp(exhaustion_ts)
        return None

    def predict_l2_exhaustion(self, threshold: float = 0.90) -> Optional[datetime]:
        """
        é¢„æµ‹L2ç¼“å­˜ä½•æ—¶è€—å°½

        Args:
            threshold: å®¹é‡ä¸Šé™é˜ˆå€¼ï¼ˆé»˜è®¤90%ï¼‰

        Returns:
            é¢„æµ‹çš„è€—å°½æ—¶é—´ï¼Œå¦‚æœæ— æ³•é¢„æµ‹åˆ™è¿”å›None
        """
        exhaustion_ts = self.predict_exhaustion(self.l2_history, threshold)
        if exhaustion_ts:
            return datetime.fromtimestamp(exhaustion_ts)
        return None

    def get_trend_stats(self) -> Dict[str, Any]:
        """
        è·å–è¶‹åŠ¿ç»Ÿè®¡ä¿¡æ¯

        Returns:
            è¶‹åŠ¿ç»Ÿè®¡å­—å…¸
        """
        stats: Dict[str, Any] = {
            "l1_samples": len(self.l1_history),
            "l2_samples": len(self.l2_history),
            "l1_exhaustion_prediction": None,
            "l2_exhaustion_prediction": None,
            "days_until_exhaustion_l1": None,
            "days_until_exhaustion_l2": None,
        }

        # L1é¢„æµ‹
        l1_exhaustion = self.predict_l1_exhaustion(0.95)
        if l1_exhaustion:
            stats["l1_exhaustion_prediction"] = l1_exhaustion.isoformat()
            l1_days_remaining: float = (l1_exhaustion - datetime.now()).total_seconds() / 86400
            stats["days_until_exhaustion_l1"] = round(l1_days_remaining, 2)

        # L2é¢„æµ‹
        l2_exhaustion = self.predict_l2_exhaustion(0.90)
        if l2_exhaustion:
            stats["l2_exhaustion_prediction"] = l2_exhaustion.isoformat()
            l2_days_remaining: float = (l2_exhaustion - datetime.now()).total_seconds() / 86400
            stats["days_until_exhaustion_l2"] = round(l2_days_remaining, 2)

        return stats


class CacheCapacityMonitor:
    """ç¼“å­˜å®¹é‡ç›‘æ§å™¨"""

    def __init__(
        self,
        hierarchical_cache,
        l1_warning_threshold: float = 0.85,
        l1_critical_threshold: float = 0.95,
        l2_warning_threshold: float = 0.80,
        l2_critical_threshold: float = 0.90,
        monitoring_interval: int = 60,
        alert_days_advance: int = 7,
    ):
        """
        åˆå§‹åŒ–å®¹é‡ç›‘æ§å™¨

        Args:
            hierarchical_cache: åˆ†å±‚ç¼“å­˜å®ä¾‹
            l1_warning_threshold: L1è­¦å‘Šé˜ˆå€¼ï¼ˆé»˜è®¤85%ï¼‰
            l1_critical_threshold: L1ä¸¥é‡é˜ˆå€¼ï¼ˆé»˜è®¤95%ï¼‰
            l2_warning_threshold: L2è­¦å‘Šé˜ˆå€¼ï¼ˆé»˜è®¤80%ï¼‰
            l2_critical_threshold: L2ä¸¥é‡é˜ˆå€¼ï¼ˆé»˜è®¤90%ï¼‰
            monitoring_interval: ç›‘æ§é—´éš”ï¼ˆç§’ï¼Œé»˜è®¤60ï¼‰
            alert_days_advance: æå‰å‘Šè­¦å¤©æ•°ï¼ˆé»˜è®¤7å¤©ï¼‰
        """
        self.cache = hierarchical_cache
        self.l1_warning_threshold = l1_warning_threshold
        self.l1_critical_threshold = l1_critical_threshold
        self.l2_warning_threshold = l2_warning_threshold
        self.l2_critical_threshold = l2_critical_threshold
        self.monitoring_interval = monitoring_interval
        self.alert_days_advance = alert_days_advance

        # è¶‹åŠ¿é¢„æµ‹å™¨
        self.predictor = CapacityTrendPredictor()

        # PrometheusæŒ‡æ ‡
        self.prometheus_metrics: Dict[str, Dict[str, Any]] = {
            "cache_capacity_bytes": {},  # {level: capacity}
            "cache_usage_bytes": {},  # {level: usage}
            "cache_usage_ratio": {},  # {level: ratio}
            "cache_capacity_prediction_days": {},  # {level: days}
        }

        # ç›‘æ§çº¿ç¨‹
        self._monitoring_thread: Optional[threading.Thread] = None
        self._stop_event = threading.Event()
        self._lock = threading.Lock()

        # å‘Šè­¦çŠ¶æ€ï¼ˆé˜²æ­¢é‡å¤å‘Šè­¦ï¼‰
        self._alert_state = {
            "l1_warning_sent": False,
            "l1_critical_sent": False,
            "l2_warning_sent": False,
            "l2_critical_sent": False,
            "prediction_alert_sent": False,
        }

        logger.info(
            f"âœ… å®¹é‡ç›‘æ§å™¨åˆå§‹åŒ–: "
            f"L1é˜ˆå€¼={l1_warning_threshold:.0%}/{l1_critical_threshold:.0%}, "
            f"L2é˜ˆå€¼={l2_warning_threshold:.0%}/{l2_critical_threshold:.0%}, "
            f"ç›‘æ§é—´éš”={monitoring_interval}s"
        )

    def get_l1_usage(self) -> float:
        """
        è·å–L1ç¼“å­˜ä½¿ç”¨ç‡

        Returns:
            ä½¿ç”¨ç‡ï¼ˆ0.0-1.0ï¼‰
        """
        with self.cache._lock:
            if self.cache.l1_size == 0:
                return 0.0
            l1_size: int = self.cache.l1_size
            return float(len(self.cache.l1_cache)) / float(l1_size)

    def get_l2_usage(self) -> float:
        """
        è·å–L2 Redisç¼“å­˜ä½¿ç”¨ç‡

        Returns:
            ä½¿ç”¨ç‡ï¼ˆ0.0-1.0ï¼‰
        """
        try:
            redis_client = self.cache._get_redis_client()
            if redis_client is None:
                return 0.0

            # è·å–Rediså†…å­˜ä¿¡æ¯
            info = redis_client.info("memory")
            maxmemory = info.get("maxmemory", 0)
            used_memory = info.get("used_memory", 0)

            if maxmemory == 0:
                # Redisæœªè®¾ç½®maxmemoryï¼Œæ£€æŸ¥used_memory_rss
                used_memory_rss = info.get("used_memory_rss", 0)
                # å‡è®¾ç³»ç»Ÿå†…å­˜é™åˆ¶ä¸º2GB
                maxmemory = 2 * 1024 * 1024 * 1024  # 2GB

            used_memory_float: float = float(used_memory)
            maxmemory_float: float = float(maxmemory)
            return used_memory_float / maxmemory_float if maxmemory_float > 0 else 0.0

        except Exception as e:
            logger.warning(f"è·å–L2å®¹é‡å¤±è´¥: {e}")
            return 0.0

    def get_redis_memory_stats(self) -> Dict:
        """
        è·å–Rediså†…å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            å†…å­˜ç»Ÿè®¡å­—å…¸
        """
        try:
            redis_client = self.cache._get_redis_client()
            if redis_client is None:
                return {}

            info = redis_client.info("memory")

            return {
                "used_memory": info.get("used_memory", 0),
                "used_memory_rss": info.get("used_memory_rss", 0),
                "used_memory_peak": info.get("used_memory_peak", 0),
                "maxmemory": info.get("maxmemory", 0),
                "maxmemory_policy": info.get("maxmemory_policy", "noeviction"),
                "mem_fragmentation_ratio": info.get("mem_fragmentation_ratio", 0.0),
                "used_memory_percentage": self._calculate_memory_percentage(info),
            }

        except Exception as e:
            logger.warning(f"è·å–Rediså†…å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {}

    def _calculate_memory_percentage(self, info: Dict) -> float:
        """
        è®¡ç®—å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”

        Args:
            info: Redis INFO memoryè¾“å‡º

        Returns:
            å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”
        """
        maxmemory: int = int(info.get("maxmemory", 0))
        used_memory: int = int(info.get("used_memory", 0))

        if maxmemory == 0:
            # Redisæœªè®¾ç½®maxmemory
            return 0.0

        return (float(used_memory) / float(maxmemory) * 100) if maxmemory > 0 else 0.0

    def monitor_l1_capacity(self) -> Optional[str]:
        """
        ç›‘æ§L1ç¼“å­˜å®¹é‡

        Returns:
            å‘Šè­¦çº§åˆ«ï¼ˆ"WARNING", "CRITICAL" æˆ– Noneï¼‰
        """
        usage = self.get_l1_usage()

        # æ›´æ–°PrometheusæŒ‡æ ‡
        self.prometheus_metrics["cache_capacity_bytes"]["l1"] = self.cache.l1_size
        self.prometheus_metrics["cache_usage_bytes"]["l1"] = len(self.cache.l1_cache)
        self.prometheus_metrics["cache_usage_ratio"]["l1"] = usage

        # æ£€æŸ¥ä¸¥é‡é˜ˆå€¼
        if usage >= self.l1_critical_threshold:
            if not self._alert_state["l1_critical_sent"]:
                logger.critical(
                    f"ğŸš¨ L1å®¹é‡ä¸¥é‡å‘Šè­¦: {usage:.1%} >= {self.l1_critical_threshold:.1%}"
                )
                self._alert_state["l1_critical_sent"] = True

                # è‡ªåŠ¨æ‰©å®¹L1
                self._auto_expand_l1()

            return "CRITICAL"

        # æ£€æŸ¥è­¦å‘Šé˜ˆå€¼
        elif usage >= self.l1_warning_threshold:
            if not self._alert_state["l1_warning_sent"]:
                logger.warning(
                    f"âš ï¸ L1å®¹é‡è­¦å‘Š: {usage:.1%} >= {self.l1_warning_threshold:.1%}"
                )
                self._alert_state["l1_warning_sent"] = True
            return "WARNING"

        # é‡ç½®å‘Šè­¦çŠ¶æ€
        else:
            self._alert_state["l1_warning_sent"] = False
            self._alert_state["l1_critical_sent"] = False
            return None

    def monitor_l2_capacity(self) -> Optional[str]:
        """
        ç›‘æ§L2 Redisç¼“å­˜å®¹é‡

        Returns:
            å‘Šè­¦çº§åˆ«ï¼ˆ"WARNING", "CRITICAL" æˆ– Noneï¼‰
        """
        usage = self.get_l2_usage()

        # æ›´æ–°PrometheusæŒ‡æ ‡
        redis_stats = self.get_redis_memory_stats()
        if redis_stats:
            self.prometheus_metrics["cache_capacity_bytes"]["l2"] = redis_stats.get(
                "maxmemory", 0
            )
            self.prometheus_metrics["cache_usage_bytes"]["l2"] = redis_stats.get(
                "used_memory", 0
            )
            self.prometheus_metrics["cache_usage_ratio"]["l2"] = usage

        # æ£€æŸ¥ä¸¥é‡é˜ˆå€¼
        if usage >= self.l2_critical_threshold:
            if not self._alert_state["l2_critical_sent"]:
                logger.critical(
                    f"ğŸš¨ L2å®¹é‡ä¸¥é‡å‘Šè­¦: {usage:.1%} >= {self.l2_critical_threshold:.1%}"
                )
                self._alert_state["l2_critical_sent"] = True
            return "CRITICAL"

        # æ£€æŸ¥è­¦å‘Šé˜ˆå€¼
        elif usage >= self.l2_warning_threshold:
            if not self._alert_state["l2_warning_sent"]:
                logger.warning(
                    f"âš ï¸ L2å®¹é‡è­¦å‘Š: {usage:.1%} >= {self.l2_warning_threshold:.1%}"
                )
                self._alert_state["l2_warning_sent"] = True
            return "WARNING"

        # é‡ç½®å‘Šè­¦çŠ¶æ€
        else:
            self._alert_state["l2_warning_sent"] = False
            self._alert_state["l2_critical_sent"] = False
            return None

    def _auto_expand_l1(self):
        """
        è‡ªåŠ¨æ‰©å®¹L1ç¼“å­˜

        æ‰©å®¹ç­–ç•¥: å¢åŠ 50%å®¹é‡
        """
        with self.cache._lock:
            old_size = self.cache.l1_size
            new_size = int(old_size * 1.5)

            self.cache.l1_size = new_size

            logger.info(
                f"ğŸ“ˆ L1ç¼“å­˜è‡ªåŠ¨æ‰©å®¹: {old_size} â†’ {new_size} (+{new_size - old_size}, +50%)"
            )

    def check_capacity_predictions(self) -> List[Dict]:
        """
        æ£€æŸ¥å®¹é‡é¢„æµ‹å‘Šè­¦

        Returns:
            å‘Šè­¦åˆ—è¡¨
        """
        alerts = []

        # æ£€æŸ¥L1é¢„æµ‹
        l1_exhaustion = self.predictor.predict_l1_exhaustion(0.95)
        if l1_exhaustion:
            days_until = (l1_exhaustion - datetime.now()).total_seconds() / 86400

            # æ›´æ–°PrometheusæŒ‡æ ‡
            self.prometheus_metrics["cache_capacity_prediction_days"]["l1"] = (
                days_until
            )

            if days_until <= self.alert_days_advance:
                alert = {
                    "level": "l1",
                    "predicted_exhaustion": l1_exhaustion.isoformat(),
                    "days_until": round(days_until, 2),
                    "message": f"L1ç¼“å­˜é¢„è®¡åœ¨{days_until:.1f}å¤©åè€—å°½",
                }
                alerts.append(alert)

                if not self._alert_state["prediction_alert_sent"]:
                    logger.warning(f"ğŸ”® å®¹é‡é¢„æµ‹å‘Šè­¦: {alert['message']}")
                    self._alert_state["prediction_alert_sent"] = True

        # æ£€æŸ¥L2é¢„æµ‹
        l2_exhaustion = self.predictor.predict_l2_exhaustion(0.90)
        if l2_exhaustion:
            days_until = (l2_exhaustion - datetime.now()).total_seconds() / 86400

            # æ›´æ–°PrometheusæŒ‡æ ‡
            self.prometheus_metrics["cache_capacity_prediction_days"]["l2"] = (
                days_until
            )

            if days_until <= self.alert_days_advance:
                alert = {
                    "level": "l2",
                    "predicted_exhaustion": l2_exhaustion.isoformat(),
                    "days_until": round(days_until, 2),
                    "message": f"L2ç¼“å­˜é¢„è®¡åœ¨{days_until:.1f}å¤©åè€—å°½",
                }
                alerts.append(alert)

        return alerts

    def _monitoring_loop(self):
        """ç›‘æ§çº¿ç¨‹ä¸»å¾ªç¯"""
        logger.info("ğŸ”„ å®¹é‡ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨")

        while not self._stop_event.is_set():
            try:
                # ç›‘æ§L1å®¹é‡
                l1_alert = self.monitor_l1_capacity()

                # ç›‘æ§L2å®¹é‡
                l2_alert = self.monitor_l2_capacity()

                # æ·»åŠ æ ·æœ¬åˆ°é¢„æµ‹å™¨
                l1_usage = self.get_l1_usage()
                l2_usage = self.get_l2_usage()
                self.predictor.add_sample(l1_usage, l2_usage)

                # æ£€æŸ¥å®¹é‡é¢„æµ‹
                prediction_alerts = self.check_capacity_predictions()

                # è®°å½•ç›‘æ§çŠ¶æ€
                if l1_alert or l2_alert or prediction_alerts:
                    logger.debug(
                        f"ğŸ“Š ç›‘æ§çŠ¶æ€: L1={l1_usage:.1%}({l1_alert}), "
                        f"L2={l2_usage:.1%}({l2_alert}), "
                        f"é¢„æµ‹å‘Šè­¦={len(prediction_alerts)}"
                    )

            except Exception as e:
                logger.error(f"âŒ ç›‘æ§å¾ªç¯é”™è¯¯: {e}")

            # ç­‰å¾…ä¸‹ä¸€æ¬¡ç›‘æ§
            self._stop_event.wait(self.monitoring_interval)

        logger.info("â¹ï¸ å®¹é‡ç›‘æ§çº¿ç¨‹å·²åœæ­¢")

    def start(self):
        """å¯åŠ¨ç›‘æ§çº¿ç¨‹"""
        if self._monitoring_thread is None or not self._monitoring_thread.is_alive():
            self._stop_event.clear()
            self._monitoring_thread = threading.Thread(
                target=self._monitoring_loop,
                daemon=True,
                name="CacheCapacityMonitor",
            )
            self._monitoring_thread.start()
            logger.info("âœ… å®¹é‡ç›‘æ§å·²å¯åŠ¨")

    def stop(self):
        """åœæ­¢ç›‘æ§çº¿ç¨‹"""
        self._stop_event.set()
        if self._monitoring_thread:
            self._monitoring_thread.join(timeout=5)
            logger.info("â¹ï¸ å®¹é‡ç›‘æ§å·²åœæ­¢")

    def get_capacity_report(self) -> Dict:
        """
        è·å–å®¹é‡æŠ¥å‘Š

        Returns:
            å®¹é‡æŠ¥å‘Šå­—å…¸
        """
        l1_usage = self.get_l1_usage()
        l2_usage = self.get_l2_usage()

        report = {
            "timestamp": datetime.now().isoformat(),
            "l1": {
                "usage_ratio": f"{l1_usage:.2%}",
                "used": len(self.cache.l1_cache),
                "capacity": self.cache.l1_size,
                "alert_level": self.monitor_l1_capacity(),
            },
            "l2": {
                "usage_ratio": f"{l2_usage:.2%}",
                "redis_stats": self.get_redis_memory_stats(),
                "alert_level": self.monitor_l2_capacity(),
            },
            "predictions": self.predictor.get_trend_stats(),
            "prometheus_metrics": self.prometheus_metrics,
        }

        return report

    def get_prometheus_metrics(self) -> str:
        """
        å¯¼å‡ºPrometheusæŒ‡æ ‡

        Returns:
            Prometheusæ ¼å¼çš„æŒ‡æ ‡å­—ç¬¦ä¸²
        """
        lines = []

        # L1å®¹é‡æŒ‡æ ‡
        l1_usage = self.get_l1_usage()
        lines.append(
            f'cache_capacity_bytes{{level="l1"}} {self.cache.l1_size} {int(time.time())}'
        )
        lines.append(
            f'cache_usage_bytes{{level="l1"}} {len(self.cache.l1_cache)} {int(time.time())}'
        )
        lines.append(
            f'cache_usage_ratio{{level="l1"}} {l1_usage:.4f} {int(time.time())}'
        )

        # L2å®¹é‡æŒ‡æ ‡
        redis_stats = self.get_redis_memory_stats()
        if redis_stats:
            maxmemory = redis_stats.get("maxmemory", 0)
            used_memory = redis_stats.get("used_memory", 0)
            l2_usage = self.get_l2_usage()

            lines.append(f'cache_capacity_bytes{{level="l2"}} {maxmemory} {int(time.time())}')
            lines.append(f'cache_usage_bytes{{level="l2"}} {used_memory} {int(time.time())}')
            lines.append(f'cache_usage_ratio{{level="l2"}} {l2_usage:.4f} {int(time.time())}')

        # é¢„æµ‹æŒ‡æ ‡
        trend_stats = self.predictor.get_trend_stats()
        if trend_stats.get("days_until_exhaustion_l1"):
            lines.append(
                f'cache_capacity_prediction_days{{level="l1"}} {trend_stats["days_until_exhaustion_l1"]} {int(time.time())}'
            )
        if trend_stats.get("days_until_exhaustion_l2"):
            lines.append(
                f'cache_capacity_prediction_days{{level="l2"}} {trend_stats["days_until_exhaustion_l2"]} {int(time.time())}'
            )

        return "\n".join(lines)


# å…¨å±€å®¹é‡ç›‘æ§å™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_capacity_monitor: Optional[CacheCapacityMonitor] = None


def get_capacity_monitor() -> Optional[CacheCapacityMonitor]:
    """
    è·å–å…¨å±€å®¹é‡ç›‘æ§å™¨å®ä¾‹

    Returns:
        CacheCapacityMonitorå®ä¾‹æˆ–None
    """
    return _capacity_monitor


def init_capacity_monitor(
    hierarchical_cache,
    l1_warning_threshold: float = 0.85,
    l1_critical_threshold: float = 0.95,
    l2_warning_threshold: float = 0.80,
    l2_critical_threshold: float = 0.90,
    monitoring_interval: int = 60,
    alert_days_advance: int = 7,
    auto_start: bool = True,
) -> CacheCapacityMonitor:
    """
    åˆå§‹åŒ–å…¨å±€å®¹é‡ç›‘æ§å™¨

    Args:
        hierarchical_cache: åˆ†å±‚ç¼“å­˜å®ä¾‹
        l1_warning_threshold: L1è­¦å‘Šé˜ˆå€¼ï¼ˆé»˜è®¤85%ï¼‰
        l1_critical_threshold: L1ä¸¥é‡é˜ˆå€¼ï¼ˆé»˜è®¤95%ï¼‰
        l2_warning_threshold: L2è­¦å‘Šé˜ˆå€¼ï¼ˆé»˜è®¤80%ï¼‰
        l2_critical_threshold: L2ä¸¥é‡é˜ˆå€¼ï¼ˆé»˜è®¤90%ï¼‰
        monitoring_interval: ç›‘æ§é—´éš”ï¼ˆç§’ï¼Œé»˜è®¤60ï¼‰
        alert_days_advance: æå‰å‘Šè­¦å¤©æ•°ï¼ˆé»˜è®¤7å¤©ï¼‰
        auto_start: æ˜¯å¦è‡ªåŠ¨å¯åŠ¨ç›‘æ§ï¼ˆé»˜è®¤Trueï¼‰

    Returns:
        CacheCapacityMonitorå®ä¾‹
    """
    global _capacity_monitor

    if _capacity_monitor is None:
        _capacity_monitor = CacheCapacityMonitor(
            hierarchical_cache=hierarchical_cache,
            l1_warning_threshold=l1_warning_threshold,
            l1_critical_threshold=l1_critical_threshold,
            l2_warning_threshold=l2_warning_threshold,
            l2_critical_threshold=l2_critical_threshold,
            monitoring_interval=monitoring_interval,
            alert_days_advance=alert_days_advance,
        )

        if auto_start:
            _capacity_monitor.start()

        logger.info("âœ… å…¨å±€å®¹é‡ç›‘æ§å™¨å·²åˆå§‹åŒ–")

    return _capacity_monitor


# å…¬å¼€åˆ«åï¼Œç”¨äºæ¨¡å—å¯¼å…¥
cache_capacity_monitor = _capacity_monitor


logger.info("âœ… ç¼“å­˜å®¹é‡ç›‘æ§ç³»ç»Ÿå·²åŠ è½½ (1.0.0)")
