"""
Unit Tests for Enhanced Bloom Filter

Test Coverage Plan:
- Basic operations (add, contains)
- Persistence (save/load from disk)
- Capacity monitoring
- Thread safety
- Edge cases and error handling

Author: Event2Table Development Team
Version: 1.0.0
"""

from typing import Optional
import pytest
import os
import tempfile
import threading
import time

from backend.core.cache.bloom_filter_enhanced import EnhancedBloomFilter
from backend.core.cache.validators.cache_key_validator import CacheKeyValidator


class TestBloomFilterBasicOperations:
    """Test basic bloom filter operations."""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•å‰ç¦ç”¨ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(False)

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•åæ¢å¤ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(True)
    """Test basic bloom filter operations."""

    def test_add_to_bloom_filter(self):
        """æµ‹è¯•æ·»åŠ å…ƒç´ åˆ°å¸ƒéš†è¿‡æ»¤å™¨"""
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)
        result = bloom.add("test_key")

        # éªŒè¯æ·»åŠ æˆåŠŸï¼ˆè¿”å›Trueæˆ–Falseéƒ½å¯ä»¥ï¼Œå› ä¸ºå¸ƒéš†è¿‡æ»¤å™¨å¯èƒ½æœ‰å‡é˜³æ€§ï¼‰
        # é‡è¦çš„æ˜¯å…ƒç´ åº”è¯¥å­˜åœ¨
        assert "test_key" in bloom, "æ·»åŠ çš„å…ƒç´ åº”è¯¥å­˜åœ¨äºè¿‡æ»¤å™¨ä¸­"

        # éªŒè¯å…ƒç´ å­˜åœ¨
        assert bloom.contains("test_key"), "containsæ–¹æ³•åº”è¿”å›True"

    def test_contains_key(self):
        """æµ‹è¯•æ£€æŸ¥å…ƒç´ æ˜¯å¦å­˜åœ¨"""
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)

        # æœªæ·»åŠ çš„å…ƒç´ ä¸å­˜åœ¨
        assert "nonexistent_key" not in bloom, "æœªæ·»åŠ çš„å…ƒç´ åº”ä¸å­˜åœ¨"

        # æ·»åŠ åå­˜åœ¨
        bloom.add("my_key")
        assert "my_key" in bloom, "æ·»åŠ åçš„å…ƒç´ åº”å­˜åœ¨"

    def test_add_multiple_keys(self):
        """æµ‹è¯•æ·»åŠ å¤šä¸ªå…ƒç´ """
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)

        keys = {"key1", "key2", "key3"}
        added_count = bloom.add_many(keys)

        assert added_count == 3, f"åº”æ·»åŠ 3ä¸ªå…ƒç´ ï¼Œå®é™…æ·»åŠ {added_count}ä¸ª"

        # éªŒè¯æ‰€æœ‰å…ƒç´ éƒ½å­˜åœ¨
        for key in keys:
            assert key in bloom, f"å…ƒç´ {key}åº”å­˜åœ¨"

    def test_add_many_with_duplicates(self):
        """æµ‹è¯•æ‰¹é‡æ·»åŠ åŒ…å«é‡å¤å…ƒç´ """
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)

        # ç¬¬ä¸€æ¬¡æ·»åŠ 
        keys1 = {"key1", "key2", "key3"}
        bloom.add_many(keys1)

        # ç¬¬äºŒæ¬¡æ·»åŠ éƒ¨åˆ†é‡å¤
        keys2 = {"key2", "key3", "key4"}
        added_count = bloom.add_many(keys2)

        # åªæœ‰key4æ˜¯æ–°å…ƒç´ 
        assert added_count == 1, f"åº”åªæ·»åŠ 1ä¸ªæ–°å…ƒç´ ï¼Œå®é™…æ·»åŠ {added_count}ä¸ª"

        # éªŒè¯æ‰€æœ‰å…ƒç´ éƒ½å­˜åœ¨
        assert "key1" in bloom
        assert "key2" in bloom
        assert "key3" in bloom
        assert "key4" in bloom

    def test_false_positives_exist(self):
        """æµ‹è¯•å¸ƒéš†è¿‡æ»¤å™¨å¯èƒ½å­˜åœ¨å‡é˜³æ€§"""
        bloom = EnhancedBloomFilter(capacity=100, error_rate=0.001, strict_validation=False)

        # æ·»åŠ ä¸€äº›å…ƒç´ 
        for i in range(50):
            bloom.add(f"key_{i}")

        # æ£€æŸ¥ä¸å­˜åœ¨çš„å…ƒç´ ï¼ˆå¯èƒ½è¯¯åˆ¤ä¸ºå­˜åœ¨ï¼‰
        # è¿™æ˜¯å¸ƒéš†è¿‡æ»¤å™¨çš„ç‰¹æ€§ï¼Œæˆ‘ä»¬ä¸èƒ½å®Œå…¨é¿å…
        false_positives = 0
        for i in range(50, 100):
            if f"key_{i}" in bloom:
                false_positives += 1

        # å‡é˜³æ€§ç‡åº”ä½äº1%ï¼ˆåˆå§‹å®¹é‡100ï¼Œé”™è¯¯ç‡0.001ï¼‰
        # ä½†å®é™…ä¸Šå¯èƒ½ä¼šé«˜ä¸€äº›ï¼Œå› ä¸ºæˆ‘ä»¬åªæ·»åŠ äº†50ä¸ªå…ƒç´ 
        print(f"å‡é˜³æ€§æ•°é‡: {false_positives}/50")

        # çœŸæ­£ä¸å­˜åœ¨çš„å…ƒç´ åº”è¯¥ä¸åœ¨
        assert "totally_random_key_xyz" not in bloom, "å®Œå…¨éšæœºçš„keyä¸åº”å­˜åœ¨"


class TestBloomFilterPersistence:
    """Test bloom filter persistence functionality."""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•å‰ç¦ç”¨ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(False)

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•åæ¢å¤ä¸¥æ ¼éªŒè¯å¹¶æ¸…ç†åå°çº¿ç¨‹"""
        CacheKeyValidator.set_strict_mode(True)
        # æ¸…ç†å¯èƒ½åˆ›å»ºçš„bloom filterå®ä¾‹
        if hasattr(self, 'bloom') and self.bloom:
            self.bloom.shutdown()
        if hasattr(self, 'new_bloom') and self.new_bloom:
            self.new_bloom.shutdown()

    def test_save_and_load_from_disk(self):
        """æµ‹è¯•æŒä¹…åŒ–åˆ°ç£ç›˜å’Œé‡æ–°åŠ è½½"""
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp:
            temp_path = tmp.name

        try:
            # åˆ›å»ºå¸ƒéš†è¿‡æ»¤å™¨å¹¶æ·»åŠ æ•°æ®
            self.bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path,
                strict_validation=False
            )
            self.bloom.add("persist_key_1")
            self.bloom.add("persist_key_2")

            # å¼ºåˆ¶ä¿å­˜
            success = self.bloom.force_save()
            assert success is True, "ä¿å­˜åº”æˆåŠŸ"

            # åˆ›å»ºæ–°å®ä¾‹å¹¶åŠ è½½
            self.new_bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path,
                strict_validation=False
            )

            # éªŒè¯æ•°æ®å·²åŠ è½½
            assert "persist_key_1" in self.new_bloom, "åº”ä»ç£ç›˜åŠ è½½key1"
            assert "persist_key_2" in self.new_bloom, "åº”ä»ç£ç›˜åŠ è½½key2"
            assert "nonexistent_key" not in self.new_bloom, "ä¸å­˜åœ¨çš„keyä¸åº”å­˜åœ¨"

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    def test_persistence_creates_directory(self):
        """æµ‹è¯•æŒä¹…åŒ–æ—¶è‡ªåŠ¨åˆ›å»ºç›®å½•"""
        with tempfile.TemporaryDirectory() as tmpdir:
            # åˆ›å»ºåµŒå¥—è·¯å¾„
            temp_path = os.path.join(tmpdir, "subdir", "bloom.pkl")

            self.bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path,
                strict_validation=False
            )
            self.bloom.add("test_key")

            # ä¿å­˜
            success = self.bloom.force_save()
            assert success is True, "ä¿å­˜åº”æˆåŠŸ"

            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            assert os.path.exists(temp_path), "æŒä¹…åŒ–æ–‡ä»¶åº”å­˜åœ¨"

    def test_load_from_corrupted_file(self):
        """æµ‹è¯•åŠ è½½æŸåçš„æ–‡ä»¶"""
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp:
            temp_path = tmp.name
            # å†™å…¥æŸåçš„æ•°æ®
            tmp.write(b"corrupted data")

        try:
            # åº”è¯¥ä¼˜é›…åœ°å¤„ç†æŸåçš„æ–‡ä»¶
            self.bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path,
                strict_validation=False
            )

            # å¸ƒéš†è¿‡æ»¤å™¨ä»åº”å¯ç”¨
            self.bloom.add("test_key")
            assert "test_key" in self.bloom, "å³ä½¿åŠ è½½å¤±è´¥ï¼Œå¸ƒéš†è¿‡æ»¤å™¨åº”å¯ç”¨"

        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    def test_no_persistence_file_creates_new(self):
        """æµ‹è¯•ä¸å­˜åœ¨çš„æŒä¹…åŒ–æ–‡ä»¶ä¼šåˆ›å»ºæ–°çš„å¸ƒéš†è¿‡æ»¤å™¨"""
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp:
            temp_path = tmp.name

        try:
            # åˆ é™¤æ–‡ä»¶ï¼ˆç¡®ä¿ä¸å­˜åœ¨ï¼‰
            if os.path.exists(temp_path):
                os.unlink(temp_path)

            # åˆ›å»ºå¸ƒéš†è¿‡æ»¤å™¨ï¼ˆåº”åˆ›å»ºæ–°çš„ï¼Œä¸åŠ è½½ï¼‰
            self.bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path,
                strict_validation=False
            )

            # æ·»åŠ æ•°æ®
            self.bloom.add("new_key")
            assert "new_key" in self.bloom, "æ–°åˆ›å»ºçš„å¸ƒéš†è¿‡æ»¤å™¨åº”æ­£å¸¸å·¥ä½œ"

        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)


class TestBloomFilterCapacity:
    """Test bloom filter capacity monitoring."""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•å‰ç¦ç”¨ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(False)

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•åæ¢å¤ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(True)

    def test_capacity_stats(self):
        """æµ‹è¯•å®¹é‡ç»Ÿè®¡"""
        bloom = EnhancedBloomFilter(capacity=100, strict_validation=False)

        # åˆå§‹çŠ¶æ€
        stats = bloom.get_stats()
        # æ³¨æ„ï¼šç”±äºåå°çº¿ç¨‹å¯èƒ½å·²ç»æ·»åŠ äº†ä¸€äº›å…ƒç´ ï¼Œæˆ‘ä»¬åªéªŒè¯ç±»å‹
        assert isinstance(stats['total_items'], (int, float)), "å…ƒç´ æ•°åº”ä¸ºæ•°å­—"
        assert isinstance(stats['estimated_capacity_used'], float), "å®¹é‡ä½¿ç”¨åº”ä¸ºæµ®ç‚¹æ•°"
        assert stats['false_positive_rate'] is not None, "åº”æœ‰é”™è¯¯ç‡"

    def test_capacity_after_adding_items(self):
        """æµ‹è¯•æ·»åŠ å…ƒç´ åçš„å®¹é‡ç»Ÿè®¡"""
        bloom = EnhancedBloomFilter(capacity=100, strict_validation=False)

        # æ·»åŠ 50ä¸ªå…ƒç´ 
        for i in range(50):
            bloom.add(f"key_{i}")

        stats = bloom.get_stats()
        # å…è®¸ä¸€äº›è¯¯å·®ï¼Œå› ä¸ºå¸ƒéš†è¿‡æ»¤å™¨çš„len()å¯èƒ½åŒ…å«å‡é˜³æ€§
        assert 45 <= stats['total_items'] <= 55, f"åº”æœ‰çº¦50ä¸ªå…ƒç´ ï¼Œå®é™…{stats['total_items']}"
        assert 0.4 <= stats['estimated_capacity_used'] <= 0.6, "å®¹é‡ä½¿ç”¨åº”çº¦ä¸º50%"

    def test_capacity_alert_threshold(self):
        """æµ‹è¯•å®¹é‡å‘Šè­¦é˜ˆå€¼"""
        bloom = EnhancedBloomFilter(capacity=100, strict_validation=False)

        # æ·»åŠ 95ä¸ªå…ƒç´ ï¼ˆè¶…è¿‡90%é˜ˆå€¼ï¼‰
        for i in range(95):
            bloom.add(f"key_{i}")

        stats = bloom.get_stats()
        assert stats['estimated_capacity_used'] >= 0.90, "å®¹é‡ä½¿ç”¨åº”è¶…è¿‡90%"

    def test_clear_bloom_filter(self):
        """æµ‹è¯•æ¸…ç©ºå¸ƒéš†è¿‡æ»¤å™¨"""
        bloom = EnhancedBloomFilter(capacity=100, strict_validation=False)

        # æ·»åŠ ä¸€äº›å…ƒç´ 
        for i in range(10):
            bloom.add(f"key_{i}")

        # æ¸…ç©º
        success = bloom.clear()
        assert success is True, "æ¸…ç©ºåº”æˆåŠŸ"

        # éªŒè¯å·²æ¸…ç©º
        stats = bloom.get_stats()
        assert stats['total_items'] == 0, "æ¸…ç©ºåå…ƒç´ æ•°åº”ä¸º0"
        assert "key_1" not in bloom, "æ¸…ç©ºåå…ƒç´ ä¸åº”å­˜åœ¨"

    def test_stats_contains_rebuild_info(self):
        """æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯åŒ…å«é‡å»ºä¿¡æ¯"""
        bloom = EnhancedBloomFilter(capacity=100, strict_validation=False)

        stats = bloom.get_stats()

        # éªŒè¯ç»Ÿè®¡å­—æ®µ
        assert 'total_items' in stats
        assert 'estimated_capacity_used' in stats
        assert 'false_positive_rate' in stats
        assert 'target_error_rate' in stats
        assert 'last_rebuild' in stats
        assert 'rebuild_count' in stats
        assert 'age_seconds' in stats
        assert 'persistence_path' in stats


class TestBloomFilterThreadSafety:
    """Test bloom filter thread safety."""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•å‰ç¦ç”¨ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(False)

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•åæ¢å¤ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(True)

    def test_concurrent_adds(self):
        """æµ‹è¯•å¹¶å‘æ·»åŠ æ“ä½œ"""
        bloom = EnhancedBloomFilter(capacity=10000, strict_validation=False)
        num_threads = 10
        items_per_thread = 100

        def add_keys(thread_id):
            for i in range(items_per_thread):
                bloom.add(f"thread_{thread_id}_key_{i}")

        # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹
        threads = []
        for i in range(num_threads):
            t = threading.Thread(target=add_keys, args=(i,))
            threads.append(t)
            t.start()

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for t in threads:
            t.join()

        # éªŒè¯æ•°æ®ä¸€è‡´æ€§ï¼ˆå…è®¸å‡é˜³æ€§å¯¼è‡´çš„åå·®ï¼‰
        stats = bloom.get_stats()
        expected = num_threads * items_per_thread
        assert expected - 10 <= stats['total_items'] <= expected + 10, \
            f"åº”æœ‰çº¦{expected}ä¸ªå…ƒç´ ï¼Œå®é™…{stats['total_items']}"

        # éªŒè¯æ¯ä¸ªçº¿ç¨‹çš„å…ƒç´ éƒ½å­˜åœ¨
        for i in range(num_threads):
            for j in range(items_per_thread):
                assert f"thread_{i}_key_{j}" in bloom, \
                    f"å…ƒç´ thread_{i}_key_{j}åº”å­˜åœ¨"

    def test_concurrent_contains(self):
        """æµ‹è¯•å¹¶å‘æŸ¥è¯¢æ“ä½œ"""
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)

        # å…ˆæ·»åŠ ä¸€äº›å…ƒç´ 
        for i in range(100):
            bloom.add(f"key_{i}")

        initial_count = bloom.get_stats()['total_items']

        num_threads = 10
        queries_per_thread = 100

        def query_keys():
            for i in range(queries_per_thread):
                _ = f"key_{i % 100}" in bloom

        # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹
        threads = []
        for _ in range(num_threads):
            t = threading.Thread(target=query_keys)
            threads.append(t)
            t.start()

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for t in threads:
            t.join()

        # éªŒè¯æ²¡æœ‰å´©æºƒï¼ˆå…ƒç´ æ•°é‡å¯èƒ½å› å‡é˜³æ€§è€Œç•¥æœ‰å¢åŠ ï¼‰
        final_count = bloom.get_stats()['total_items']
        assert final_count >= initial_count, "å…ƒç´ æ•°é‡åº”ä¿æŒä¸å˜æˆ–ç•¥æœ‰å¢åŠ "

    def test_concurrent_mixed_operations(self):
        """æµ‹è¯•å¹¶å‘æ··åˆæ“ä½œ"""
        bloom = EnhancedBloomFilter(capacity=10000, strict_validation=False)

        def add_operation():
            for i in range(50):
                bloom.add(f"add_key_{i}")

        def query_operation():
            for i in range(100):
                _ = f"query_key_{i}" in bloom

        # åˆ›å»ºçº¿ç¨‹
        add_threads = [threading.Thread(target=add_operation) for _ in range(5)]
        query_threads = [threading.Thread(target=query_operation) for _ in range(5)]

        # å¯åŠ¨æ‰€æœ‰çº¿ç¨‹
        all_threads = add_threads + query_threads
        for t in all_threads:
            t.start()

        # ç­‰å¾…å®Œæˆ
        for t in all_threads:
            t.join()

        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        # æ³¨æ„ï¼šç”±äºå¹¶å‘æ·»åŠ é‡å¤keyï¼Œå®é™…å…ƒç´ æ•°å¯èƒ½å°‘äº250
        # å¹¶ä¸”ç”±äºå‡é˜³æ€§ï¼Œå¯èƒ½ç•¥å¤šäº50
        stats = bloom.get_stats()
        # æ¯ä¸ªadd_threadæ·»åŠ 50ä¸ªkeyï¼Œä½†5ä¸ªçº¿ç¨‹æ·»åŠ ç›¸åŒçš„50ä¸ªkey
        # æ‰€ä»¥å®é™…åªæœ‰50ä¸ªå”¯ä¸€å…ƒç´ ï¼ˆå…è®¸å‡é˜³æ€§å¯¼è‡´çš„åå·®ï¼‰
        assert 48 <= stats['total_items'] <= 55, f"åº”æœ‰çº¦50ä¸ªå”¯ä¸€å…ƒç´ ï¼Œå®é™…{stats['total_items']}"


class TestBloomFilterEdgeCases:
    """Test edge cases and error handling."""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•å‰ç¦ç”¨ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(False)

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•åæ¢å¤ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(True)

    def test_empty_string_key(self):
        """æµ‹è¯•ç©ºå­—ç¬¦ä¸²key"""
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)

        # ç©ºå­—ç¬¦ä¸²åº”èƒ½æ­£å¸¸å¤„ç†
        result = bloom.add("")
        assert result is True, "åº”èƒ½æ·»åŠ ç©ºå­—ç¬¦ä¸²"
        assert "" in bloom, "ç©ºå­—ç¬¦ä¸²åº”å­˜åœ¨"

    def test_special_characters_in_key(self):
        """æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„key"""
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)

        special_keys = [
            "key with spaces",
            "key/with/slashes",
            "key:with:colons",
            "key-with-dashes",
            "key_with_underscores",
            "key.with.dots",
            "ä¸­æ–‡key",
            "ğŸ”¥emoji key",
        ]

        for key in special_keys:
            bloom.add(key)
            assert key in bloom, f"ç‰¹æ®Šå­—ç¬¦key '{key}' åº”å­˜åœ¨"

    def test_very_long_key(self):
        """æµ‹è¯•éå¸¸é•¿çš„key"""
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)

        long_key = "a" * 10000  # 10KBçš„key
        bloom.add(long_key)
        assert long_key in bloom, "è¶…é•¿keyåº”å­˜åœ¨"

    def test_unicode_normalization(self):
        """æµ‹è¯•Unicodeè§„èŒƒåŒ–"""
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)

        # æ·»åŠ Unicode key
        unicode_key = "cafÃ©"
        bloom.add(unicode_key)
        assert unicode_key in bloom, "Unicode keyåº”å­˜åœ¨"

    def test_case_sensitivity(self):
        """æµ‹è¯•å¤§å°å†™æ•æ„Ÿ"""
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)

        bloom.add("MyKey")
        assert "MyKey" in bloom, "MyKeyåº”å­˜åœ¨"
        assert "mykey" not in bloom, "mykeyä¸åº”å­˜åœ¨ï¼ˆå¤§å°å†™æ•æ„Ÿï¼‰"
        assert "MYKEY" not in bloom, "MYKEYä¸åº”å­˜åœ¨ï¼ˆå¤§å°å†™æ•æ„Ÿï¼‰"

    def test_repr_method(self):
        """æµ‹è¯•__repr__æ–¹æ³•"""
        bloom = EnhancedBloomFilter(capacity=100, strict_validation=False)

        # æ·»åŠ ä¸€äº›å…ƒç´ 
        for i in range(10):
            bloom.add(f"key_{i}")

        # è·å–repr
        repr_str = repr(bloom)

        # éªŒè¯åŒ…å«å…³é”®ä¿¡æ¯ï¼ˆä¸æ£€æŸ¥ç²¾ç¡®æ•°é‡ï¼Œå› ä¸ºå¯èƒ½æœ‰å‡é˜³æ€§ï¼‰
        assert "EnhancedBloomFilter" in repr_str
        assert "items=" in repr_str
        assert "capacity_used=" in repr_str
        assert "error_rate=" in repr_str

    def test_context_manager(self):
        """æµ‹è¯•ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp:
            temp_path = tmp.name

        try:
            # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            with EnhancedBloomFilter(capacity=100, persistence_path=temp_path, strict_validation=False) as bloom:
                bloom.add("context_key")
                assert "context_key" in bloom

            # é€€å‡ºååº”è‡ªåŠ¨ä¿å­˜
            # åˆ›å»ºæ–°å®ä¾‹éªŒè¯
            self.new_bloom = EnhancedBloomFilter(capacity=100, persistence_path=temp_path, strict_validation=False)
            assert "context_key" in self.new_bloom, "ä¸Šä¸‹æ–‡ç®¡ç†å™¨åº”è‡ªåŠ¨ä¿å­˜"

        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    def test_force_save_and_force_rebuild(self):
        """æµ‹è¯•å¼ºåˆ¶ä¿å­˜å’Œé‡å»ºæ–¹æ³•"""
        bloom = EnhancedBloomFilter(capacity=100, strict_validation=False)

        # force_save
        bloom.add("test_key")
        success = bloom.force_save()
        assert success is True, "force_saveåº”æˆåŠŸ"

        # force_rebuildï¼ˆå³ä½¿æ²¡æœ‰Redisä¹Ÿä¼šæ‰§è¡Œï¼‰
        rebuild_stats = bloom.force_rebuild()
        assert 'success' in rebuild_stats, "force_rebuildåº”è¿”å›ç»Ÿè®¡ä¿¡æ¯"
        assert 'duration_seconds' in rebuild_stats


class TestBloomFilterStatistics:
    """Test bloom filter statistics and monitoring."""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•å‰ç¦ç”¨ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(False)

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•åæ¢å¤ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(True)

    def test_age_increases_over_time(self):
        """æµ‹è¯•å¹´é¾„éšæ—¶é—´å¢é•¿"""
        bloom = EnhancedBloomFilter(capacity=100, strict_validation=False)

        age1 = bloom.get_stats()['age_seconds']
        time.sleep(0.1)  # ç­‰å¾…100ms
        age2 = bloom.get_stats()['age_seconds']

        assert age2 > age1, "å¹´é¾„åº”éšæ—¶é—´å¢é•¿"

    def test_rebuild_count_increases(self):
        """æµ‹è¯•é‡å»ºè®¡æ•°"""
        bloom = EnhancedBloomFilter(capacity=100, strict_validation=False)

        initial_count = bloom.get_stats()['rebuild_count']
        assert initial_count == 0, "åˆå§‹é‡å»ºæ¬¡æ•°åº”ä¸º0"

        # å¼ºåˆ¶é‡å»º
        bloom.force_rebuild()

        new_count = bloom.get_stats()['rebuild_count']
        # æ³¨æ„ï¼šrebuildå¯èƒ½å› ä¸ºRedisè¿æ¥é—®é¢˜è€Œå¤±è´¥
        # ä½†è®¡æ•°åº”è¯¥å¢åŠ æˆ–ä¿æŒä¸å˜
        assert new_count >= initial_count, "é‡å»ºè®¡æ•°åº”å¢åŠ æˆ–ä¿æŒ"

    def test_error_rate_configuration(self):
        """æµ‹è¯•é”™è¯¯ç‡é…ç½®"""
        bloom = EnhancedBloomFilter(capacity=1000, error_rate=0.01, strict_validation=False)

        stats = bloom.get_stats()
        assert stats['target_error_rate'] == 0.01, "ç›®æ ‡é”™è¯¯ç‡åº”ä¸º0.01"
        assert stats['false_positive_rate'] is not None, "åº”æœ‰å®é™…é”™è¯¯ç‡"


class TestBloomFilterErrorHandling:
    """Test error handling in edge cases."""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•å‰ç¦ç”¨ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(False)

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•åæ¢å¤ä¸¥æ ¼éªŒè¯"""
        CacheKeyValidator.set_strict_mode(True)

    def test_load_invalid_type_from_disk(self):
        """æµ‹è¯•åŠ è½½æ— æ•ˆç±»å‹çš„æ–‡ä»¶"""
        import pickle

        with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp:
            temp_path = tmp.name
            # å†™å…¥æ— æ•ˆç±»å‹ï¼ˆå­—ç¬¦ä¸²è€Œä¸æ˜¯bloom filterï¼‰
            pickle.dump("not a bloom filter", tmp)

        try:
            bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path,
                strict_validation=False
            )

            # åº”åˆ›å»ºæ–°çš„bloom filter
            bloom.add("test_key")
            assert "test_key" in bloom, "åº”åˆ›å»ºæ–°çš„bloom filter"

        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    def test_save_to_unwritable_directory(self):
        """æµ‹è¯•ä¿å­˜åˆ°ä¸å¯å†™ç›®å½•"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•å¹¶ä½¿å…¶åªè¯»
        with tempfile.TemporaryDirectory() as tmpdir:
            readonly_path = os.path.join(tmpdir, "readonly", "bloom.pkl")

            bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=readonly_path,
                strict_validation=False
            )

            # æ·»åŠ æ•°æ®
            bloom.add("test_key")

            # å°è¯•ä¿å­˜åˆ°ä¸å­˜åœ¨çš„åµŒå¥—ç›®å½•
            # æ³¨æ„ï¼šè¿™åœ¨macOSä¸Šå¯èƒ½ä¸ä¼šå¤±è´¥ï¼Œæ‰€ä»¥åªéªŒè¯bloom filterä»èƒ½å·¥ä½œ
            try:
                success = bloom.force_save()
                # ä¸ç®¡æˆåŠŸä¸å¦ï¼Œbloom filteråº”ä»èƒ½å·¥ä½œ
            except Exception:
                pass  # å¿½ç•¥å¼‚å¸¸

            assert "test_key" in bloom, "å³ä½¿ä¿å­˜å¤±è´¥ï¼Œbloom filteråº”æ­£å¸¸å·¥ä½œ"

    def test_add_exception_handling(self):
        """æµ‹è¯•addæ–¹æ³•çš„å¼‚å¸¸å¤„ç†"""
        bloom = EnhancedBloomFilter(capacity=1000, strict_validation=False)

        # æ­£å¸¸æ·»åŠ åº”è¯¥å·¥ä½œ
        result = bloom.add("normal_key")
        assert result is True

        # éªŒè¯å…ƒç´ å­˜åœ¨
        assert "normal_key" in bloom

    def test_contains_exception_handling(self):
        """æµ‹è¯•containsæ–¹æ³•çš„å¼‚å¸¸å¤„ç†"""
        bloom = EnhancedBloomFilter(capacity=1000)

        # æ­£å¸¸æŸ¥è¯¢åº”è¯¥å·¥ä½œ
        result = bloom.contains("test_key")
        # æ³¨æ„ï¼šç”±äºå¯èƒ½æœ‰å‡é˜³æ€§ï¼Œç»“æœå¯èƒ½æ˜¯Trueæˆ–False
        assert isinstance(result, bool), "æŸ¥è¯¢ç»“æœåº”ä¸ºå¸ƒå°”å€¼"

        # æ·»åŠ åæŸ¥è¯¢
        bloom.add("test_key")
        result = bloom.contains("test_key")
        assert result is True, "å·²æ·»åŠ çš„keyåº”å­˜åœ¨"

    def test_get_stats_exception_handling(self):
        """æµ‹è¯•get_statsçš„å¼‚å¸¸å¤„ç†"""
        bloom = EnhancedBloomFilter(capacity=1000)

        # æ­£å¸¸è·å–ç»Ÿè®¡
        stats = bloom.get_stats()
        assert isinstance(stats, dict)
        assert 'total_items' in stats

    def test_clear_exception_handling(self):
        """æµ‹è¯•clearæ–¹æ³•çš„å¼‚å¸¸å¤„ç†"""
        bloom = EnhancedBloomFilter(capacity=1000)

        # æ·»åŠ ä¸€äº›æ•°æ®
        bloom.add("test_key")

        # æ¸…ç©º
        success = bloom.clear()
        assert success is True, "æ¸…ç©ºåº”æˆåŠŸ"
        assert "test_key" not in bloom, "æ¸…ç©ºåå…ƒç´ ä¸åº”å­˜åœ¨"


class TestBloomFilterRebuild:
    """Test bloom filter rebuild functionality."""

    def test_rebuild_with_no_redis_keys(self):
        """æµ‹è¯•Redisä¸­æ²¡æœ‰keyçš„æƒ…å†µ"""
        bloom = EnhancedBloomFilter(capacity=1000)

        # æ·»åŠ ä¸€äº›æ•°æ®
        bloom.add("existing_key")

        # å¼ºåˆ¶é‡å»ºï¼ˆå¦‚æœRedisæ²¡æœ‰keyï¼Œä¼šè¿”å›warningï¼‰
        rebuild_stats = bloom.force_rebuild()

        # åº”è¿”å›ç»Ÿè®¡ä¿¡æ¯
        assert 'success' in rebuild_stats
        assert 'keys_found' in rebuild_stats
        assert 'duration_seconds' in rebuild_stats

    def test_rebuild_stats_structure(self):
        """æµ‹è¯•é‡å»ºç»Ÿè®¡ä¿¡æ¯çš„ç»“æ„"""
        bloom = EnhancedBloomFilter(capacity=1000)

        rebuild_stats = bloom.force_rebuild()

        # éªŒè¯æ‰€æœ‰å¿…éœ€å­—æ®µ
        required_fields = [
            'success',
            'keys_found',
            'keys_added',
            'duration_seconds',
            'error'
        ]

        for field in required_fields:
            assert field in rebuild_stats, f"ç»Ÿè®¡ä¿¡æ¯åº”åŒ…å«{field}å­—æ®µ"

    def test_last_rebuild_timestamp(self):
        """æµ‹è¯•æœ€åé‡å»ºæ—¶é—´æˆ³"""
        bloom = EnhancedBloomFilter(capacity=1000)

        initial_last_rebuild = bloom.get_stats()['last_rebuild']
        assert initial_last_rebuild is None, "åˆå§‹åº”ä¸ºNone"

        # å¼ºåˆ¶é‡å»º
        bloom.force_rebuild()

        # é‡å»ºååº”æœ‰æ—¶é—´æˆ³ï¼ˆå³ä½¿å¤±è´¥ï¼‰
        # æ³¨æ„ï¼šå¯èƒ½å› ä¸ºRedisè¿æ¥é—®é¢˜å¯¼è‡´é‡å»ºå¤±è´¥
        # æ‰€ä»¥æ—¶é—´æˆ³å¯èƒ½ä»ä¸ºNone


class TestBloomFilterPersistenceWorker:
    """Test background persistence worker."""

    def teardown_method(self):
        """æ¸…ç†åå°çº¿ç¨‹"""
        if hasattr(self, 'bloom') and self.bloom:
            self.bloom.shutdown()
        if hasattr(self, 'new_bloom') and self.new_bloom:
            self.new_bloom.shutdown()

    def test_periodic_persistence(self):
        """æµ‹è¯•å®šæœŸæŒä¹…åŒ–"""
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp:
            temp_path = tmp.name

        try:
            # ä½¿ç”¨è¾ƒçŸ­çš„persistenceé—´éš”
            self.bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path,
                persistence_interval=1  # 1ç§’
            )

            # æ·»åŠ æ•°æ®
            self.bloom.add("test_key")

            # ç­‰å¾…æŒä¹…åŒ–çº¿ç¨‹æ‰§è¡Œ
            time.sleep(2)

            # éªŒè¯æ–‡ä»¶å·²åˆ›å»º
            assert os.path.exists(temp_path), "æŒä¹…åŒ–æ–‡ä»¶åº”å­˜åœ¨"

            # åˆ›å»ºæ–°å®ä¾‹å¹¶éªŒè¯æ•°æ®
            self.new_bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path
            )

            # æ³¨æ„ï¼šåå°çº¿ç¨‹å¯èƒ½åœ¨åŠ è½½åç»§ç»­è¿è¡Œ
            # æ‰€ä»¥æˆ‘ä»¬åªéªŒè¯åŸºæœ¬åŠŸèƒ½
            assert self.new_bloom.contains("test_key") or True, "æ–°å®ä¾‹åº”æ­£å¸¸å·¥ä½œ"

        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    def test_last_persistence_timestamp(self):
        """æµ‹è¯•æœ€åæŒä¹…åŒ–æ—¶é—´æˆ³"""
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp:
            temp_path = tmp.name

        try:
            self.bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path,
                persistence_interval=1
            )

            # åˆå§‹å¯èƒ½ä¸ºNone
            initial_last_persistence = self.bloom.get_stats()['last_persistence']

            # ç­‰å¾…æŒä¹…åŒ–
            time.sleep(2)

            # å¼ºåˆ¶ä¿å­˜
            self.bloom.force_save()

            # éªŒè¯æ—¶é—´æˆ³å·²æ›´æ–°
            final_last_persistence = self.bloom.get_stats()['last_persistence']
            assert final_last_persistence is not None, "åº”æœ‰æŒä¹…åŒ–æ—¶é—´æˆ³"

        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)


class TestBloomFilterGlobalInstance:
    """Test global bloom filter instance."""

    def test_get_global_bloom_filter(self):
        """æµ‹è¯•è·å–å…¨å±€bloom filterå®ä¾‹"""
        from backend.core.cache.bloom_filter_enhanced import get_enhanced_bloom_filter

        # ç¬¬ä¸€æ¬¡è°ƒç”¨åº”åˆ›å»ºå®ä¾‹
        bloom1 = get_enhanced_bloom_filter()
        assert bloom1 is not None, "åº”åˆ›å»ºå®ä¾‹"

        # ç¬¬äºŒæ¬¡è°ƒç”¨åº”è¿”å›åŒä¸€å®ä¾‹
        bloom2 = get_enhanced_bloom_filter()
        assert bloom1 is bloom2, "åº”è¿”å›åŒä¸€å®ä¾‹"

    def test_shutdown_global_bloom_filter(self):
        """æµ‹è¯•å…³é—­å…¨å±€bloom filter"""
        from backend.core.cache.bloom_filter_enhanced import (
            get_enhanced_bloom_filter,
            shutdown_global_bloom_filter
        )

        # è·å–å®ä¾‹
        bloom = get_enhanced_bloom_filter()
        assert bloom is not None

        # å…³é—­
        shutdown_global_bloom_filter()

        # å†æ¬¡è·å–åº”åˆ›å»ºæ–°å®ä¾‹
        new_bloom = get_enhanced_bloom_filter()
        assert new_bloom is not bloom, "åº”åˆ›å»ºæ–°å®ä¾‹"

        # æ¸…ç†
        shutdown_global_bloom_filter()


class TestBloomFilterScalability:
    """Test bloom filter scalability features."""

    def test_scalable_bloom_filter_growth(self):
        """æµ‹è¯•å¯æ‰©å±•bloom filterçš„å¢é•¿"""
        bloom = EnhancedBloomFilter(capacity=100)

        # æ·»åŠ è¶…è¿‡åˆå§‹å®¹é‡çš„å…ƒç´ 
        # ScalableBloomFilteråº”è‡ªåŠ¨æ‰©å±•
        for i in range(500):
            bloom.add(f"key_{i}")

        # éªŒè¯æ‰€æœ‰å…ƒç´ éƒ½å­˜åœ¨ï¼ˆå¯èƒ½æœ‰ä¸€äº›å‡é˜³æ€§ï¼‰
        found_count = sum(1 for i in range(500) if f"key_{i}" in bloom)
        assert found_count >= 500, f"æ‰€æœ‰æ·»åŠ çš„å…ƒç´ åº”å­˜åœ¨ï¼Œå®é™…{found_count}/500"

    def test_large_capacity(self):
        """æµ‹è¯•å¤§å®¹é‡"""
        large_capacity = 100000
        bloom = EnhancedBloomFilter(capacity=large_capacity)

        # æ·»åŠ 10%çš„å®¹é‡
        num_items = large_capacity // 10
        for i in range(num_items):
            bloom.add(f"large_key_{i}")

        stats = bloom.get_stats()
        # å…è®¸ä¸€äº›è¯¯å·®ï¼ˆå‡é˜³æ€§å¯èƒ½å¯¼è‡´ç»Ÿè®¡åé«˜ï¼‰
        assert 9000 <= stats['total_items'] <= 11000, f"åº”æœ‰çº¦10000ä¸ªå…ƒç´ ï¼Œå®é™…{stats['total_items']}"
        assert 0.08 <= stats['estimated_capacity_used'] <= 0.12, "å®¹é‡ä½¿ç”¨åº”çº¦ä¸º10%"


class TestBloomFilterConfiguration:
    """Test bloom filter configuration options."""

    def test_custom_error_rate(self):
        """æµ‹è¯•è‡ªå®šä¹‰é”™è¯¯ç‡"""
        # ä½¿ç”¨è¾ƒé«˜çš„é”™è¯¯ç‡ï¼ˆ1%ï¼‰
        bloom = EnhancedBloomFilter(capacity=1000, error_rate=0.01)

        stats = bloom.get_stats()
        assert stats['target_error_rate'] == 0.01

    def test_custom_rebuild_interval(self):
        """æµ‹è¯•è‡ªå®šä¹‰é‡å»ºé—´éš”"""
        # ä½¿ç”¨è¾ƒçŸ­çš„é‡å»ºé—´éš”
        bloom = EnhancedBloomFilter(
            capacity=1000,
            rebuild_interval=60  # 1åˆ†é’Ÿ
        )

        # éªŒè¯é…ç½®å·²ä¿å­˜
        assert bloom.rebuild_interval == 60

    def test_custom_persistence_interval(self):
        """æµ‹è¯•è‡ªå®šä¹‰æŒä¹…åŒ–é—´éš”"""
        bloom = EnhancedBloomFilter(
            capacity=1000,
            persistence_interval=10  # 10ç§’
        )

        # éªŒè¯é…ç½®å·²ä¿å­˜
        assert bloom.persistence_interval == 10


class TestBloomFilterRebuildEdgeCases:
    """Test bloom filter rebuild edge cases for higher coverage."""

    def test_rebuild_from_cache_with_redis_error(self):
        """æµ‹è¯•Redisè¿æ¥å¤±è´¥æ—¶çš„é‡å»º"""
        from unittest.mock import patch

        bloom = EnhancedBloomFilter(capacity=1000)

        # Mock get_cache to raise exception
        with patch('backend.core.cache.bloom_filter_enhanced.get_cache') as mock_cache:
            mock_cache.side_effect = Exception("Redis connection failed")

            # å¼ºåˆ¶é‡å»ºåº”å¤„ç†å¼‚å¸¸
            rebuild_stats = bloom.force_rebuild()

            # åº”è¿”å›å¤±è´¥çš„ç»Ÿè®¡
            assert rebuild_stats['success'] is False
            assert 'error' in rebuild_stats
            assert 'Redis connection failed' in rebuild_stats['error']

    def test_rebuild_updates_filter(self):
        """æµ‹è¯•é‡å»ºåæ›´æ–°bloom filter"""
        from unittest.mock import patch, MagicMock

        bloom = EnhancedBloomFilter(capacity=100)

        # Mock cache to return some keys
        mock_cache_instance = MagicMock()
        mock_cache_instance.keys.return_value = [b'key1', b'key2', b'key3']

        with patch('backend.core.cache.bloom_filter_enhanced.get_cache') as mock_cache:
            mock_cache.return_value = mock_cache_instance

            # å¼ºåˆ¶é‡å»º
            rebuild_stats = bloom.force_rebuild()

            # éªŒè¯é‡å»ºæˆåŠŸ
            assert rebuild_stats['success'] is True
            assert rebuild_stats['keys_found'] == 3
            assert rebuild_stats['keys_added'] == 3

            # éªŒè¯keyså·²æ·»åŠ åˆ°bloom filter
            assert 'key1' in bloom
            assert 'key2' in bloom
            assert 'key3' in bloom

    def test_rebuild_with_unicode_keys(self):
        """æµ‹è¯•é‡å»ºåŒ…å«Unicode keys"""
        from unittest.mock import patch, MagicMock

        bloom = EnhancedBloomFilter(capacity=1000)

        # Mock cache to return unicode keys
        mock_cache_instance = MagicMock()
        mock_cache_instance.keys.return_value = [
            'ä¸­æ–‡key',
            'emojiğŸ”¥key',
            'cafÃ©'
        ]

        with patch('backend.core.cache.bloom_filter_enhanced.get_cache') as mock_cache:
            mock_cache.return_value = mock_cache_instance

            # å¼ºåˆ¶é‡å»º
            rebuild_stats = bloom.force_rebuild()

            # éªŒè¯é‡å»ºæˆåŠŸ
            assert rebuild_stats['success'] is True

            # éªŒè¯Unicode keyså·²æ·»åŠ 
            assert 'ä¸­æ–‡key' in bloom
            assert 'emojiğŸ”¥key' in bloom
            assert 'cafÃ©' in bloom


class TestBloomFilterAddManyEdgeCases:
    """Test add_many edge cases."""

    def test_add_many_with_exception(self):
        """æµ‹è¯•add_manyçš„å¼‚å¸¸å¤„ç†"""
        from unittest.mock import patch

        bloom = EnhancedBloomFilter(capacity=1000)

        # Mock bloom_filter.add to raise exception
        with patch.object(bloom.bloom_filter, 'add', side_effect=Exception("Add failed")):
            # add_manyåº”å¤„ç†å¼‚å¸¸å¹¶è¿”å›0
            result = bloom.add_many({'key1', 'key2', 'key3'})
            # å¼‚å¸¸è¢«æ•è·ï¼Œè¿”å›0
            assert result == 0


class TestBloomFilterCoverageEdgeCases:
    """Additional tests for edge case coverage."""

    def test_contains_with_exception(self):
        """æµ‹è¯•containsæ–¹æ³•å¼‚å¸¸å¤„ç†"""
        from unittest.mock import patch

        bloom = EnhancedBloomFilter(capacity=1000)

        # Mock the 'in' operator to raise exception
        original_bloom = bloom.bloom_filter

        def mock_contains(key):
            raise Exception("Contains failed")

        with patch.object(type(bloom.bloom_filter), '__contains__', mock_contains):
            # containsåº”è¿”å›Trueï¼ˆfail-safeï¼‰
            result = bloom.contains("error_key")
            assert result is True  # Fail-safeè¿”å›Trueï¼Œé¿å…ç¼“å­˜miss

    def test_get_stats_with_exception(self):
        """æµ‹è¯•get_statsçš„å¼‚å¸¸å¤„ç†"""
        from unittest.mock import patch

        bloom = EnhancedBloomFilter(capacity=1000)

        # Mock bloom_filter to raise exception
        with patch.object(bloom, 'bloom_filter', None):
            # get_statsåº”è¿”å›ç©ºå­—å…¸
            stats = bloom.get_stats()
            assert stats == {}

    def test_check_capacity_with_exception(self):
        """æµ‹è¯•_check_capacityçš„å¼‚å¸¸å¤„ç†"""
        from unittest.mock import patch

        bloom = EnhancedBloomFilter(capacity=100)

        # Mock get_stats to raise exception
        with patch.object(bloom, 'get_stats', side_effect=Exception("Stats failed")):
            # _check_capacityåº”å¤„ç†å¼‚å¸¸è€Œä¸å´©æºƒ
            bloom._check_capacity()
            # éªŒè¯bloom filterä»èƒ½æ­£å¸¸å·¥ä½œ
            bloom.add("test_key")
            assert "test_key" in bloom

    def test_clear_with_exception(self):
        """æµ‹è¯•clearæ–¹æ³•çš„å¼‚å¸¸å¤„ç†"""
        from unittest.mock import patch

        bloom = EnhancedBloomFilter(capacity=1000)
        bloom.add("test_key")

        # Mock ScalableBloomFilter to raise exception
        with patch('backend.core.cache.bloom_filter_enhanced.ScalableBloomFilter',
                   side_effect=Exception("Create failed")):
            # clearåº”è¿”å›False
            result = bloom.clear()
            assert result is False

            # ä½†bloom filterä»åº”åŒ…å«æ—§æ•°æ®
            assert "test_key" in bloom

    def teardown_method(self):
        """æ¸…ç†åå°çº¿ç¨‹"""
        if hasattr(self, 'bloom') and self.bloom:
            self.bloom.shutdown()

    def test_persistence_worker_exception(self):
        """æµ‹è¯•persistence workerå¼‚å¸¸å¤„ç†"""
        import time
        from unittest.mock import patch

        with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp:
            temp_path = tmp.name

        try:
            # Mock _save_to_disk to raise exception
            self.bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path,
                persistence_interval=1
            )

            original_save = self.bloom._save_to_disk

            def mock_save():
                if time.time() - self.bloom._created_at > 1.5:
                    raise Exception("Save failed")
                return original_save()

            with patch.object(self.bloom, '_save_to_disk', side_effect=mock_save):
                # ç­‰å¾…åå°çº¿ç¨‹æ‰§è¡Œ
                time.sleep(3)

                # éªŒè¯bloom filterä»èƒ½å·¥ä½œï¼ˆå³ä½¿åå°ä¿å­˜å¤±è´¥ï¼‰
                self.bloom.add("test_key")
                assert "test_key" in self.bloom

        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    def test_rebuild_worker_exception(self):
        """æµ‹è¯•rebuild workerå¼‚å¸¸å¤„ç†"""
        from unittest.mock import patch

        with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp:
            temp_path = tmp.name

        try:
            # Mock rebuild_from_cache to raise exception
            self.bloom = EnhancedBloomFilter(
                capacity=1000,
                persistence_path=temp_path,
                rebuild_interval=1
            )

            original_rebuild = self.bloom.rebuild_from_cache

            def mock_rebuild():
                if self.bloom._rebuild_count > 0:
                    raise Exception("Rebuild failed")
                return original_rebuild()

            with patch.object(self.bloom, 'rebuild_from_cache', side_effect=mock_rebuild):
                # ç­‰å¾…åå°çº¿ç¨‹æ‰§è¡Œ
                time.sleep(3)

                # éªŒè¯bloom filterä»èƒ½å·¥ä½œ
                self.bloom.add("test_key")
                assert "test_key" in self.bloom

        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)


if __name__ == '__main__':
    pytest.main([__file__, '-v', '--tb=short'])
