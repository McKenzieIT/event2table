#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼“å­˜ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ
==================
ç›‘æ§ç¼“å­˜æ€§èƒ½æŒ‡æ ‡ï¼Œå¹¶åœ¨å¼‚å¸¸æ—¶è§¦å‘å‘Šè­¦

æ ¸å¿ƒåŠŸèƒ½:
- å®æ—¶æŒ‡æ ‡é‡‡é›† (å‘½ä¸­ç‡ã€å“åº”æ—¶é—´ã€QPS)
- å‘Šè­¦è§„åˆ™å¼•æ“ (é˜ˆå€¼+æŒç»­æ—¶é—´éªŒè¯)
- å‘Šè­¦å»é‡æœºåˆ¶ (é˜²æ­¢é‡å¤å‘Šè­¦)
- æ€§èƒ½æŒ‡æ ‡å†å²è¿½è¸ª
- è‡ªåŠ¨åŒ–å“åº” (é¢„çƒ­ã€æ‰©å®¹)

ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2026-02-24
"""

import logging
import time
from collections import deque
from dataclasses import dataclass, field
from threading import Lock
from typing import Dict, List, Optional, Callable, Any
from enum import Enum

from backend.core.cache.filters import SensitiveDataFilter

logger = logging.getLogger(__name__)

# Add sensitive data filter to prevent information leakage
logger.addFilter(SensitiveDataFilter())


class AlertLevel(Enum):
    """å‘Šè­¦çº§åˆ«"""
    WARNING = "WARNING"
    CRITICAL = "CRITICAL"
    INFO = "INFO"


@dataclass
class AlertRule:
    """å‘Šè­¦è§„åˆ™å®šä¹‰

    Args:
        name: è§„åˆ™åç§°
        metric: ç›‘æ§æŒ‡æ ‡åç§°
        threshold: é˜ˆå€¼
        duration: æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒæŒ‡æ ‡æŒç»­å¼‚å¸¸å¤šä¹…æ‰è§¦å‘å‘Šè­¦
        level: å‘Šè­¦çº§åˆ«
        action: è§¦å‘åŠ¨ä½œï¼ˆå¯é€‰çš„å›è°ƒå‡½æ•°ï¼‰
        description: è§„åˆ™æè¿°
    """
    name: str
    metric: str
    threshold: float
    duration: int
    level: AlertLevel
    action: Optional[Callable[[], None]] = None
    description: str = ""

    def __str__(self) -> str:
        return (
            f"AlertRule(name={self.name}, "
            f"metric={self.metric}, "
            f"threshold={self.threshold:.2%}, "
            f"duration={self.duration}s, "
            f"level={self.level.value})"
        )


@dataclass
class AlertEvent:
    """å‘Šè­¦äº‹ä»¶"""
    rule_name: str
    metric: str
    current_value: float
    threshold: float
    level: AlertLevel
    timestamp: float = field(default_factory=time.time)
    duration: int = 0
    resolved: bool = False

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "rule_name": self.rule_name,
            "metric": self.metric,
            "current_value": f"{self.current_value:.2%}" if self.metric.endswith("_rate") else f"{self.current_value:.2f}",
            "threshold": f"{self.threshold:.2%}" if self.metric.endswith("_rate") else f"{self.threshold:.2f}",
            "level": self.level.value,
            "timestamp": self.timestamp,
            "duration": self.duration,
            "resolved": self.resolved
        }


@dataclass
class MetricSnapshot:
    """æŒ‡æ ‡å¿«ç…§"""
    timestamp: float
    l1_hit_rate: float
    l2_hit_rate: float
    overall_hit_rate: float
    l1_usage: float
    l2_memory_usage: float
    qps: float
    avg_response_time_ms: float


class MetricsHistory:
    """æŒ‡æ ‡å†å²è®°å½•ï¼ˆä½¿ç”¨å¾ªç¯ç¼“å†²åŒºï¼‰"""

    def __init__(self, max_size: int = 3600):
        """
        åˆå§‹åŒ–æŒ‡æ ‡å†å²

        Args:
            max_size: æœ€å¤§ä¿å­˜çš„å¿«ç…§æ•°é‡ï¼Œé»˜è®¤3600ï¼ˆ1åˆ†é’Ÿ1ä¸ªï¼Œä¿å­˜1å°æ—¶ï¼‰
        """
        self.max_size = max_size
        self.history: deque[MetricSnapshot] = deque(maxlen=max_size)
        self._lock = Lock()

    def add(self, snapshot: MetricSnapshot):
        """æ·»åŠ å¿«ç…§"""
        with self._lock:
            self.history.append(snapshot)

    def get_recent(self, duration_seconds: int) -> List[MetricSnapshot]:
        """
        è·å–æœ€è¿‘çš„å¿«ç…§

        Args:
            duration_seconds: æ—¶é—´èŒƒå›´ï¼ˆç§’ï¼‰

        Returns:
            åœ¨æ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰å¿«ç…§
        """
        cutoff_time = time.time() - duration_seconds

        with self._lock:
            return [s for s in self.history if s.timestamp >= cutoff_time]

    def get_latest(self) -> Optional[MetricSnapshot]:
        """è·å–æœ€æ–°å¿«ç…§"""
        with self._lock:
            return self.history[-1] if self.history else None

    def get_trend(self, metric: str, duration_seconds: int = 300) -> Optional[Dict[str, float]]:
        """
        è®¡ç®—æŒ‡æ ‡è¶‹åŠ¿

        Args:
            metric: æŒ‡æ ‡åç§° (l1_hit_rate, l2_hit_rate, overall_hit_rate)
            duration_seconds: æ—¶é—´èŒƒå›´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤300ç§’ï¼ˆ5åˆ†é’Ÿï¼‰

        Returns:
            è¶‹åŠ¿æ•°æ® {min, max, avg, trend} æˆ– None
        """
        snapshots = self.get_recent(duration_seconds)
        if not snapshots:
            return None

        values = [getattr(s, metric) for s in snapshots]

        if not values:
            return None

        return {
            "min": min(values),
            "max": max(values),
            "avg": sum(values) / len(values),
            "count": len(values),
            "trend": values[-1] - values[0] if len(values) > 1 else 0
        }


class CacheAlertManager:
    """ç¼“å­˜å‘Šè­¦ç®¡ç†å™¨

    ç›‘æ§ç¼“å­˜æ€§èƒ½æŒ‡æ ‡ï¼Œå¹¶åœ¨å¼‚å¸¸æ—¶è§¦å‘å‘Šè­¦

    å‘Šè­¦è§„åˆ™:
    - L1å‘½ä¸­ç‡ <60% æŒç»­5åˆ†é’Ÿ â†’ WARNING
    - L2å‘½ä¸­ç‡ <70% æŒç»­10åˆ†é’Ÿ â†’ WARNING
    - æ€»ä½“å‘½ä¸­ç‡ <50% æŒç»­5åˆ†é’Ÿ â†’ CRITICAL (è‡ªåŠ¨é¢„çƒ­)
    - L1å‘½ä¸­ç‡ <40% æŒç»­3åˆ†é’Ÿ â†’ CRITICAL (æ‰©å®¹L1)
    - L1ä½¿ç”¨ç‡ >85% â†’ WARNING
    - L1ä½¿ç”¨ç‡ >95% â†’ CRITICAL (è‡ªåŠ¨æ‰©å®¹)
    """

    def __init__(self, hierarchical_cache):
        """
        åˆå§‹åŒ–å‘Šè­¦ç®¡ç†å™¨

        Args:
            hierarchical_cache: ä¸‰çº§ç¼“å­˜å®ä¾‹
        """
        self.cache = hierarchical_cache
        self.metrics_history = MetricsHistory(max_size=3600)

        # å‘Šè­¦è§„åˆ™å®šä¹‰
        self.alert_rules: List[AlertRule] = [
            # L1å‘½ä¸­ç‡å‘Šè­¦
            AlertRule(
                name="l1_hit_rate_low",
                metric="l1_hit_rate",
                threshold=0.6,
                duration=300,  # 5åˆ†é’Ÿ
                level=AlertLevel.WARNING,
                description="L1ç¼“å­˜å‘½ä¸­ç‡ä½äº60%æŒç»­5åˆ†é’Ÿ"
            ),
            AlertRule(
                name="l1_hit_rate_critical",
                metric="l1_hit_rate",
                threshold=0.4,
                duration=180,  # 3åˆ†é’Ÿ
                level=AlertLevel.CRITICAL,
                action=self._auto_expand_l1,
                description="L1ç¼“å­˜å‘½ä¸­ç‡ä½äº40%æŒç»­3åˆ†é’Ÿï¼Œè§¦å‘è‡ªåŠ¨æ‰©å®¹"
            ),

            # L2å‘½ä¸­ç‡å‘Šè­¦
            AlertRule(
                name="l2_hit_rate_low",
                metric="l2_hit_rate",
                threshold=0.7,
                duration=600,  # 10åˆ†é’Ÿ
                level=AlertLevel.WARNING,
                description="L2ç¼“å­˜å‘½ä¸­ç‡ä½äº70%æŒç»­10åˆ†é’Ÿ"
            ),

            # æ€»ä½“å‘½ä¸­ç‡å‘Šè­¦
            AlertRule(
                name="overall_hit_rate_critical",
                metric="overall_hit_rate",
                threshold=0.5,
                duration=300,  # 5åˆ†é’Ÿ
                level=AlertLevel.CRITICAL,
                action=self._trigger_warm_up,
                description="æ€»ä½“ç¼“å­˜å‘½ä¸­ç‡ä½äº50%æŒç»­5åˆ†é’Ÿï¼Œè§¦å‘è‡ªåŠ¨é¢„çƒ­"
            ),

            # L1å®¹é‡å‘Šè­¦
            AlertRule(
                name="l1_capacity_warning",
                metric="l1_usage",
                threshold=0.85,
                duration=60,  # 1åˆ†é’Ÿ
                level=AlertLevel.WARNING,
                description="L1ç¼“å­˜ä½¿ç”¨ç‡è¶…è¿‡85%"
            ),
            AlertRule(
                name="l1_capacity_critical",
                metric="l1_usage",
                threshold=0.95,
                duration=30,  # 30ç§’
                level=AlertLevel.CRITICAL,
                action=self._auto_expand_l1,
                description="L1ç¼“å­˜ä½¿ç”¨ç‡è¶…è¿‡95%ï¼Œè§¦å‘è‡ªåŠ¨æ‰©å®¹"
            ),
        ]

        # å‘Šè­¦çŠ¶æ€è¿½è¸ª
        self.active_alerts: Dict[str, AlertEvent] = {}
        self.alert_history: List[AlertEvent] = []
        self._alert_lock = Lock()

        # æ€§èƒ½ç»Ÿè®¡ï¼ˆç”¨äºè®¡ç®—QPSå’Œå“åº”æ—¶é—´ï¼‰
        self._request_count = 0
        self._response_time_total = 0.0
        self._last_check_time = time.time()
        self._performance_lock = Lock()

        logger.info("âœ… ç¼“å­˜å‘Šè­¦ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def record_request(self, response_time_ms: float):
        """
        è®°å½•è¯·æ±‚ï¼ˆç”¨äºè®¡ç®—QPSå’Œå“åº”æ—¶é—´ï¼‰

        Args:
            response_time_ms: å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        """
        with self._performance_lock:
            self._request_count += 1
            self._response_time_total += response_time_ms

    def collect_metrics(self) -> MetricSnapshot:
        """
        é‡‡é›†å½“å‰æŒ‡æ ‡å¿«ç…§

        Returns:
            æŒ‡æ ‡å¿«ç…§
        """
        # è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = self.cache.get_stats()

        # è§£æç™¾åˆ†æ¯”å­—ç¬¦ä¸²
        def parse_rate(rate_str: str) -> float:
            """è§£æç™¾åˆ†æ¯”å­—ç¬¦ä¸²"""
            if isinstance(rate_str, str):
                return float(rate_str.rstrip('%')) / 100
            return float(rate_str)

        # è®¡ç®—å„å±‚å‘½ä¸­ç‡
        l1_hits = stats.get('l1_hits', 0)
        l2_hits = stats.get('l2_hits', 0)
        misses = stats.get('misses', 0)
        total_requests = stats.get('total_requests', 1)

        # L1å‘½ä¸­ç‡ = L1å‘½ä¸­æ¬¡æ•° / æ€»è¯·æ±‚æ¬¡æ•°
        l1_hit_rate = l1_hits / total_requests if total_requests > 0 else 0

        # L2å‘½ä¸­ç‡ = L2å‘½ä¸­æ¬¡æ•° / (L2æœªå‘½ä¸­ä½†L2æŸ¥è¯¢çš„æ¬¡æ•°)
        # ç®€åŒ–è®¡ç®—ï¼šL2å‘½ä¸­ / (L1æœªå‘½ä¸­æ¬¡æ•°)
        l1_misses = total_requests - l1_hits
        l2_hit_rate = l2_hits / l1_misses if l1_misses > 0 else 0

        # æ€»ä½“å‘½ä¸­ç‡ = (L1å‘½ä¸­ + L2å‘½ä¸­) / æ€»è¯·æ±‚æ¬¡æ•°
        overall_hit_rate = (l1_hits + l2_hits) / total_requests if total_requests > 0 else 0

        # è§£æL1ä½¿ç”¨ç‡
        l1_usage = parse_rate(stats.get('l1_usage', '0%'))

        # è®¡ç®—QPSå’Œå¹³å‡å“åº”æ—¶é—´
        current_time = time.time()
        time_elapsed = current_time - self._last_check_time

        with self._performance_lock:
            qps = self._request_count / time_elapsed if time_elapsed > 0 else 0
            avg_response_time = (
                self._response_time_total / self._request_count
                if self._request_count > 0 else 0
            )
            # é‡ç½®è®¡æ•°å™¨
            self._request_count = 0
            self._response_time_total = 0.0

        self._last_check_time = current_time

        # åˆ›å»ºå¿«ç…§
        snapshot = MetricSnapshot(
            timestamp=current_time,
            l1_hit_rate=l1_hit_rate,
            l2_hit_rate=l2_hit_rate,
            overall_hit_rate=overall_hit_rate,
            l1_usage=l1_usage,
            l2_memory_usage=0.0,  # TODO: ä»Redisè·å–
            qps=qps,
            avg_response_time_ms=avg_response_time
        )

        # ä¿å­˜åˆ°å†å²è®°å½•
        self.metrics_history.add(snapshot)

        return snapshot

    def check_alerts(self) -> List[AlertEvent]:
        """
        æ£€æŸ¥æ‰€æœ‰å‘Šè­¦è§„åˆ™

        Returns:
            æ–°è§¦å‘çš„å‘Šè­¦äº‹ä»¶åˆ—è¡¨
        """
        current_snapshot = self.collect_metrics()
        new_alerts: List[AlertEvent] = []

        for rule in self.alert_rules:
            # è·å–å½“å‰æŒ‡æ ‡å€¼
            current_value = getattr(current_snapshot, rule.metric, 0.0)

            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
            is_triggered = current_value < rule.threshold if rule.metric.endswith("_rate") else current_value > rule.threshold

            if is_triggered:
                # æ£€æŸ¥æŒç»­æ—¶é—´
                duration_seconds = self._check_duration(rule, current_value)

                if duration_seconds >= rule.duration:
                    # è§¦å‘å‘Šè­¦
                    alert = AlertEvent(
                        rule_name=rule.name,
                        metric=rule.metric,
                        current_value=current_value,
                        threshold=rule.threshold,
                        level=rule.level,
                        duration=int(duration_seconds)
                    )

                    # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸åŒçš„å‘Šè­¦
                    if self._should_trigger_alert(alert):
                        with self._alert_lock:
                            self.active_alerts[rule.name] = alert
                            self.alert_history.append(alert)

                        # è®°å½•æ—¥å¿—
                        self._log_alert(alert, rule)

                        # æ‰§è¡Œå‘Šè­¦åŠ¨ä½œ
                        if rule.action:
                            try:
                                rule.action()
                            except Exception as e:
                                logger.error(f"âŒ å‘Šè­¦åŠ¨ä½œæ‰§è¡Œå¤±è´¥: {e}")

                        new_alerts.append(alert)
            else:
                # æŒ‡æ ‡æ­£å¸¸ï¼Œæ ‡è®°å‘Šè­¦ä¸ºå·²è§£å†³
                if rule.name in self.active_alerts:
                    with self._alert_lock:
                        alert = self.active_alerts[rule.name]
                        alert.resolved = True
                        del self.active_alerts[rule.name]

                    logger.info(
                        f"âœ… å‘Šè­¦å·²è§£é™¤: {rule.name} "
                        f"({rule.metric}: {current_value:.2%})"
                    )

        return new_alerts

    def _check_duration(self, rule: AlertRule, current_value: float) -> float:
        """
        æ£€æŸ¥æŒ‡æ ‡æŒç»­å¼‚å¸¸çš„æ—¶é—´

        Args:
            rule: å‘Šè­¦è§„åˆ™
            current_value: å½“å‰æŒ‡æ ‡å€¼

        Returns:
            æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        """
        snapshots = self.metrics_history.get_recent(rule.duration)

        # ç»Ÿè®¡å¼‚å¸¸å¿«ç…§æ•°é‡
        is_anomaly = lambda s: (
            getattr(s, rule.metric, 0.0) < rule.threshold
            if rule.metric.endswith("_rate")
            else getattr(s, rule.metric, 0.0) > rule.threshold
        )

        anomaly_count = sum(1 for s in snapshots if is_anomaly(s))

        if anomaly_count == 0:
            return 0

        # ä¼°ç®—æŒç»­æ—¶é—´ï¼ˆå‡è®¾å¿«ç…§é—´éš”çº¦1ç§’ï¼‰
        oldest_anomaly_time = min(
            s.timestamp for s in snapshots if is_anomaly(s)
        )

        return time.time() - oldest_anomaly_time

    def _should_trigger_alert(self, alert: AlertEvent) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘å‘Šè­¦ï¼ˆå»é‡ï¼‰

        Args:
            alert: å‘Šè­¦äº‹ä»¶

        Returns:
            æ˜¯å¦åº”è¯¥è§¦å‘
        """
        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸åŒçš„æ´»è·ƒå‘Šè­¦
        if alert.rule_name in self.active_alerts:
            existing_alert = self.active_alerts[alert.rule_name]

            # å¦‚æœå‘Šè­¦çº§åˆ«ç›¸åŒï¼Œä¸”ä¸Šæ¬¡è§¦å‘æ—¶é—´ä¸è¶…è¿‡1åˆ†é’Ÿï¼Œåˆ™ä¸é‡å¤è§¦å‘
            if (existing_alert.level == alert.level and
                time.time() - existing_alert.timestamp < 60):
                return False

        return True

    def _log_alert(self, alert: AlertEvent, rule: AlertRule):
        """è®°å½•å‘Šè­¦æ—¥å¿—"""
        log_func = (
            logger.critical if alert.level == AlertLevel.CRITICAL
            else logger.warning
        )

        value_str = (
            f"{alert.current_value:.2%}" if alert.metric.endswith("_rate")
            else f"{alert.current_value:.2%}"
        )
        threshold_str = (
            f"{alert.threshold:.2%}" if alert.metric.endswith("_rate")
            else f"{alert.threshold:.2%}"
        )

        log_func(
            f"ğŸš¨ ç¼“å­˜å‘Šè­¦: {rule.description}\n"
            f"   æŒ‡æ ‡: {alert.metric}\n"
            f"   å½“å‰å€¼: {value_str}\n"
            f"   é˜ˆå€¼: {threshold_str}\n"
            f"   æŒç»­æ—¶é—´: {alert.duration}ç§’\n"
            f"   çº§åˆ«: {alert.level.value}"
        )

    def _auto_expand_l1(self):
        """è‡ªåŠ¨æ‰©å®¹L1ç¼“å­˜"""
        try:
            current_size = self.cache.l1_size
            new_size = int(current_size * 1.5)  # æ‰©å®¹50%

            logger.warning(
                f"ğŸ”§ è‡ªåŠ¨æ‰©å®¹L1ç¼“å­˜: {current_size} â†’ {new_size}"
            )

            self.cache.l1_size = new_size

            logger.info(f"âœ… L1ç¼“å­˜æ‰©å®¹å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ L1ç¼“å­˜æ‰©å®¹å¤±è´¥: {e}")

    def _trigger_warm_up(self):
        """è§¦å‘ç¼“å­˜é¢„çƒ­"""
        logger.warning("ğŸ”¥ è§¦å‘ç¼“å­˜é¢„çƒ­")
        # TODO: è°ƒç”¨æ™ºèƒ½é¢„çƒ­ç³»ç»Ÿ
        # from .intelligent_warmer import cache_warmer
        # cache_warmer.warm_up_cache()

    def get_active_alerts(self) -> List[Dict[str, Any]]:
        """
        è·å–å½“å‰æ´»è·ƒçš„å‘Šè­¦

        Returns:
            æ´»è·ƒå‘Šè­¦åˆ—è¡¨
        """
        with self._alert_lock:
            return [alert.to_dict() for alert in self.active_alerts.values()]

    def get_alert_history(self, limit: int = 100) -> List[Dict[str, Any]]:
        """
        è·å–å‘Šè­¦å†å²

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            å‘Šè­¦å†å²åˆ—è¡¨
        """
        with self._alert_lock:
            return [
                alert.to_dict()
                for alert in self.alert_history[-limit:]
            ]

    def get_metrics_summary(self) -> Dict[str, Any]:
        """
        è·å–æŒ‡æ ‡æ‘˜è¦

        Returns:
            æŒ‡æ ‡æ‘˜è¦å­—å…¸
        """
        latest = self.metrics_history.get_latest()
        if not latest:
            return {}

        return {
            "timestamp": latest.timestamp,
            "l1_hit_rate": f"{latest.l1_hit_rate:.2%}",
            "l2_hit_rate": f"{latest.l2_hit_rate:.2%}",
            "overall_hit_rate": f"{latest.overall_hit_rate:.2%}",
            "l1_usage": f"{latest.l1_usage:.1f}%",
            "qps": f"{latest.qps:.2f}",
            "avg_response_time_ms": f"{latest.avg_response_time_ms:.2f}",
            "trends": {
                "l1_hit_rate_5min": self.metrics_history.get_trend("l1_hit_rate", 300),
                "l2_hit_rate_5min": self.metrics_history.get_trend("l2_hit_rate", 300),
                "overall_hit_rate_5min": self.metrics_history.get_trend("overall_hit_rate", 300),
            }
        }

    def reset(self):
        """é‡ç½®å‘Šè­¦ç®¡ç†å™¨"""
        with self._alert_lock:
            self.active_alerts.clear()
            self.alert_history.clear()

        logger.info("ğŸ”„ å‘Šè­¦ç®¡ç†å™¨å·²é‡ç½®")


# å¯¼å‡ºPrometheusæ ¼å¼çš„æŒ‡æ ‡
def export_prometheus_metrics(alert_manager: CacheAlertManager) -> str:
    """
    å¯¼å‡ºPrometheusæ ¼å¼çš„æŒ‡æ ‡

    Args:
        alert_manager: å‘Šè­¦ç®¡ç†å™¨å®ä¾‹

    Returns:
        Prometheusæ ¼å¼çš„æŒ‡æ ‡å­—ç¬¦ä¸²
    """
    lines = []

    # ç¼“å­˜å‘½ä¸­ç‡
    summary = alert_manager.get_metrics_summary()
    if summary:
        hit_rates = {
            "l1": summary.get("l1_hit_rate", "0%"),
            "l2": summary.get("l2_hit_rate", "0%"),
            "overall": summary.get("overall_hit_rate", "0%")
        }

        for level, rate in hit_rates.items():
            rate_value = float(rate.rstrip('%')) / 100
            lines.append(f'cache_hit_rate{{level="{level}"}} {rate_value}')

    # ç¼“å­˜å®¹é‡
    stats = alert_manager.cache.get_stats()
    lines.append(f'cache_l1_usage {stats.get("l1_size", 0)}')
    lines.append(f'cache_l1_capacity {stats.get("l1_capacity", 0)}')

    # æ´»è·ƒå‘Šè­¦æ•°é‡
    active_alerts = alert_manager.get_active_alerts()
    warning_count = sum(1 for a in active_alerts if a["level"] == "WARNING")
    critical_count = sum(1 for a in active_alerts if a["level"] == "CRITICAL")

    lines.append(f'cache_alerts{{level="warning"}} {warning_count}')
    lines.append(f'cache_alerts{{level="critical"}} {critical_count}')

    return "\n".join(lines)


# Global instance
_global_alert_manager: Optional[CacheAlertManager] = None
_alert_manager_lock = Lock()


def get_cache_alert_manager(hierarchical_cache=None):
    """
    Get or create the global CacheAlertManager instance.

    Args:
        hierarchical_cache: ä¸‰çº§ç¼“å­˜å®ä¾‹ï¼ˆä»…é¦–æ¬¡è°ƒç”¨æ—¶éœ€è¦ï¼‰

    Returns:
        CacheAlertManager instance
    """
    global _global_alert_manager

    with _alert_manager_lock:
        if _global_alert_manager is None:
            if hierarchical_cache is None:
                raise ValueError(
                    "hierarchical_cache is required on first call to get_cache_alert_manager"
                )
            logger.info("Creating global CacheAlertManager instance")
            _global_alert_manager = CacheAlertManager(hierarchical_cache)

        return _global_alert_manager


# å…¬å¼€åˆ«åï¼Œç”¨äºæ¨¡å—å¯¼å…¥
# Export the class for testing purposes (the instance requires hierarchical_cache parameter)
cache_alert_manager = CacheAlertManager


logger.info("âœ… ç¼“å­˜ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿå·²åŠ è½½ (1.0.0)")
