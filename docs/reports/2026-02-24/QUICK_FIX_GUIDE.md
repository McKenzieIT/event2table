# ç¼“å­˜ç³»ç»Ÿç»´æŠ¤æ€§é—®é¢˜ - å¿«é€Ÿä¿®å¤æŒ‡å—

**ä¿®å¤ä¼˜å…ˆçº§**: P0 â†’ P1 â†’ P2 â†’ P3
**é¢„è®¡æ€»æ—¶é—´**: ~10å°æ—¶

---

## P0 - ç«‹å³ä¿®å¤ï¼ˆ5åˆ†é’Ÿï¼‰âš ï¸

### é—®é¢˜1: ç©ºexceptå—

**æ–‡ä»¶**: `tests/test_capacity_monitor.py:177`

**å½“å‰ä»£ç **:
```python
try:
    # ... æµ‹è¯•ä»£ç  ...
except:
    pass  # âŒ éšè—æ‰€æœ‰é”™è¯¯
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
try:
    # ... æµ‹è¯•ä»£ç  ...
except AssertionError as e:
    logger.debug(f"Capacity assertion failed (expected in test): {e}")
except Exception as e:
    logger.error(f"Unexpected error in capacity test: {e}")
    raise  # é‡æ–°æŠ›å‡ºæœªçŸ¥å¼‚å¸¸
```

**éªŒè¯æ–¹æ³•**:
```bash
cd backend/core/cache
python -m pytest tests/test_capacity_monitor.py -v
```

---

## P1 - æœ¬å‘¨ä¿®å¤ï¼ˆ40åˆ†é’Ÿï¼‰

### é—®é¢˜2: __init__.pyç¼ºå°‘æ¨¡å—æ–‡æ¡£

**æ–‡ä»¶**: `backend/core/cache/__init__.py`

**ä¿®å¤æ–¹æ¡ˆ**:
```python
"""
Cache System Module
===================

Provides a comprehensive three-tier hierarchical caching system with:
- L1: In-memory cache (LRU, 1000 items, 60s TTL)
- L2: Redis shared cache (100k items, 3600s TTL)
- L3: Database queries

Modules:
- bloom_filter_enhanced: Enhanced bloom filter with persistence
- cache_hierarchical: Three-tier hierarchical cache manager
- cache_system: Unified cache system with decorators
- cache_warmer: Automatic cache warming on startup
- capacity_monitor: L1/L2 capacity monitoring and auto-scaling
- consistency: Read-write lock for concurrent access
- decorators: Service layer cache decorators
- degradation: Redis failure degradation strategy
- intelligent_warmer: Smart cache warming based on access patterns
- invalidator: Unified cache invalidation strategies
- monitoring: Performance monitoring and alerting
- protection: Cache penetration protection
- statistics: Cache statistics collection

Example:
    from backend.core.cache import hierarchical_cache, cached_hierarchical

    @cached_hierarchical('events.list')
    def get_events(game_id: int):
        return fetch_events_from_db(game_id)
"""
```

---

### é—®é¢˜3: å¼‚å¸¸å¤„ç†è¿‡äºå®½æ³›

**æ–‡ä»¶**: `backend/core/cache/cache_hierarchical.py`

**å½“å‰ä»£ç ** (çº¦ç¬¬190è¡Œ):
```python
try:
    cached = cache.get(key)
    if cached is not None:
        self._set_l1(key, cached)
        self.stats["l2_hits"] += 1
        logger.debug(f"âœ… L2 HIT â†’ L1å›å¡«: {key}")
        return cached
except Exception as e:  # âŒ è¿‡äºå®½æ³›
    logger.warning(f"âš ï¸ L2ç¼“å­˜è¯»å–å¤±è´¥: {e}")
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
try:
    cached = cache.get(key)
    if cached is not None:
        self._set_l1(key, cached)
        self.stats["l2_hits"] += 1
        logger.debug(f"âœ… L2 HIT â†’ L1å›å¡«: {key}")
        return cached
except RedisError as e:  # âœ… åŒºåˆ†Rediså¼‚å¸¸
    logger.warning(f"âš ï¸ L2 Redisé”™è¯¯: {e}")
    # è§¦å‘é™çº§æ¨¡å¼
    if self._enable_degradation:
        degradation_manager = self._get_degradation_manager()
        if degradation_manager:
            degradation_manager._enter_degraded_mode()
except Exception as e:  # âœ… å…¶ä»–å¼‚å¸¸
    logger.error(f"âš ï¸ L2ç¼“å­˜æœªçŸ¥é”™è¯¯: {e}", exc_info=True)
```

---

### é—®é¢˜4: æ—¥å¿—ç¼ºå°‘ä¸Šä¸‹æ–‡

**æ–‡ä»¶**: `backend/core/cache/cache_system.py`

**å½“å‰ä»£ç ** (çº¦ç¬¬300è¡Œ):
```python
try:
    result = cache.get(key)
except Exception as e:
    logger.error(f"Cache get failed: {e}")  # âŒ ç¼ºå°‘keyä¿¡æ¯
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
try:
    result = cache.get(key)
except Exception as e:
    logger.error(
        f"Cache get failed: "
        f"key={key}, "
        f"pattern={pattern}, "
        f"error={e}",
        exc_info=True  # âœ… æ·»åŠ å †æ ˆè·Ÿè¸ª
    )
```

---

## P2 - 2å‘¨å†…ä¿®å¤ï¼ˆ5å°æ—¶ï¼‰

### é—®é¢˜5: å®ç°L2å†…å­˜ä½¿ç”¨ç‡è·å–

**æ–‡ä»¶**: `backend/core/cache/monitoring.py:345`

**å½“å‰ä»£ç **:
```python
'l2_memory_usage': 0.0,  # TODO: ä»Redisè·å–
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# 1. åœ¨_monitor_redisæ–¹æ³•ä¸­æ·»åŠ å†…å­˜ä½¿ç”¨ç‡è·å–
def _monitor_redis(self) -> Dict[str, Any]:
    """ç›‘æ§RedisçŠ¶æ€"""
    try:
        redis_client = get_redis_client()
        if redis_client is None:
            return {'l2_memory_usage': 0.0}

        # è·å–Redis info
        info = redis_client.info()

        # è®¡ç®—å†…å­˜ä½¿ç”¨ç‡
        used_memory = info.get('used_memory', 0)
        max_memory = info.get('maxmemory', 0)

        if max_memory > 0:
            memory_usage = used_memory / max_memory
        else:
            # å¦‚æœæœªè®¾ç½®max_memoryï¼Œä½¿ç”¨ç³»ç»Ÿå†…å­˜
            memory_usage = 0.0  # æˆ–è·å–ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡

        return {
            'l2_memory_usage': memory_usage,
            'l2_used_memory_bytes': used_memory,
            'l2_max_memory_bytes': max_memory,
        }
    except Exception as e:
        logger.error(f"Failed to monitor Redis: {e}")
        return {'l2_memory_usage': 0.0}

# 2. åœ¨_get_current_snapshotä¸­è°ƒç”¨
def _get_current_snapshot(self) -> MetricSnapshot:
    """è·å–å½“å‰æŒ‡æ ‡å¿«ç…§"""
    l1_stats = self.hierarchical_cache.get_stats()
    redis_stats = self._monitor_redis()

    return MetricSnapshot(
        timestamp=time.time(),
        l1_hit_rate=...,
        l2_hit_rate=...,
        overall_hit_rate=...,
        l2_memory_usage=redis_stats['l2_memory_usage'],  # âœ… ä½¿ç”¨å®é™…å€¼
        l1_size=l1_stats['l1_size'],
        l1_capacity=l1_stats['l1_capacity'],
    )
```

---

### é—®é¢˜6: å®ç°é¢„æµ‹å‡†ç¡®ç‡è®¡ç®—

**æ–‡ä»¶**: `backend/core/cache/intelligent_warmer.py:185`

**å½“å‰ä»£ç **:
```python
'prediction_accuracy': 0.0,  # TODO: è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# 1. æ·»åŠ å®é™…è®¿é—®è®°å½•è·Ÿè¸ª
class FrequencyPredictor:
    def __init__(self):
        self.key_frequency = defaultdict(int)
        self.predicted_keys = set()  # é¢„æµ‹çš„çƒ­ç‚¹é”®
        self.actual_hits = set()  # å®é™…å‘½ä¸­çš„é”®

    def record_prediction(self, keys: List[str]):
        """è®°å½•é¢„æµ‹çš„çƒ­ç‚¹é”®"""
        self.predicted_keys.update(keys)

    def record_access(self, key: str):
        """è®°å½•å®é™…è®¿é—®"""
        self.actual_hits.add(key)

    def calculate_accuracy(self) -> float:
        """è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡"""
        if len(self.predicted_keys) == 0:
            return 0.0

        # é¢„æµ‹å‘½ä¸­çš„æ•°é‡
        hits = len(self.predicted_keys & self.actual_hits)
        accuracy = hits / len(self.predicted_keys)
        return accuracy

# 2. åœ¨get_warming_statsä¸­ä½¿ç”¨
def get_warming_stats(self) -> Dict[str, Any]:
    """è·å–é¢„çƒ­ç»Ÿè®¡"""
    accuracy = self.predictor.calculate_accuracy()

    return {
        'total_predictions': len(self.predictor.predicted_keys),
        'actual_hits': len(self.predictor.actual_hits),
        'prediction_accuracy': accuracy,  # âœ… ä½¿ç”¨è®¡ç®—å€¼
        # ... å…¶ä»–ç»Ÿè®¡ ...
    }
```

---

### é—®é¢˜7: å®ç°set_raw()æ–¹æ³•

**æ–‡ä»¶**: `backend/core/cache/intelligent_warmer.py:295`

**å½“å‰ä»£ç **:
```python
# TODO: éœ€è¦å®ç°hierarchical_cache.set_raw()
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# 1. åœ¨HierarchicalCacheä¸­æ·»åŠ set_rawæ–¹æ³•
class HierarchicalCache:
    def set_raw(self, key: str, data: Any):
        """
        ç›´æ¥è®¾ç½®L2ç¼“å­˜ï¼Œä¸ç»è¿‡L1

        ç”¨äºé¢„çƒ­æ—¶ç›´æ¥å†™å…¥L2ï¼Œé¿å…L1æ±¡æŸ“

        Args:
            key: ç¼“å­˜é”®
            data: ç¼“å­˜æ•°æ®
        """
        cache = get_cache()
        if cache is not None:
            try:
                cache.set(key, data, timeout=self.l2_ttl)
                logger.debug(f"ğŸ’¾ L2 RAW SET: {key}")
            except Exception as e:
                logger.warning(f"âš ï¸ L2ç›´æ¥å†™å…¥å¤±è´¥: {e}")

# 2. åœ¨IntelligentWarmerä¸­ä½¿ç”¨
def _warm_key(self, key: str, data: Any):
    """é¢„çƒ­å•ä¸ªé”®"""
    # ç›´æ¥å†™å…¥L2ï¼Œä¸ç»è¿‡L1
    self.hierarchical_cache.set_raw(key, data)
    logger.debug(f"âœ… é¢„çƒ­å®Œæˆ: {key}")
```

---

## P3 - ä¸­æœŸä¼˜åŒ–ï¼ˆ3å°æ—¶ï¼‰

### é—®é¢˜8: é‡æ„é«˜å¤æ‚åº¦å‡½æ•°

**æ–‡ä»¶**: `backend/core/cache/cache_hierarchical.py`

**å‡½æ•°**: `_match_pattern` (åœˆå¤æ‚åº¦12)

**é‡æ„æ–¹æ¡ˆ**:
```python
# å½“å‰ä»£ç ï¼ˆå¤æ‚ï¼‰
def _match_pattern(self, key: str, pattern: str) -> bool:
    # 120è¡Œå¤æ‚é€»è¾‘...

# é‡æ„åï¼ˆæ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°ï¼‰
def _match_pattern(self, key: str, pattern: str) -> bool:
    """å‚æ•°æ„ŸçŸ¥çš„é€šé…ç¬¦åŒ¹é…"""
    # éªŒè¯å‰ç¼€
    if not self._validate_prefix(key, pattern):
        return False

    # è§£æå‚æ•°
    key_params = self._extract_key_params(key)
    pattern_constraints = self._extract_pattern_constraints(pattern)

    # æ£€æŸ¥çº¦æŸ
    return self._check_constraints(key_params, pattern_constraints)

def _validate_prefix(self, key: str, pattern: str) -> bool:
    """éªŒè¯å‰ç¼€æ˜¯å¦åŒ¹é…"""
    prefix = CacheKeyBuilder.PREFIX
    return (key.startswith(prefix) and
            pattern.startswith(prefix))

def _extract_key_params(self, key: str) -> Dict[str, str]:
    """ä»é”®ä¸­æå–å‚æ•°"""
    suffix = key[len(CacheKeyBuilder.PREFIX):]
    parts = suffix.split(":")
    params = {}
    for i in range(1, len(parts), 2):
        if i + 1 < len(parts):
            params[parts[i]] = parts[i + 1]
    return params

def _extract_pattern_constraints(self, pattern: str) -> Dict[str, Optional[str]]:
    """ä»æ¨¡å¼ä¸­æå–çº¦æŸ"""
    suffix = pattern[len(CacheKeyBuilder.PREFIX):]
    parts = suffix.split(":")
    constraints = {}
    for i in range(1, len(parts), 2):
        if i + 1 < len(parts):
            value = None if parts[i + 1] == "*" else parts[i + 1]
            constraints[parts[i]] = value
    return constraints

def _check_constraints(
    self,
    key_params: Dict[str, str],
    pattern_constraints: Dict[str, Optional[str]]
) -> bool:
    """æ£€æŸ¥å‚æ•°æ˜¯å¦æ»¡è¶³çº¦æŸ"""
    for param_name, param_value in pattern_constraints.items():
        if param_name not in key_params:
            return False
        if param_value is not None and key_params[param_name] != param_value:
            return False
    return True
```

---

## éªŒè¯æ¸…å•

ä¿®å¤å®Œæˆåï¼Œè¯·æ‰§è¡Œä»¥ä¸‹éªŒè¯ï¼š

### ä»£ç è´¨é‡æ£€æŸ¥
```bash
# 1. è¯­æ³•æ£€æŸ¥
cd backend/core/cache
python -m py_compile *.py

# 2. å¯¼å…¥æ£€æŸ¥
python -c "from backend.core.cache import hierarchical_cache, cached_hierarchical"

# 3. å•å…ƒæµ‹è¯•
python -m pytest tests/ -v

# 4. é›†æˆæµ‹è¯•
cd /Users/mckenzie/Documents/event2table
python backend/tests/integration/test_cache_integration.py
```

### æ—¥å¿—éªŒè¯
```bash
# å¯åŠ¨åº”ç”¨
python web_app.py

# è§‚å¯Ÿæ—¥å¿—è¾“å‡º
# ç¡®è®¤æ—¥å¿—åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆkey, patternç­‰ï¼‰
# ç¡®è®¤å¼‚å¸¸æ—¥å¿—åŒ…å«å †æ ˆè·Ÿè¸ªï¼ˆexc_info=Trueï¼‰
```

### åŠŸèƒ½éªŒè¯
```bash
# 1. ç¼“å­˜è¯»å†™
curl http://127.0.0.1:5001/api/games
curl http://127.0.0.1:5001/admin/cache/stats

# 2. ç¼“å­˜å¤±æ•ˆ
curl -X POST http://127.0.0.1:5001/admin/cache/clear

# 3. ç›‘æ§æ•°æ®
curl http://127.0.0.1:5001/admin/cache/performance
```

---

## ä¿®å¤æ—¶é—´ä¼°ç®—

| ä¼˜å…ˆçº§ | é—®é¢˜æ•° | é¢„è®¡æ—¶é—´ | å®Œæˆæ—¥æœŸ |
|--------|--------|---------|---------|
| P0 | 1 | 5åˆ†é’Ÿ | 2026-02-24 |
| P1 | 3 | 40åˆ†é’Ÿ | 2026-02-24 |
| P2 | 4 | 5å°æ—¶ | 2026-03-10 |
| P3 | 3 | 3å°æ—¶ | 2026-03-17 |
| **æ€»è®¡** | **11** | **~10å°æ—¶** | **2026-03-17** |

---

## è¿›åº¦è·Ÿè¸ª

### P0 - ç«‹å³ä¿®å¤
- [ ] tests/test_capacity_monitor.py:177 ç©ºexceptå—

### P1 - æœ¬å‘¨ä¿®å¤
- [ ] __init__.py æ¨¡å—æ–‡æ¡£
- [ ] cache_hierarchical.py å¼‚å¸¸å¤„ç†
- [ ] cache_system.py æ—¥å¿—ä¸Šä¸‹æ–‡

### P2 - 2å‘¨å†…ä¿®å¤
- [ ] monitoring.py:345 L2å†…å­˜ä½¿ç”¨ç‡
- [ ] intelligent_warmer.py:185 é¢„æµ‹å‡†ç¡®ç‡
- [ ] monitoring.py:516 æ™ºèƒ½é¢„çƒ­è”åŠ¨
- [ ] intelligent_warmer.py:295 set_raw()æ–¹æ³•

### P3 - ä¸­æœŸä¼˜åŒ–
- [ ] cache_hierarchical.py:_match_pattern é‡æ„
- [ ] monitoring.py:_check_alert_rules é‡æ„
- [ ] cache_system.py:cached é‡æ„

---

**æœ€åæ›´æ–°**: 2026-02-24
**ç»´æŠ¤äººå‘˜**: Event2Table Development Team
