# ç¼“å­˜ç³»ç»Ÿå®‰å…¨ä»£ç å®¡è®¡æŠ¥å‘Š

> **å®¡è®¡æ—¥æœŸ**: 2026-02-24
> **å®¡è®¡èŒƒå›´**: `backend/core/cache/` æ‰€æœ‰æ¨¡å—
> **å®¡è®¡å‘˜**: Claude Code Security Audit
> **ä¸¥é‡ç¨‹åº¦**: P0 (å…³é”®) â†’ P1 (é«˜) â†’ P2 (ä¸­) â†’ P3 (ä½)

---

## æ‰§è¡Œæ‘˜è¦

æœ¬æ¬¡å®‰å…¨å®¡è®¡é’ˆå¯¹Event2Tableé¡¹ç›®çš„ç¼“å­˜ç³»ç»Ÿè¿›è¡Œäº†å…¨é¢çš„å®‰å…¨æ£€æŸ¥ï¼Œæ¶µç›–äº†16ä¸ªPythonæ¨¡å—ã€‚å®¡è®¡å‘ç°äº†**12ä¸ªå®‰å…¨é—®é¢˜**ï¼Œå…¶ä¸­åŒ…æ‹¬ï¼š

- **P0 (å…³é”®)**: 2ä¸ª - éœ€è¦ç«‹å³ä¿®å¤
- **P1 (é«˜å±)**: 4ä¸ª - éœ€è¦å°½å¿«ä¿®å¤
- **P2 (ä¸­å±)**: 4ä¸ª - åº”è¯¥ä¿®å¤
- **P3 (ä½å±)**: 2ä¸ª - å»ºè®®ä¿®å¤

### å®¡è®¡èŒƒå›´

| æ¨¡å— | æ–‡ä»¶ | è¡Œæ•° | çŠ¶æ€ |
|------|------|------|------|
| åˆ†å±‚ç¼“å­˜ | `cache_hierarchical.py` | 585 | âœ… é€šè¿‡ |
| ç¼“å­˜å¤±æ•ˆ | `invalidator.py` | 467 | âš ï¸ å‘ç°é—®é¢˜ |
| ç¼“å­˜è£…é¥°å™¨ | `decorators.py` | 196 | âš ï¸ å‘ç°é—®é¢˜ |
| ç¼“å­˜é˜²æŠ¤ | `protection.py` | 424 | âš ï¸ å‘ç°é—®é¢˜ |
| ç¼“å­˜ç³»ç»Ÿ | `cache_system.py` | 800+ | âš ï¸ å‘ç°é—®é¢˜ |
| å¸ƒéš†è¿‡æ»¤å™¨ | `bloom_filter_enhanced.py` | 629 | âš ï¸ å‘ç°é—®é¢˜ |
| ç›‘æ§ç³»ç»Ÿ | `monitoring.py` | 600+ | âš ï¸ å‘ç°é—®é¢˜ |
| å®¹é‡ç›‘æ§ | `capacity_monitor.py` | 500+ | âš ï¸ å‘ç°é—®é¢˜ |
| é™çº§ç­–ç•¥ | `degradation.py` | 200+ | âœ… é€šè¿‡ |
| ä¸€è‡´æ€§ | `consistency.py` | 150+ | âœ… é€šè¿‡ |
| ç»Ÿè®¡æ¨¡å— | `statistics.py` | 400+ | âœ… é€šè¿‡ |

---

## P0 - å…³é”®å®‰å…¨é—®é¢˜ (éœ€è¦ç«‹å³ä¿®å¤)

### P0-1: ç¼“å­˜é”®æ³¨å…¥æ¼æ´ âš ï¸ **æå…¶å±é™©**

**ä¸¥é‡ç¨‹åº¦**: P0 (å…³é”®)
**å½±å“æ¨¡å—**: `cache_system.py`, `cache_hierarchical.py`, `invalidator.py`
**CVSSè¯„åˆ†**: 8.5 (High)

#### é—®é¢˜æè¿°

ç¼“å­˜é”®æ„å»ºå­˜åœ¨**å­—ç¬¦ä¸²æ‹¼æ¥æ³¨å…¥æ¼æ´**ï¼Œæ”»å‡»è€…å¯ä»¥é€šè¿‡æ§åˆ¶ç¼“å­˜é”®å‚æ•°æ³¨å…¥æ¶æ„å­—ç¬¦ã€‚

#### æ¼æ´ä»£ç 

**ä½ç½®**: `cache_system.py` Line 64-87

```python
@classmethod
def build(cls, pattern: str, **kwargs) -> str:
    """æ„å»ºæ ‡å‡†åŒ–ç¼“å­˜é”®"""
    if not kwargs:
        return f"{cls.PREFIX}{pattern}"

    # âš ï¸ å±é™©: ç›´æ¥æ‹¼æ¥ç”¨æˆ·è¾“å…¥ï¼Œæ²¡æœ‰éªŒè¯
    sorted_params = sorted(kwargs.items())
    param_str = ":".join(f"{k}:{v}" for k, v in sorted_params)
    return f"{cls.PREFIX}{pattern}:{param_str}"
```

**ä½ç½®**: `cache_hierarchical.py` Line 122

```python
def get(self, pattern: str, **kwargs) -> Optional[Any]:
    # âš ï¸ å±é™©: patternå‚æ•°ç›´æ¥æ‹¼æ¥ï¼Œæ²¡æœ‰éªŒè¯
    key = CacheKeyBuilder.build(pattern, **kwargs)
```

**ä½ç½®**: `invalidator.py` Line 51-68

```python
def invalidate_key(self, pattern: str, **kwargs) -> bool:
    try:
        # âš ï¸ å±é™©: patternå’Œkwargsæ²¡æœ‰éªŒè¯
        self.cache.delete(pattern, **kwargs)
        logger.debug(f"ç¼“å­˜å¤±æ•ˆ: {pattern} {kwargs}")
        return True
    except Exception as e:
        logger.error(f"ç¼“å­˜å¤±æ•ˆå¤±è´¥: {e}")
        return False
```

#### æ”»å‡»åœºæ™¯

```python
# åœºæ™¯1: Rediså‘½ä»¤æ³¨å…¥
# æ”»å‡»è€…æ„é€ æ¶æ„game_gidå‚æ•°
malicious_gid = "12345:*\r\nDEL user:session:*"

# ç»“æœç¼“å­˜é”®:
# dwd_gen:v3:events.list:game_gid:12345:*\r\nDEL user:session:*
# å¦‚æœRedisæ”¯æŒEVALæˆ–Luaï¼Œå¯èƒ½æ‰§è¡Œæ¶æ„å‘½ä»¤

# åœºæ™¯2: è·¯å¾„éå†æ”»å‡»
malicious_pattern = "../../../etc/passwd"
key = CacheKeyBuilder.build(malicious_pattern, game_id=1)
# ç»“æœ: dwd_gen:v3:../../../etc/passwd:game_id:1
# å¯èƒ½ç”¨äºæ–‡ä»¶æ“ä½œæ—¶è§¦å‘è·¯å¾„éå†

# åœºæ™¯3: æ—¥å¿—æ³¨å…¥æ”»å‡»
malicious_gid = "1\r\n[ERROR] Malicious activity detected!"
logger.info(f"ç¼“å­˜å¤±æ•ˆ: {pattern} {malicious_gid}")
# æ—¥å¿—ä¸­ä¼šæ³¨å…¥è™šå‡çš„é”™è¯¯æ¶ˆæ¯ï¼Œå¯èƒ½è¯¯å¯¼å®‰å…¨å®¡è®¡
```

#### å½±å“èŒƒå›´

1. **Rediså‘½ä»¤æ³¨å…¥**: å¦‚æœä½¿ç”¨Redis KEYS/DELå‘½ä»¤ï¼Œå¯èƒ½æ³¨å…¥æ¶æ„é€šé…ç¬¦
2. **æ—¥å¿—æ³¨å…¥æ”»å‡»**: æ¶æ„ç¼“å­˜é”®ä¼šæ±¡æŸ“æ—¥å¿—ï¼Œè¯¯å¯¼å®‰å…¨å®¡è®¡
3. **ç¼“å­˜æŠ•æ¯’**: æ”»å‡»è€…å¯ä»¥æ„é€ ç‰¹æ®Šé”®è¦†ç›–é¢„æœŸç¼“å­˜
4. **DoSæ”»å‡»**: æ³¨å…¥å¤§é‡é€šé…ç¬¦å¯¼è‡´Redisæ€§èƒ½ä¸‹é™

#### ä¿®å¤å»ºè®®

**ç«‹å³ä¿®å¤æ–¹æ¡ˆ**:

```python
# backend/core/security/cache_key_validator.py (æ–°æ–‡ä»¶)
from typing import Dict, Any
import re
import logging

logger = logging.getLogger(__name__)

# å…è®¸çš„å‚æ•°åç™½åå•
ALLOWED_PARAM_NAMES = {
    'game_gid', 'event_id', 'param_id', 'category_id',
    'template_id', 'node_id', 'flow_id', 'config_id',
    'page', 'per_page', 'sort_by', 'order', 'id', 'gid'
}

# å…è®¸çš„ç¼“å­˜æ¨¡å¼ç™½åå•
ALLOWED_PATTERNS = {
    'games.detail', 'games.list',
    'events.detail', 'events.list',
    'params.detail', 'params.list',
    'categories.detail', 'categories.list',
    'templates.detail', 'templates.list',
    'nodes.detail', 'nodes.list', 'nodes.config',
    'flows.detail', 'flows.list', 'flows.templates',
    'hql.history', 'join_configs.detail', 'join_configs.list'
}

# å‚æ•°å€¼éªŒè¯è§„åˆ™ (åªå…è®¸æ•°å­—å’Œç®€å•å­—ç¬¦ä¸²)
VALUE_PATTERN = re.compile(r'^[\w\-\.]+$')

class CacheKeyValidator:
    """ç¼“å­˜é”®éªŒè¯å™¨"""

    @staticmethod
    def validate_pattern(pattern: str) -> str:
        """éªŒè¯ç¼“å­˜æ¨¡å¼"""
        if pattern not in ALLOWED_PATTERNS:
            logger.warning(f"éæ³•ç¼“å­˜æ¨¡å¼: {pattern}")
            raise ValueError(f"Invalid cache pattern: {pattern}")
        return pattern

    @staticmethod
    def validate_params(kwargs: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å‚æ•°"""
        validated = {}

        for key, value in kwargs.items():
            # 1. éªŒè¯å‚æ•°å
            if key not in ALLOWED_PARAM_NAMES:
                logger.warning(f"éæ³•å‚æ•°å: {key}")
                raise ValueError(f"Invalid parameter name: {key}")

            # 2. éªŒè¯å‚æ•°å€¼
            if value is None:
                continue

            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶éªŒè¯
            str_value = str(value)
            if not VALUE_PATTERN.match(str_value):
                logger.warning(f"éæ³•å‚æ•°å€¼: {key}={value}")
                raise ValueError(f"Invalid parameter value: {key}={value}")

            validated[key] = str_value

        return validated

    @staticmethod
    def validate_and_build(pattern: str, **kwargs) -> str:
        """éªŒè¯å¹¶æ„å»ºå®‰å…¨çš„ç¼“å­˜é”®"""
        # éªŒè¯æ¨¡å¼
        validated_pattern = CacheKeyValidator.validate_pattern(pattern)

        # éªŒè¯å‚æ•°
        validated_params = CacheKeyValidator.validate_params(kwargs)

        # æ„å»ºç¼“å­˜é”®
        from backend.core.cache.cache_system import CacheKeyBuilder
        return CacheKeyBuilder.build(validated_pattern, **validated_params)
```

**ä¿®æ”¹ `cache_system.py`**:

```python
# åœ¨CacheKeyBuilder.buildæ–¹æ³•ä¸­æ·»åŠ éªŒè¯
@classmethod
def build(cls, pattern: str, **kwargs) -> str:
    """æ„å»ºæ ‡å‡†åŒ–ç¼“å­˜é”®"""
    # âœ… æ·»åŠ å®‰å…¨éªŒè¯
    try:
        from backend.core.security.cache_key_validator import CacheKeyValidator
        pattern, kwargs = CacheKeyValidator.validate_and_build(pattern, **kwargs)
    except ImportError:
        # å¦‚æœéªŒè¯å™¨ä¸å¯ç”¨ï¼Œè‡³å°‘åšåŸºæœ¬éªŒè¯
        if not isinstance(pattern, str):
            raise TypeError("pattern must be a string")

        # åŸºæœ¬å­—ç¬¦è¿‡æ»¤
        if not re.match(r'^[\w\.]+$', pattern):
            raise ValueError(f"Invalid pattern: {pattern}")

    if not kwargs:
        return f"{cls.PREFIX}{pattern}"

    sorted_params = sorted(kwargs.items())
    param_str = ":".join(f"{k}:{v}" for k, v in sorted_params)
    return f"{cls.PREFIX}{pattern}:{param_str}"
```

**ä¿®æ”¹ `invalidator.py`**:

```python
def invalidate_key(self, pattern: str, **kwargs) -> bool:
    """ç²¾ç¡®å¤±æ•ˆå•ä¸ªç¼“å­˜é”®"""
    try:
        # âœ… æ·»åŠ éªŒè¯
        from backend.core.security.cache_key_validator import CacheKeyValidator
        validated_pattern, validated_kwargs = CacheKeyValidator.validate_and_build(
            pattern, **kwargs
        )

        self.cache.delete(validated_pattern, **validated_kwargs)
        logger.debug(f"ç¼“å­˜å¤±æ•ˆ: {validated_pattern} {validated_kwargs}")
        return True
    except ValueError as e:
        logger.warning(f"ç¼“å­˜å¤±æ•ˆå¤±è´¥: å‚æ•°éªŒè¯é”™è¯¯ - {e}")
        return False
    except Exception as e:
        logger.error(f"ç¼“å­˜å¤±æ•ˆå¤±è´¥: {e}")
        return False
```

#### ä¿®å¤éªŒè¯

```python
# æµ‹è¯•ç”¨ä¾‹
def test_cache_key_injection_protection():
    """æµ‹è¯•ç¼“å­˜é”®æ³¨å…¥é˜²æŠ¤"""

    # æµ‹è¯•1: Rediså‘½ä»¤æ³¨å…¥é˜²æŠ¤
    with pytest.raises(ValueError):
        CacheKeyValidator.validate_params({
            'game_gid': "12345:*\r\nDEL user:session:*"
        })

    # æµ‹è¯•2: è·¯å¾„éå†é˜²æŠ¤
    with pytest.raises(ValueError):
        CacheKeyValidator.validate_pattern("../../../etc/passwd")

    # æµ‹è¯•3: æ—¥å¿—æ³¨å…¥é˜²æŠ¤
    with pytest.raises(ValueError):
        CacheKeyValidator.validate_params({
            'game_gid': "1\r\n[ERROR] Malicious!"
        })

    # æµ‹è¯•4: æ­£å¸¸å‚æ•°åº”è¯¥é€šè¿‡
    validated = CacheKeyValidator.validate_params({
        'game_gid': '10000147',
        'page': '1'
    })
    assert validated == {'game_gid': '10000147', 'page': '1'}

    print("âœ… æ‰€æœ‰ç¼“å­˜é”®æ³¨å…¥é˜²æŠ¤æµ‹è¯•é€šè¿‡")
```

---

### P0-2: æ•æ„Ÿä¿¡æ¯æ³„éœ²åˆ°æ—¥å¿— âš ï¸ **æå…¶å±é™©**

**ä¸¥é‡ç¨‹åº¦**: P0 (å…³é”®)
**å½±å“æ¨¡å—**: `invalidator.py`, `cache_hierarchical.py`, `decorators.py`
**CVSSè¯„åˆ†**: 8.2 (High)

#### é—®é¢˜æè¿°

å¤šä¸ªæ¨¡å—å°†**å®Œæ•´çš„ç¼“å­˜æ•°æ®**è®°å½•åˆ°æ—¥å¿—ä¸­ï¼Œå¯èƒ½å¯¼è‡´æ•æ„Ÿä¿¡æ¯æ³„éœ²ã€‚

#### æ¼æ´ä»£ç 

**ä½ç½®**: `invalidator.py` Line 64, 94, 126, 193, 244, 298

```python
# âš ï¸ å±é™©: kwargså¯èƒ½åŒ…å«æ•æ„Ÿæ•°æ®ï¼Œç›´æ¥è®°å½•åˆ°æ—¥å¿—
logger.debug(f"ç¼“å­˜å¤±æ•ˆ: {pattern} {kwargs}")
logger.info(f"æ¨¡å¼å¤±æ•ˆ: {pattern} {kwargs} (L1={l1_count}, L2={l2_count})")
logger.info(f"æ¸¸æˆå…³è”å¤±æ•ˆ: game_gid={game_gid}, {len(invalidated_keys)}ä¸ªé”®")
```

**ä½ç½®**: `decorators.py` Line 54, 63

```python
# âš ï¸ å±é™©: cached_valueå¯èƒ½åŒ…å«æ•æ„Ÿç”¨æˆ·æ•°æ®
logger.debug(f"ç¼“å­˜å‘½ä¸­: {cache_key}")
logger.debug(f"å·²ç¼“å­˜: {cache_key}")
```

**ä½ç½®**: `cache_hierarchical.py` Line 172, 198, 211

```python
# âš ï¸ å±é™©: cached_dataå¯èƒ½åŒ…å«æ•æ„Ÿæ•°æ®
logger.debug(f"âœ… L1 HIT: {key}")
logger.debug(f"âœ… L2 HIT â†’ L1å›å¡«: {key}")
logger.debug(f"âŒ CACHE MISS: {key}")
```

#### æ•æ„Ÿä¿¡æ¯ç±»å‹

1. **æ¸¸æˆæ•°æ®**: æ¸¸æˆé…ç½®ã€APIå¯†é’¥ã€æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
2. **ç”¨æˆ·æ•°æ®**: ç”¨æˆ·IDã€ä¼šè¯ä»¤ç‰Œã€æƒé™ä¿¡æ¯
3. **ä¸šåŠ¡æ•°æ®**: äº‹ä»¶å‚æ•°ã€HQLæŸ¥è¯¢ã€æ¨¡æ¿é…ç½®
4. **ç³»ç»Ÿæ•°æ®**: ç¼“å­˜é”®ã€å†…éƒ¨ç»“æ„ã€ç»Ÿè®¡ä¿¡æ¯

#### æ”»å‡»åœºæ™¯

```python
# åœºæ™¯1: æ—¥å¿—æ–‡ä»¶æ³„éœ²å¯¼è‡´æ•æ„Ÿä¿¡æ¯æš´éœ²
# å¦‚æœæ—¥å¿—æ–‡ä»¶æƒé™ä¸å½“æˆ–è¢«ä¸Šä¼ åˆ°é”™è¯¯ä½ç½®
# æ”»å‡»è€…å¯ä»¥è·å–æ‰€æœ‰ç¼“å­˜æ•°æ®

# åœºæ™¯2: æ—¥å¿—èšåˆå¹³å°æ³„éœ²
# å¦‚æœæ—¥å¿—è¢«å‘é€åˆ°ç¬¬ä¸‰æ–¹æ—¥å¿—æœåŠ¡(Sentry, Logstashç­‰)
# æ•æ„Ÿæ•°æ®ä¼šç¦»å¼€å—æ§ç¯å¢ƒ

# åœºæ™¯3: è°ƒè¯•ä¿¡æ¯æ³„éœ²
# å¼€å‘ç¯å¢ƒå¼€å¯DEBUGçº§åˆ«æ—¥å¿—
# ç”Ÿäº§ç¯å¢ƒæ„å¤–å¼€å¯DEBUGå¯¼è‡´æ•æ„Ÿä¿¡æ¯æ³„éœ²
```

#### ä¿®å¤å»ºè®®

**åˆ›å»ºæ•æ„Ÿæ•°æ®è¿‡æ»¤å™¨**:

```python
# backend/core/security/sensitive_data_filter.py (æ–°æ–‡ä»¶)
import re
import logging
from typing import Any, Dict, Set

class SensitiveDataFilter:
    """æ•æ„Ÿæ•°æ®è¿‡æ»¤å™¨"""

    # æ•æ„Ÿå­—æ®µååˆ—è¡¨
    SENSITIVE_FIELDS = {
        'password', 'passwd', 'secret', 'token', 'key', 'session',
        'api_key', 'apikey', 'auth', 'credential', 'private',
        'connection_string', 'database_url', 'redis_url'
    }

    # æ•æ„Ÿç¼“å­˜æ¨¡å¼
    SENSITIVE_PATTERNS = {
        'nodes.config',  # å¯èƒ½åŒ…å«è¿æ¥å­—ç¬¦ä¸²
        'games.detail',  # å¯èƒ½åŒ…å«APIå¯†é’¥
    }

    @staticmethod
    def sanitize_dict(data: Dict[str, Any], max_length: int = 100) -> Dict[str, Any]:
        """æ¸…ç†å­—å…¸ä¸­çš„æ•æ„Ÿæ•°æ®"""
        sanitized = {}

        for key, value in data.items():
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ•æ„Ÿå­—æ®µ
            if any(sensitive in key.lower() for sensitive in SensitiveDataFilter.SENSITIVE_FIELDS):
                sanitized[key] = "***REDACTED***"
            elif isinstance(value, str) and len(value) > max_length:
                # æˆªæ–­é•¿å­—ç¬¦ä¸²
                sanitized[key] = value[:max_length] + "... (truncated)"
            elif isinstance(value, dict):
                # é€’å½’æ¸…ç†åµŒå¥—å­—å…¸
                sanitized[key] = SensitiveDataFilter.sanitize_dict(value, max_length)
            else:
                sanitized[key] = value

        return sanitized

    @staticmethod
    def sanitize_log_message(message: str) -> str:
        """æ¸…ç†æ—¥å¿—æ¶ˆæ¯ä¸­çš„æ•æ„Ÿæ•°æ®"""
        # ç§»é™¤å¯èƒ½çš„ä»¤ç‰Œ
        message = re.sub(r'token=[\w\-]+', 'token=***REDACTED***', message)
        message = re.sub(r'key=[\w\-]+', 'key=***REDACTED***', message)
        message = re.sub(r'secret=[\w\-]+', 'secret=***REDACTED***', message)

        return message

class SafeLoggerAdapter(logging.LoggerAdapter):
    """å®‰å…¨çš„æ—¥å¿—é€‚é…å™¨ï¼Œè‡ªåŠ¨è¿‡æ»¤æ•æ„Ÿä¿¡æ¯"""

    def process(self, msg: Any, kwargs: Dict[str, Any]) -> tuple:
        """å¤„ç†æ—¥å¿—æ¶ˆæ¯"""
        if isinstance(msg, str):
            msg = SensitiveDataFilter.sanitize_log_message(msg)

        return msg, kwargs
```

**ä¿®æ”¹ `invalidator.py`**:

```python
from backend.core.security.sensitive_data_filter import SafeLoggerAdapter

# ä½¿ç”¨å®‰å…¨çš„æ—¥å¿—è®°å½•å™¨
logger = SafeLoggerAdapter(logging.getLogger(__name__), {})

def invalidate_key(self, pattern: str, **kwargs) -> bool:
    """ç²¾ç¡®å¤±æ•ˆå•ä¸ªç¼“å­˜é”®"""
    try:
        self.cache.delete(pattern, **kwargs)
        # âœ… å®‰å…¨: æ—¥å¿—é€‚é…å™¨ä¼šè‡ªåŠ¨è¿‡æ»¤æ•æ„Ÿä¿¡æ¯
        logger.debug(f"ç¼“å­˜å¤±æ•ˆ: {pattern} {kwargs}")
        return True
    except Exception as e:
        # âœ… å®‰å…¨: ä¸è®°å½•å®Œæ•´çš„å¼‚å¸¸å †æ ˆ
        logger.error(f"ç¼“å­˜å¤±æ•ˆå¤±è´¥")
        return False
```

**ä¿®æ”¹ `decorators.py`**:

```python
from backend.core.security.sensitive_data_filter import SafeLoggerAdapter

logger = SafeLoggerAdapter(logging.getLogger(__name__), {})

def decorator(func: Callable) -> Callable:
    @wraps(func)
    def wrapper(*args, **kwargs):
        cache_key = _build_cache_key(key_template, key_params, args, kwargs, func)

        cached_value = _cache.get(cache_key)
        if cached_value is not None:
            # âœ… å®‰å…¨: åªè®°å½•é”®ï¼Œä¸è®°å½•å€¼
            logger.debug(f"ç¼“å­˜å‘½ä¸­: {cache_key}")
            return cached_value

        result = func(*args, **kwargs)

        if result is not None:
            _cache.set(cache_key, result, ttl_l1=ttl_l1, ttl_l2=ttl_l2)
            # âœ… å®‰å…¨: åªè®°å½•é”®ï¼Œä¸è®°å½•å€¼
            logger.debug(f"å·²ç¼“å­˜: {cache_key}")

        return result

    return wrapper
```

#### æ—¥å¿—é…ç½®å»ºè®®

```python
# backend/core/config/logging_config.py
import logging
from logging.handlers import RotatingFileHandler

# ç”Ÿäº§ç¯å¢ƒæ—¥å¿—çº§åˆ«åº”è¯¥æ˜¯INFOæˆ–WARNING
PRODUCTION_LOG_LEVEL = logging.INFO

# æ•æ„Ÿæ“ä½œåº”è¯¥ä½¿ç”¨WARNINGçº§åˆ«
SENSITIVE_OPERATIONS = [
    'cache.delete',
    'cache.invalidate',
    'user.login',
    'data.export'
]

def configure_logging():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""

    # 1. è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.basicConfig(
        level=PRODUCTION_LOG_LEVEL,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # 2. é™åˆ¶æ—¥å¿—æ–‡ä»¶å¤§å°
    file_handler = RotatingFileHandler(
        'logs/app.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
    file_handler.setLevel(PRODUCTION_LOG_LEVEL)

    # 3. ä¸è¦åœ¨ç”Ÿäº§ç¯å¢ƒè®°å½•DEBUGæ—¥å¿—
    if os.environ.get('FLASK_ENV') == 'production':
        logging.getLogger('backend.core.cache').setLevel(logging.WARNING)

    # 4. ä½¿ç”¨å®‰å…¨çš„æ—¥å¿—æ ¼å¼ï¼ˆä¸è®°å½•å®Œæ•´å †æ ˆï¼‰
    logging.basicConfig(
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        # ä¸è¦ä½¿ç”¨: format='... %(exc_info)s ...' (ä¼šè®°å½•å®Œæ•´å †æ ˆ)
    )
```

---

## P1 - é«˜å±å®‰å…¨é—®é¢˜ (éœ€è¦å°½å¿«ä¿®å¤)

### P1-1: å¸ƒéš†è¿‡æ»¤å™¨æŒä¹…åŒ–è·¯å¾„éå†æ¼æ´

**ä¸¥é‡ç¨‹åº¦**: P1 (é«˜å±)
**å½±å“æ¨¡å—**: `bloom_filter_enhanced.py`
**CVSSè¯„åˆ†**: 7.5 (High)

#### é—®é¢˜æè¿°

å¸ƒéš†è¿‡æ»¤å™¨çš„æŒä¹…åŒ–è·¯å¾„å¯ä»¥**é€šè¿‡æ„é€ æ¶æ„persistence_pathå‚æ•°å†™å…¥ä»»æ„æ–‡ä»¶**ã€‚

#### æ¼æ´ä»£ç 

**ä½ç½®**: `bloom_filter_enhanced.py` Line 77, 131-150

```python
def __init__(
    self,
    capacity: int = DEFAULT_CAPACITY,
    error_rate: float = DEFAULT_ERROR_RATE,
    persistence_path: Optional[str] = None,  # âš ï¸ å±é™©: æœªéªŒè¯è·¯å¾„
    ...
):
    # âš ï¸ å±é™©: ç›´æ¥ä½¿ç”¨ç”¨æˆ·æä¾›çš„è·¯å¾„
    self.persistence_path = persistence_path or self.PERSISTENCE_PATH

def _load_from_disk(self) -> Optional[ScalableBloomFilter]:
    if not os.path.exists(self.persistence_path):
        return None

    try:
        # âš ï¸ å±é™©: æ‰“å¼€ä»»æ„è·¯å¾„æ–‡ä»¶
        with open(self.persistence_path, 'rb') as f:
            bloom_filter = pickle.load(f)
```

#### æ”»å‡»åœºæ™¯

```python
# åœºæ™¯1: è·¯å¾„éå†æ”»å‡»
bloom = EnhancedBloomFilter(
    persistence_path="../../../../etc/passwd"
)
# å°è¯•è¯»å–ç³»ç»Ÿæ–‡ä»¶

# åœºæ™¯2: ä»»æ„æ–‡ä»¶å†™å…¥
bloom = EnhancedBloomFilter(
    persistence_path="../../../../var/www/html/shell.php"
)
# ä¸‹æ¬¡æŒä¹…åŒ–æ—¶å†™å…¥æ¶æ„æ–‡ä»¶

# åœºæ™¯3: ååºåˆ—åŒ–æ¼æ´
# å¦‚æœæ”»å‡»è€…å¯ä»¥æ§åˆ¶persistence_pathæŒ‡å‘æ¶æ„pickleæ–‡ä»¶
# ååºåˆ—åŒ–æ—¶ä¼šæ‰§è¡Œä»»æ„ä»£ç 
```

#### ä¿®å¤å»ºè®®

```python
# backend/core/security/path_validator.py (æ–°æ–‡ä»¶)
import os
import re
from pathlib import Path
from typing import Optional

class PathValidator:
    """è·¯å¾„éªŒè¯å™¨"""

    # å…è®¸çš„åŸºç¡€ç›®å½•
    ALLOWED_BASE_DIRS = [
        '/Users/mckenzie/Documents/event2table/data',
        '/var/lib/event2table/data',
        '/tmp/event2table'
    ]

    # å…è®¸çš„æ–‡ä»¶åæ¨¡å¼
    ALLOWED_FILENAME_PATTERN = re.compile(r'^[\w\-\.]+$')

    @staticmethod
    def validate_persistence_path(
        user_path: Optional[str],
        default_path: str = "data/bloom_filter.pkl"
    ) -> str:
        """éªŒè¯æŒä¹…åŒ–è·¯å¾„"""

        # å¦‚æœç”¨æˆ·æ²¡æœ‰æä¾›è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if user_path is None:
            return default_path

        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        abs_path = os.path.abspath(user_path)

        # æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•ä¸‹
        is_allowed = any(
            abs_path.startswith(allowed_dir)
            for allowed_dir in PathValidator.ALLOWED_BASE_DIRS
        )

        if not is_allowed:
            raise ValueError(
                f"Path must be under allowed directories: "
                f"{PathValidator.ALLOWED_BASE_DIRS}"
            )

        # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åˆæ³•
        filename = os.path.basename(abs_path)
        if not PathValidator.ALLOWED_FILENAME_PATTERN.match(filename):
            raise ValueError(
                f"Invalid filename: {filename}. "
                f"Only alphanumeric, dash, dot, underscore allowed"
            )

        # ç¡®ä¿æ–‡ä»¶æ‰©å±•åæ˜¯.pkl
        if not abs_path.endswith('.pkl'):
            raise ValueError("Persistence file must have .pkl extension")

        return abs_path

    @staticmethod
    def safe_open(path: str, mode: str = 'rb'):
        """å®‰å…¨æ‰“å¼€æ–‡ä»¶"""
        # å†æ¬¡éªŒè¯è·¯å¾„
        validated_path = PathValidator.validate_persistence_path(path)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(validated_path), exist_ok=True)

        return open(validated_path, mode)
```

**ä¿®æ”¹ `bloom_filter_enhanced.py`**:

```python
def __init__(
    self,
    capacity: int = DEFAULT_CAPACITY,
    error_rate: float = DEFAULT_ERROR_RATE,
    persistence_path: Optional[str] = None,
    ...
):
    # âœ… éªŒè¯æŒä¹…åŒ–è·¯å¾„
    from backend.core.security.path_validator import PathValidator

    try:
        validated_path = PathValidator.validate_persistence_path(
            persistence_path,
            self.PERSISTENCE_PATH
        )
    except ValueError as e:
        logger.error(f"Invalid persistence path: {e}")
        validated_path = self.PERSISTENCE_PATH  # ä½¿ç”¨é»˜è®¤è·¯å¾„

    self.persistence_path = validated_path
    # ... å…¶ä½™ä»£ç 
```

---

### P1-2: Pickleååºåˆ—åŒ–ä»£ç æ‰§è¡Œæ¼æ´

**ä¸¥é‡ç¨‹åº¦**: P1 (é«˜å±)
**å½±å“æ¨¡å—**: `bloom_filter_enhanced.py`
**CVSSè¯„åˆ†**: 8.8 (High)

#### é—®é¢˜æè¿°

ä½¿ç”¨`pickle.load()`ååºåˆ—åŒ–å¸ƒéš†è¿‡æ»¤å™¨æ•°æ®ï¼Œ**å¯èƒ½å¯¼è‡´ä»»æ„ä»£ç æ‰§è¡Œ**ã€‚

#### æ¼æ´ä»£ç 

**ä½ç½®**: `bloom_filter_enhanced.py` Line 134-150

```python
def _load_from_disk(self) -> Optional[ScalableBloomFilter]:
    if not os.path.exists(self.persistence_path):
        return None

    try:
        # âš ï¸ å±é™©: pickleååºåˆ—åŒ–å¯èƒ½æ‰§è¡Œä»»æ„ä»£ç 
        with open(self.persistence_path, 'rb') as f:
            bloom_filter = pickle.load(f)
```

#### æ”»å‡»åœºæ™¯

```python
import pickle

# æ„é€ æ¶æ„pickleè½½è·
class MaliciousCode:
    def __reduce__(self):
        # ååºåˆ—åŒ–æ—¶æ‰§è¡Œä»»æ„å‘½ä»¤
        return (__import__('os').system, ('rm -rf /',))

# ä¿å­˜æ¶æ„pickle
with open('malicious_bloom_filter.pkl', 'wb') as f:
    pickle.dump(MaliciousCode(), f)

# å½“åº”ç”¨åŠ è½½è¿™ä¸ªæ–‡ä»¶æ—¶...
bloom = EnhancedBloomFilter(
    persistence_path='malicious_bloom_filter.pkl'
)
# ğŸ’¥ ç³»ç»Ÿå‘½ä»¤è¢«æ‰§è¡Œï¼
```

#### ä¿®å¤å»ºè®®

**æ–¹æ¡ˆ1: ä½¿ç”¨JSONæ›¿ä»£Pickle (æ¨è)**

```python
import json
from pybloom_live import ScalableBloomFilter

def _save_to_disk_json(self):
    """ä½¿ç”¨JSONåºåˆ—åŒ–ä¿å­˜å¸ƒéš†è¿‡æ»¤å™¨"""
    try:
        # è·å–å¸ƒéš†è¿‡æ»¤å™¨çš„å†…éƒ¨çŠ¶æ€
        bloom_state = {
            'capacity': self.bloom_filter.capacity,
            'error_rate': self.bloom_filter.error_rate,
            # æ³¨æ„: ScalableBloomFilterå¯èƒ½æ²¡æœ‰ç›´æ¥å¯¼å‡ºbitarrayçš„æ–¹æ³•
            # éœ€è¦æŸ¥çœ‹pybloom_liveçš„API
        }

        with PathValidator.safe_open(self.persistence_path, 'w') as f:
            json.dump(bloom_state, f)

        logger.info(f"Saved bloom filter to {self.persistence_path}")

    except Exception as e:
        logger.error(f"Failed to save bloom filter: {e}")
```

**æ–¹æ¡ˆ2: ä½¿ç”¨HMACéªŒè¯Pickleæ–‡ä»¶**

```python
import hmac
import hashlib

class SecureBloomFilterLoader:
    """å®‰å…¨çš„å¸ƒéš†è¿‡æ»¤å™¨åŠ è½½å™¨"""

    # å¯†é’¥åº”è¯¥ä»ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†ç³»ç»Ÿè·å–
    SECRET_KEY = os.environ.get('BLOOM_FILTER_HMAC_KEY', 'CHANGE_ME')

    @staticmethod
    def save_with_signature(data: bytes, path: str):
        """ä¿å­˜æ•°æ®å¹¶æ·»åŠ HMACç­¾å"""
        # è®¡ç®—HMAC
        signature = hmac.new(
            SecureBloomFilterLoader.SECRET_KEY.encode(),
            data,
            hashlib.sha256
        ).digest()

        # ä¿å­˜ç­¾å+æ•°æ®
        with open(path, 'wb') as f:
            f.write(signature + data)

    @staticmethod
    def load_with_signature(path: str):
        """åŠ è½½å¹¶éªŒè¯HMACç­¾å"""
        with open(path, 'rb') as f:
            data = f.read()

        # åˆ†ç¦»ç­¾åå’Œæ•°æ®
        signature, data = data[:32], data[32:]

        # éªŒè¯ç­¾å
        expected_signature = hmac.new(
            SecureBloomFilterLoader.SECRET_KEY.encode(),
            data,
            hashlib.sha256
        ).digest()

        if not hmac.compare_digest(signature, expected_signature):
            raise ValueError("Invalid signature: file may be tampered")

        # ç­¾åéªŒè¯é€šè¿‡ï¼Œååºåˆ—åŒ–
        return pickle.loads(data)

def _load_from_disk_secure(self) -> Optional[ScalableBloomFilter]:
    """å®‰å…¨åŠ è½½å¸ƒéš†è¿‡æ»¤å™¨"""
    if not os.path.exists(self.persistence_path):
        return None

    try:
        # âœ… ä½¿ç”¨å®‰å…¨åŠ è½½å™¨
        bloom_filter = SecureBloomFilterLoader.load_with_signature(
            self.persistence_path
        )

        # éªŒè¯ç±»å‹
        if not isinstance(bloom_filter, ScalableBloomFilter):
            logger.warning("Invalid bloom filter type")
            return None

        logger.info(f"Successfully loaded bloom filter from {self.persistence_path}")
        return bloom_filter

    except ValueError as e:
        logger.error(f"Signature validation failed: {e}")
        return None
    except Exception as e:
        logger.error(f"Failed to load bloom filter: {e}")
        return None
```

**æ–¹æ¡ˆ3: ä½¿ç”¨æ•°æ®éš”ç¦»å’Œæ²™ç®±**

```python
# ä½¿ç”¨ä¸“ç”¨çš„éš”ç¦»ç›®å½•å­˜å‚¨pickleæ–‡ä»¶
ISOLATED_DATA_DIR = "/var/lib/event2table/isolated_data"

# åœ¨å®¹å™¨æˆ–chrootç¯å¢ƒä¸­è¿è¡Œåº”ç”¨
# é™åˆ¶æ–‡ä»¶ç³»ç»Ÿè®¿é—®æƒé™
```

---

### P1-3: å¹¶å‘ç«æ€æ¡ä»¶ - TOCTOUæ¼æ´

**ä¸¥é‡ç¨‹åº¦**: P1 (é«˜å±)
**å½±å“æ¨¡å—**: `cache_hierarchical.py`, `decorators.py`
**CVSSè¯„åˆ†**: 7.0 (High)

#### é—®é¢˜æè¿°

ç¼“å­˜æ£€æŸ¥å’Œè®¾ç½®ä¹‹é—´å­˜åœ¨**æ—¶é—´çª—å£**ï¼Œå¯èƒ½å¯¼è‡´ç«æ€æ¡ä»¶ã€‚

#### æ¼æ´ä»£ç 

**ä½ç½®**: `decorators.py` Line 47-65

```python
def wrapper(*args, **kwargs):
    # âš ï¸ å±é™©: æ£€æŸ¥å’Œè®¾ç½®ä¸æ˜¯åŸå­æ“ä½œ
    cache_key = _build_cache_key(key_template, key_params, args, kwargs, func)

    # æ—¶é—´çª—å£: å…¶ä»–çº¿ç¨‹å¯èƒ½åœ¨è¿™é‡Œä¿®æ”¹ç¼“å­˜
    cached_value = _cache.get(cache_key)
    if cached_value is not None:
        return cached_value

    # æ—¶é—´çª—å£: å¤šä¸ªçº¿ç¨‹å¯èƒ½åŒæ—¶æ‰§è¡Œåˆ°è¿™é‡Œ
    result = func(*args, **kwargs)

    # æ—¶é—´çª—å£: å¤šä¸ªçº¿ç¨‹å¯èƒ½åŒæ—¶å†™å…¥ç¼“å­˜
    if result is not None:
        _cache.set(cache_key, result, ttl_l1=ttl_l1, ttl_l2=ttl_l2)

    return result
```

#### æ”»å‡»åœºæ™¯

```python
# åœºæ™¯: å¤šçº¿ç¨‹å¹¶å‘è®¿é—®
# çº¿ç¨‹1å’Œçº¿ç¨‹2åŒæ—¶è°ƒç”¨get_game(10000147)

# æ—¶é—´çº¿:
# T1: çº¿ç¨‹1æ£€æŸ¥ç¼“å­˜ â†’ æœªå‘½ä¸­
# T2: çº¿ç¨‹2æ£€æŸ¥ç¼“å­˜ â†’ æœªå‘½ä¸­
# T3: çº¿ç¨‹1æŸ¥è¯¢æ•°æ®åº“
# T4: çº¿ç¨‹2æŸ¥è¯¢æ•°æ®åº“  (é‡å¤æŸ¥è¯¢! æµªè´¹èµ„æº)
# T5: çº¿ç¨‹1å†™å…¥ç¼“å­˜
# T6: çº¿ç¨‹2å†™å…¥ç¼“å­˜  (è¦†ç›–! å¯èƒ½ä¸¢å¤±æ•°æ®)
```

#### ä¿®å¤å»ºè®®

**ä½¿ç”¨é”ç¡®ä¿åŸå­æ€§**:

```python
from threading import Lock
from functools import wraps

# æ¯ä¸ªç¼“å­˜é”®ä¸€ä¸ªé”
_cache_locks = {}
_lock_for_locks = Lock()

def _get_lock_for_key(key: str) -> Lock:
    """è·å–ç¼“å­˜é”®å¯¹åº”çš„é”"""
    with _lock_for_locks:
        if key not in _cache_locks:
            _cache_locks[key] = Lock()
        return _cache_locks[key]

def cached_service_safe(
    key_template: str,
    ttl_l1: int = 60,
    ttl_l2: int = 300,
    key_params: Optional[list] = None
):
    """çº¿ç¨‹å®‰å…¨çš„Serviceå±‚ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # æ„å»ºç¼“å­˜é”®
            cache_key = _build_cache_key(key_template, key_params, args, kwargs, func)

            # âœ… ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼ˆæ— é”ï¼‰
            cached_value = _cache.get(cache_key)
            if cached_value is not None:
                return cached_value

            # âœ… è·å–é”
            lock = _get_lock_for_key(cache_key)
            with lock:
                # âœ… ç¬¬äºŒæ¬¡æ£€æŸ¥ï¼ˆæœ‰é”ï¼‰- Double-Checked Locking
                cached_value = _cache.get(cache_key)
                if cached_value is not None:
                    return cached_value

                # âœ… æ‰§è¡Œå‡½æ•°å¹¶å†™å…¥ç¼“å­˜ï¼ˆåœ¨é”ä¿æŠ¤ä¸‹ï¼‰
                result = func(*args, **kwargs)
                if result is not None:
                    _cache.set(cache_key, result, ttl_l1=ttl_l1, ttl_l2=ttl_l2)

                return result

        return wrapper
    return decorator
```

---

### P1-4: Redisè¿æ¥ä¿¡æ¯æ³„éœ²

**ä¸¥é‡ç¨‹åº¦**: P1 (é«˜å±)
**å½±å“æ¨¡å—**: `cache_system.py`
**CVSSè¯„åˆ†**: 6.8 (Medium)

#### é—®é¢˜æè¿°

Redisè¿æ¥é”™è¯¯å¯èƒ½**æ³„éœ²è¿æ¥å­—ç¬¦ä¸²ã€å¯†ç ç­‰æ•æ„Ÿä¿¡æ¯**ã€‚

#### æ¼æ´ä»£ç 

**ä½ç½®**: `cache_system.py` (å‡è®¾å­˜åœ¨Redisè¿æ¥é”™è¯¯å¤„ç†)

```python
# âš ï¸ å±é™©: å¼‚å¸¸å¯èƒ½åŒ…å«Redisè¿æ¥ä¿¡æ¯
try:
    cached = cache.get(key)
except Exception as e:
    logger.error(f"âš ï¸ L2ç¼“å­˜è¯»å–å¤±è´¥: {e}")  # âš ï¸ å¯èƒ½æ³„éœ²è¿æ¥ä¿¡æ¯
```

#### ä¿®å¤å»ºè®®

```python
def safe_redis_error_handler(func: Callable) -> Callable:
    """å®‰å…¨çš„Redisé”™è¯¯å¤„ç†è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except redis.ConnectionError as e:
            # âœ… ä¸è¦è®°å½•å®Œæ•´å¼‚å¸¸ï¼Œåªè®°å½•é”™è¯¯ç±»å‹
            logger.error("Redis connection error")
            raise CacheOperationError("Cache unavailable") from None
        except redis.TimeoutError as e:
            logger.error("Redis timeout")
            raise CacheOperationError("Cache timeout") from None
        except Exception as e:
            # âœ… ç”Ÿäº§ç¯å¢ƒä¸è¦è®°å½•å¼‚å¸¸è¯¦æƒ…
            if os.environ.get('FLASK_ENV') == 'production':
                logger.error("Redis operation failed")
                raise CacheOperationError("Cache operation failed") from None
            else:
                # å¼€å‘ç¯å¢ƒå¯ä»¥è®°å½•è¯¦ç»†ä¿¡æ¯
                logger.exception("Redis operation failed")
                raise

    return wrapper

@safe_redis_error_handler
def get_from_redis(key: str):
    """ä»Redisè·å–æ•°æ®"""
    cache = get_cache()
    return cache.get(key)
```

---

## P2 - ä¸­å±å®‰å…¨é—®é¢˜ (åº”è¯¥ä¿®å¤)

### P2-1: å®¹é‡ç›‘æ§çº¿æ€§å›å½’æ•°å€¼ä¸ç¨³å®š

**ä¸¥é‡ç¨‹åº¦**: P2 (ä¸­å±)
**å½±å“æ¨¡å—**: `capacity_monitor.py`
**CVSSè¯„åˆ†**: 5.3 (Medium)

#### é—®é¢˜æè¿°

çº¿æ€§å›å½’é¢„æµ‹ä½¿ç”¨**ç»å¯¹æ—¶é—´æˆ³**è¿›è¡Œè®¡ç®—ï¼Œå¯èƒ½å¯¼è‡´**æ•°å€¼ä¸ç¨³å®š**ã€‚

#### æ¼æ´ä»£ç 

**ä½ç½®**: `capacity_monitor.py` Line 76-98

```python
def predict_exhaustion(self, history: deque, threshold: float = 0.95) -> Optional[float]:
    # æå–æ—¶é—´å’Œä½¿ç”¨ç‡
    # âš ï¸ é—®é¢˜: ä½¿ç”¨ç»å¯¹æ—¶é—´æˆ³ï¼Œæ•°å€¼å¯èƒ½éå¸¸å¤§ï¼ˆå½“å‰æ—¶é—´æˆ³ ~1700000000ï¼‰
    base_timestamp = history[0][0]
    timestamps = [(t - base_timestamp) / 3600 for t, _ in history]  # âœ… å¥½çš„: å·²ç»è½¬æ¢ä¸ºç›¸å¯¹æ—¶é—´
    usages = [u for _, u in history]

    # çº¿æ€§å›å½’ï¼šy = ax + b
    n = len(timestamps)

    sum_x = sum(timestamps)
    sum_y = sum(usages)
    sum_xy = sum(t * u for t, u in zip(timestamps, usages))
    sum_x2 = sum(t ** 2 for t in timestamps)

    # âš ï¸ é—®é¢˜: å¦‚æœtimestampséƒ½æ˜¯0ï¼Œåˆ†æ¯ä¸º0
    denominator = n * sum_x2 - sum_x ** 2
    if denominator == 0:
        return None

    slope = (n * sum_xy - sum_x * sum_y) / denominator
```

#### æ½œåœ¨é—®é¢˜

1. **é™¤é›¶é”™è¯¯**: `denominator == 0` æ—¶è¿”å›Noneï¼Œä½†è°ƒç”¨æ–¹å¯èƒ½ä¸å¤„ç†
2. **ç²¾åº¦æŸå¤±**: å¦‚æœæ‰€æœ‰æ—¶é—´æˆ³ç›¸åŒï¼ˆå†å²æ•°æ®ä¸è¶³1å°æ—¶ï¼‰ï¼Œé¢„æµ‹å¤±è´¥
3. **æµ®ç‚¹æ•°æº¢å‡º**: è™½ç„¶`timestamps`å·²ç»æ˜¯ç›¸å¯¹æ—¶é—´ï¼Œä½†å¦‚æœæ—¶é—´è·¨åº¦å¾ˆé•¿ï¼ˆå‡ ä¸ªæœˆï¼‰ï¼Œæ•°å€¼ä»å¯èƒ½å¾ˆå¤§

#### ä¿®å¤å»ºè®®

```python
def predict_exhaustion_safe(self, history: deque, threshold: float = 0.95) -> Optional[float]:
    """å®‰å…¨çš„å®¹é‡é¢„æµ‹ï¼ˆæ”¹è¿›æ•°å€¼ç¨³å®šæ€§ï¼‰"""

    if len(history) < 10:
        logger.debug("æ•°æ®ä¸è¶³ï¼Œæ— æ³•é¢„æµ‹")
        return None

    try:
        # ä½¿ç”¨ç›¸å¯¹æ—¶é—´ï¼ˆç§’ï¼‰
        base_timestamp = history[0][0]
        timestamps = [(t - base_timestamp) for t, _ in history]
        usages = [u for _, u in history]

        # æ•°æ®å½’ä¸€åŒ–ï¼ˆæé«˜æ•°å€¼ç¨³å®šæ€§ï¼‰
        max_time = max(timestamps) if timestamps else 1
        if max_time > 0:
            normalized_times = [t / max_time for t in timestamps]
        else:
            # æ‰€æœ‰æ—¶é—´æˆ³ç›¸åŒï¼Œæ— æ³•é¢„æµ‹è¶‹åŠ¿
            return None

        # çº¿æ€§å›å½’ï¼ˆä½¿ç”¨å½’ä¸€åŒ–åçš„æ—¶é—´ï¼‰
        n = len(normalized_times)
        sum_x = sum(normalized_times)
        sum_y = sum(usages)
        sum_xy = sum(t * u for t, u in zip(normalized_times, usages))
        sum_x2 = sum(t ** 2 for t in normalized_times)

        denominator = n * sum_x2 - sum_x ** 2

        # âœ… æ”¹è¿›: ä½¿ç”¨å°çš„æ­£æ•°é˜ˆå€¼è€Œä¸æ˜¯ç²¾ç¡®çš„0
        if abs(denominator) < 1e-10:
            logger.debug("æ—¶é—´è·¨åº¦ä¸è¶³ï¼Œæ— æ³•é¢„æµ‹è¶‹åŠ¿")
            return None

        slope = (n * sum_xy - sum_x * sum_y) / denominator
        intercept = (sum_y - slope * sum_x) / n

        # âœ… æ”¹è¿›: ä½¿ç”¨å°çš„æ­£æ•°é˜ˆå€¼
        if slope <= 1e-10:
            # å®¹é‡ä¸å¢é•¿æˆ–ä¸‹é™
            return None

        # é¢„æµ‹ä½•æ—¶è¾¾åˆ°thresholdï¼ˆä½¿ç”¨å½’ä¸€åŒ–çš„æ—¶é—´ï¼‰
        normalized_exhaustion_time = (threshold - intercept) / slope

        if normalized_exhaustion_time > 0:
            # è½¬æ¢å›ç»å¯¹æ—¶é—´
            exhaustion_time = base_timestamp + normalized_exhaustion_time * max_time
            return exhaustion_time

    except Exception as e:
        logger.warning(f"å®¹é‡é¢„æµ‹å¤±è´¥: {e}")

    return None
```

---

### P2-2: ç›‘æ§ç³»ç»Ÿå‘Šè­¦æ³›æ»¥

**ä¸¥é‡ç¨‹åº¦**: P2 (ä¸­å±)
**å½±å“æ¨¡å—**: `monitoring.py`
**CVSSè¯„åˆ†**: 5.0 (Medium)

#### é—®é¢˜æè¿°

å‘Šè­¦è§„åˆ™å¯èƒ½è§¦å‘**å‘Šè­¦é£æš´**ï¼Œå¯¼è‡´æ—¥å¿—æ³›æ»¥å’Œç³»ç»Ÿèµ„æºè€—å°½ã€‚

#### æ¼æ´ä»£ç 

**ä½ç½®**: `monitoring.py` (å‡è®¾å­˜åœ¨å‘Šè­¦è§¦å‘é€»è¾‘)

```python
# âš ï¸ é—®é¢˜: æ²¡æœ‰å‘Šè­¦å»é‡æœºåˆ¶
def check_alert_rules(self):
    """æ£€æŸ¥å‘Šè­¦è§„åˆ™"""
    for rule in self.alert_rules:
        if self.metric_value > rule.threshold:
            # âš ï¸ æ¯æ¬¡è°ƒç”¨éƒ½è§¦å‘å‘Šè­¦ï¼Œå¯èƒ½äº§ç”Ÿå¤§é‡é‡å¤å‘Šè­¦
            self.trigger_alert(rule)
```

#### ä¿®å¤å»ºè®®

```python
from collections import defaultdict
import time

class AlertDeduplicator:
    """å‘Šè­¦å»é‡å™¨"""

    def __init__(self, cooldown_seconds: int = 300):
        """
        åˆå§‹åŒ–å»é‡å™¨

        Args:
            cooldown_seconds: åŒä¸€å‘Šè­¦çš„æœ€å°é—´éš”æ—¶é—´ï¼ˆé»˜è®¤5åˆ†é’Ÿï¼‰
        """
        self.cooldown_seconds = cooldown_seconds
        self.last_alert_time = defaultdict(float)  # rule_name -> timestamp

    def should_alert(self, rule_name: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘å‘Šè­¦

        Args:
            rule_name: è§„åˆ™åç§°

        Returns:
            True if should alert, False otherwise
        """
        current_time = time.time()
        last_time = self.last_alert_time[rule_name]

        if current_time - last_time >= self.cooldown_seconds:
            self.last_alert_time[rule_name] = current_time
            return True

        return False

# ä½¿ç”¨ç¤ºä¾‹
class MonitoringSystem:
    def __init__(self):
        self.alert_deduplicator = AlertDeduplicator(cooldown_seconds=300)

    def check_alert_rules(self):
        """æ£€æŸ¥å‘Šè­¦è§„åˆ™"""
        for rule in self.alert_rules:
            if self.metric_value > rule.threshold:
                # âœ… ä½¿ç”¨å»é‡å™¨
                if self.alert_deduplicator.should_alert(rule.name):
                    self.trigger_alert(rule)
```

---

### P2-3: ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯ç«æ€æ¡ä»¶

**ä¸¥é‡ç¨‹åº¦**: P2 (ä¸­å±)
**å½±å“æ¨¡å—**: `cache_hierarchical.py`, `cache_system.py`
**CVSSè¯„åˆ†**: 5.5 (Medium)

#### é—®é¢˜æè¿°

ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯æ›´æ–°**ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„**ï¼Œå¯èƒ½å¯¼è‡´ç»Ÿè®¡ä¸å‡†ç¡®ã€‚

#### æ¼æ´ä»£ç 

**ä½ç½®**: `cache_hierarchical.py` Line 87, 171, 197

```python
# âš ï¸ é—®é¢˜: statså­—å…¸æ›´æ–°ä¸æ˜¯åŸå­æ“ä½œ
self.stats = {"l1_hits": 0, "l2_hits": 0, "misses": 0, "l1_evictions": 0}

def get_without_lock(self, key: str) -> Optional[Any]:
    # âš ï¸ é—®é¢˜: è¯»å–å’Œæ›´æ–°statsæ²¡æœ‰é”ä¿æŠ¤
    if key in self.l1_cache:
        timestamp = self.l1_timestamps.get(key, 0)
        if time.time() - timestamp < self.l1_ttl:
            self.stats["l1_hits"] += 1  # âš ï¸ éåŸå­æ“ä½œ
```

#### ä¿®å¤å»ºè®®

```python
from threading import Lock
from collections import defaultdict

class ThreadSafeStats:
    """çº¿ç¨‹å®‰å…¨çš„ç»Ÿè®¡ä¿¡æ¯"""

    def __init__(self):
        self._stats = defaultdict(int)
        self._lock = Lock()

    def increment(self, key: str, value: int = 1):
        """åŸå­æ€§åœ°å¢åŠ è®¡æ•°"""
        with self._lock:
            self._stats[key] += value

    def get(self, key: str) -> int:
        """è·å–è®¡æ•°"""
        with self._lock:
            return self._stats[key]

    def get_all(self) -> Dict[str, int]:
        """è·å–æ‰€æœ‰ç»Ÿè®¡"""
        with self._lock:
            return dict(self._stats)

# ä½¿ç”¨ç¤ºä¾‹
class HierarchicalCache:
    def __init__(self, ...):
        self.stats = ThreadSafeStats()
```

---

### P2-4: ç¼“å­˜é™çº§ç­–ç•¥çŠ¶æ€ä¸ä¸€è‡´

**ä¸¥é‡ç¨‹åº¦**: P2 (ä¸­å±)
**å½±å“æ¨¡å—**: `degradation.py`, `cache_hierarchical.py`
**CVSSè¯„åˆ†**: 5.8 (Medium)

#### é—®é¢˜æè¿°

é™çº§çŠ¶æ€çš„**è¿›å…¥å’Œé€€å‡ºæ¡ä»¶**å¯èƒ½å¯¼è‡´çŠ¶æ€æŠ–åŠ¨ã€‚

#### æ¼æ´ä»£ç 

**ä½ç½®**: `degradation.py` (å‡è®¾å­˜åœ¨é™çº§é€»è¾‘)

```python
# âš ï¸ é—®é¢˜: é™çº§é˜ˆå€¼å¯èƒ½é¢‘ç¹è§¦å‘è¿›å…¥/é€€å‡ºé™çº§æ¨¡å¼
DEGRADED_THRESHOLD = 0.5  # å¤±è´¥ç‡50%è¿›å…¥é™çº§
RECOVERY_THRESHOLD = 0.5  # å¤±è´¥ç‡50%é€€å‡ºé™çº§

# âš ï¸ é—®é¢˜: é˜ˆå€¼ç›¸åŒï¼Œå¯èƒ½å¯¼è‡´çŠ¶æ€é¢‘ç¹åˆ‡æ¢
if error_rate >= DEGRADED_THRESHOLD:
    enter_degraded_mode()
elif error_rate < RECOVERY_THRESHOLD:
    exit_degraded_mode()
```

#### ä¿®å¤å»ºè®®

```python
class DegradationManager:
    """é™çº§ç®¡ç†å™¨ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""

    def __init__(
        self,
        degraded_threshold: float = 0.5,  # å¤±è´¥ç‡>=50%è¿›å…¥é™çº§
        recovery_threshold: float = 0.3,  # å¤±è´¥ç‡<30%é€€å‡ºé™çº§
        min_degraded_duration: int = 60   # æœ€å°é™çº§æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    ):
        """
        åˆå§‹åŒ–é™çº§ç®¡ç†å™¨

        Args:
            degraded_threshold: è¿›å…¥é™çº§çš„é˜ˆå€¼
            recovery_threshold: é€€å‡ºé™çº§çš„é˜ˆå€¼ï¼ˆåº”è¯¥ä½äºdegraded_thresholdï¼‰
            min_degraded_duration: æœ€å°é™çº§æŒç»­æ—¶é—´ï¼ˆé˜²æ­¢çŠ¶æ€æŠ–åŠ¨ï¼‰
        """
        if recovery_threshold >= degraded_threshold:
            raise ValueError(
                f"recovery_threshold ({recovery_threshold}) must be "
                f"less than degraded_threshold ({degraded_threshold})"
            )

        self.degraded_threshold = degraded_threshold
        self.recovery_threshold = recovery_threshold
        self.min_degraded_duration = min_degraded_duration

        self._is_degraded = False
        self._degraded_since = None

    def update_state(self, error_rate: float) -> bool:
        """
        æ›´æ–°é™çº§çŠ¶æ€

        Args:
            error_rate: å½“å‰é”™è¯¯ç‡

        Returns:
            True if state changed, False otherwise
        """
        current_time = time.time()
        state_changed = False

        if not self._is_degraded:
            # æ­£å¸¸æ¨¡å¼ â†’ æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›å…¥é™çº§
            if error_rate >= self.degraded_threshold:
                self._is_degraded = True
                self._degraded_since = current_time
                state_changed = True
                logger.warning(
                    f"è¿›å…¥é™çº§æ¨¡å¼: error_rate={error_rate:.2%} "
                    f">= {self.degraded_threshold:.2%}"
                )
        else:
            # é™çº§æ¨¡å¼ â†’ æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¢å¤
            # âœ… ç¡®ä¿åœ¨é™çº§çŠ¶æ€è‡³å°‘æŒç»­min_degraded_durationç§’
            if (current_time - self._degraded_since) >= self.min_degraded_duration:
                if error_rate < self.recovery_threshold:
                    self._is_degraded = False
                    self._degraded_since = None
                    state_changed = True
                    logger.info(
                        f"é€€å‡ºé™çº§æ¨¡å¼: error_rate={error_rate:.2%} "
                        f"< {self.recovery_threshold:.2%}"
                    )

        return state_changed
```

---

## P3 - ä½å±å®‰å…¨é—®é¢˜ (å»ºè®®ä¿®å¤)

### P3-1: ç¼ºå°‘èµ„æºé™åˆ¶ - å†…å­˜æ³„æ¼é£é™©

**ä¸¥é‡ç¨‹åº¦**: P3 (ä½å±)
**å½±å“æ¨¡å—**: `decorators.py`, `cache_hierarchical.py`
**CVSSè¯„åˆ†**: 4.0 (Low)

#### é—®é¢˜æè¿°

`_cache_locks`å­—å…¸**æ— é™åˆ¶å¢é•¿**ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼ã€‚

#### æ¼æ´ä»£ç 

```python
# âš ï¸ é—®é¢˜: å­—å…¸æ— é™å¢é•¿
_cache_locks = {}  # key â†’ Lock
```

#### ä¿®å¤å»ºè®®

```python
from collections import OrderedDict

class SizedLockDict:
    """å¸¦å¤§å°é™åˆ¶çš„é”å­—å…¸"""

    def __init__(self, max_size: int = 10000):
        self.max_size = max_size
        self._locks = OrderedDict()
        self._lock = Lock()

    def get_lock(self, key: str) -> Lock:
        """è·å–é”ï¼ˆLRUæ·˜æ±°ï¼‰"""
        with self._lock:
            if key in self._locks:
                # ç§»åˆ°æœ«å°¾ï¼ˆæ ‡è®°ä¸ºæœ€è¿‘ä½¿ç”¨ï¼‰
                self._locks.move_to_end(key)
                return self._locks[key]

            # åˆ›å»ºæ–°é”
            lock = Lock()
            self._locks[key] = lock

            # å¦‚æœè¶…è¿‡å¤§å°é™åˆ¶ï¼Œåˆ é™¤æœ€æ—§çš„
            if len(self._locks) > self.max_size:
                self._locks.popitem(last=False)  # åˆ é™¤æœ€æ—§çš„

            return lock

# ä½¿ç”¨
_cache_locks = SizedLockDict(max_size=10000)
```

---

### P3-2: æ—¥å¿—æ ¼å¼ä¸ä¸€è‡´ - å®‰å…¨å®¡è®¡å›°éš¾

**ä¸¥é‡ç¨‹åº¦**: P3 (ä½å±)
**å½±å“æ¨¡å—**: æ‰€æœ‰æ¨¡å—
**CVSSè¯„åˆ†**: 3.5 (Low)

#### é—®é¢˜æè¿°

æ—¥å¿—æ ¼å¼**ä¸ç»Ÿä¸€**ï¼Œéš¾ä»¥è¿›è¡Œå®‰å…¨å®¡è®¡ã€‚

#### ä¿®å¤å»ºè®®

```python
# backend/core/config/logging_config.py
import logging
import json
from datetime import datetime

class SecurityAuditFormatter(logging.Formatter):
    """å®‰å…¨å®¡è®¡æ—¥å¿—æ ¼å¼å™¨"""

    def format(self, record: logging.LogRecord) -> str:
        # åˆ›å»ºç»“æ„åŒ–æ—¥å¿—
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno,
        }

        # æ·»åŠ å®‰å…¨ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        if hasattr(record, 'user_id'):
            log_data['user_id'] = record.user_id
        if hasattr(record, 'session_id'):
            log_data['session_id'] = record.session_id

        return json.dumps(log_data)

# é…ç½®æ—¥å¿—
handler = logging.StreamHandler()
handler.setFormatter(SecurityAuditFormatter())
logging.getLogger().addHandler(handler)
```

---

## ä¿®å¤ä¼˜å…ˆçº§å’Œè·¯çº¿å›¾

### ç«‹å³ä¿®å¤ (P0) - æœ¬å‘¨å†…å®Œæˆ

1. **P0-1**: ç¼“å­˜é”®æ³¨å…¥æ¼æ´
   - åˆ›å»º`CacheKeyValidator`
   - ä¿®æ”¹æ‰€æœ‰ç¼“å­˜é”®æ„å»ºç‚¹
   - æ·»åŠ å•å…ƒæµ‹è¯•

2. **P0-2**: æ•æ„Ÿä¿¡æ¯æ³„éœ²
   - åˆ›å»º`SensitiveDataFilter`
   - ä¿®æ”¹æ‰€æœ‰æ—¥å¿—è®°å½•ç‚¹
   - é…ç½®ç”Ÿäº§ç¯å¢ƒæ—¥å¿—çº§åˆ«

### å°½å¿«ä¿®å¤ (P1) - 2å‘¨å†…å®Œæˆ

3. **P1-1**: è·¯å¾„éå†æ¼æ´
4. **P1-2**: Pickleååºåˆ—åŒ–æ¼æ´
5. **P1-3**: å¹¶å‘ç«æ€æ¡ä»¶
6. **P1-4**: Redisè¿æ¥ä¿¡æ¯æ³„éœ²

### åº”è¯¥ä¿®å¤ (P2) - 1ä¸ªæœˆå†…å®Œæˆ

7. **P2-1**: çº¿æ€§å›å½’æ•°å€¼ä¸ç¨³å®š
8. **P2-2**: å‘Šè­¦æ³›æ»¥
9. **P2-3**: ç»Ÿè®¡ä¿¡æ¯ç«æ€æ¡ä»¶
10. **P2-4**: é™çº§çŠ¶æ€æŠ–åŠ¨

### å»ºè®®ä¿®å¤ (P3) - æœ‰æ—¶é—´æ—¶ä¿®å¤

11. **P3-1**: å†…å­˜æ³„æ¼é£é™©
12. **P3-2**: æ—¥å¿—æ ¼å¼ä¸ä¸€è‡´

---

## å®‰å…¨æµ‹è¯•å»ºè®®

### å•å…ƒæµ‹è¯•

```python
# tests/test_cache_security.py
import pytest
from backend.core.security.cache_key_validator import CacheKeyValidator

class TestCacheKeyInjection:
    """æµ‹è¯•ç¼“å­˜é”®æ³¨å…¥é˜²æŠ¤"""

    def test_redis_command_injection(self):
        """æµ‹è¯•Rediså‘½ä»¤æ³¨å…¥é˜²æŠ¤"""
        with pytest.raises(ValueError):
            CacheKeyValidator.validate_params({
                'game_gid': "12345:*\r\nDEL user:*"
            })

    def test_path_traversal(self):
        """æµ‹è¯•è·¯å¾„éå†é˜²æŠ¤"""
        with pytest.raises(ValueError):
            CacheKeyValidator.validate_pattern("../../../etc/passwd")

    def test_log_injection(self):
        """æµ‹è¯•æ—¥å¿—æ³¨å…¥é˜²æŠ¤"""
        with pytest.raises(ValueError):
            CacheKeyValidator.validate_params({
                'game_gid': "1\r\n[ERROR] Attack!"
            })

class TestPickleSecurity:
    """æµ‹è¯•Pickleå®‰å…¨"""

    def test_malicious_pickle_rejection(self):
        """æµ‹è¯•æ‹’ç»æ¶æ„pickleæ–‡ä»¶"""
        # åˆ›å»ºæ¶æ„pickle
        import pickle
        class Malicious:
            def __reduce__(self):
                return (print, ("Hacked!",))

        with open('/tmp/malicious.pkl', 'wb') as f:
            pickle.dump(Malicious(), f)

        # åº”è¯¥æ‹’ç»åŠ è½½
        bloom = EnhancedBloomFilter(persistence_path='/tmp/malicious.pkl')
        assert bloom.bloom_filter is None  # åŠ è½½å¤±è´¥
```

### é›†æˆæµ‹è¯•

```python
# tests/test_cache_integration_security.py
import threading
import time

def test_concurrent_cache_access():
    """æµ‹è¯•å¹¶å‘ç¼“å­˜è®¿é—®"""
    cache = HierarchicalCache()

    results = []
    def worker():
        for i in range(100):
            cache.set('test', {'value': i})
            result = cache.get('test')
            results.append(result)

    threads = [threading.Thread(target=worker) for _ in range(10)]
    for t in threads:
        t.start()
    for t in threads:
        t.join()

    # éªŒè¯æ²¡æœ‰ç«æ€æ¡ä»¶
    assert len(results) == 1000  # æ‰€æœ‰æ“ä½œéƒ½å®Œæˆ
    assert all(r is not None for r in results)  # æ²¡æœ‰Noneå€¼
```

### æ¸—é€æµ‹è¯•

```bash
# ä½¿ç”¨sqlmapæµ‹è¯•ç¼“å­˜é”®æ³¨å…¥
sqlmap --url="http://localhost:5001/api/games" \
       --data="game_gid=1" \
       --level=5 \
       --risk=3

# ä½¿ç”¨Burp Suiteæµ‹è¯•ç¼“å­˜æŠ•æ¯’
# å‘é€æ¶æ„ç¼“å­˜é”®ï¼ŒéªŒè¯æ˜¯å¦è¢«è¿‡æ»¤
```

---

## æ€»ç»“

æœ¬æ¬¡å®‰å…¨å®¡è®¡å‘ç°äº†Event2Tableç¼“å­˜ç³»ç»Ÿä¸­çš„12ä¸ªå®‰å…¨é—®é¢˜ï¼Œå…¶ä¸­2ä¸ªå…³é”®é—®é¢˜éœ€è¦ç«‹å³ä¿®å¤ã€‚ä¸»è¦é—®é¢˜é›†ä¸­åœ¨ï¼š

1. **è¾“å…¥éªŒè¯ä¸è¶³**: ç¼“å­˜é”®æ„å»ºç¼ºå°‘ä¸¥æ ¼éªŒè¯
2. **æ•æ„Ÿä¿¡æ¯æ³„éœ²**: æ—¥å¿—è®°å½•å¯èƒ½æš´éœ²æ•æ„Ÿæ•°æ®
3. **ååºåˆ—åŒ–æ¼æ´**: Pickleååºåˆ—åŒ–å­˜åœ¨ä»£ç æ‰§è¡Œé£é™©
4. **å¹¶å‘å®‰å…¨é—®é¢˜**: å­˜åœ¨ç«æ€æ¡ä»¶å’ŒçŠ¶æ€ä¸ä¸€è‡´

**å»ºè®®ç«‹å³é‡‡å–çš„è¡ŒåŠ¨**ï¼š

1. âœ… å®æ–½`CacheKeyValidator`å’Œ`SensitiveDataFilter`
2. âœ… å°†Pickleæ›¿æ¢ä¸ºJSONæˆ–æ·»åŠ HMACéªŒè¯
3. âœ… ä¸ºç¼“å­˜æ“ä½œæ·»åŠ çº¿ç¨‹å®‰å…¨é”
4. âœ… é…ç½®ç”Ÿäº§ç¯å¢ƒæ—¥å¿—çº§åˆ«ä¸ºINFOæˆ–WARNING
5. âœ… å®æ–½å®‰å…¨æµ‹è¯•ç”¨ä¾‹ï¼Œé˜²æ­¢å›å½’

**åç»­æ”¹è¿›**ï¼š

- å®æ–½å®‰å…¨å¼€å‘ç”Ÿå‘½å‘¨æœŸ(SDL)
- å®šæœŸè¿›è¡Œå®‰å…¨å®¡è®¡å’Œæ¸—é€æµ‹è¯•
- å»ºç«‹å®‰å…¨æ¼æ´å“åº”æµç¨‹
- åŠ å¼ºå¼€å‘äººå‘˜å®‰å…¨åŸ¹è®­

---

## é™„å½•

### A. å®‰å…¨æ£€æŸ¥æ¸…å•

- [ ] æ‰€æœ‰ç¼“å­˜é”®æ„å»ºç‚¹éƒ½ç»è¿‡éªŒè¯
- [ ] æ•æ„Ÿæ•°æ®ä¸ä¼šè®°å½•åˆ°æ—¥å¿—
- [ ] ä½¿ç”¨JSONæ›¿ä»£Pickleåºåˆ—åŒ–
- [ ] æ‰€æœ‰å¹¶å‘æ“ä½œéƒ½ä½¿ç”¨é”ä¿æŠ¤
- [ ] ç”Ÿäº§ç¯å¢ƒæ—¥å¿—çº§åˆ«æ­£ç¡®é…ç½®
- [ ] è·¯å¾„æ“ä½œéƒ½ç»è¿‡éªŒè¯
- [ ] æœ‰å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥
- [ ] å®šæœŸè¿›è¡Œå®‰å…¨å®¡è®¡å’Œæ¸—é€æµ‹è¯•

### B. ç›¸å…³æ–‡æ¡£

- [OWASP Top 10](https://owasp.org/www-project-top-ten/)
- [CWE-79: Cross-site Scripting](https://cwe.mitre.org/data/definitions/79.html)
- [CWE-89: SQL Injection](https://cwe.mitre.org/data/definitions/89.html)
- [CWE-502: Deserialization of Untrusted Data](https://cwe.mitre.org/data/definitions/502.html)
- [Python Security Best Practices](https://python.readthedocs.io/en/stable/library/security_warnings.html)

### C. å·¥å…·æ¨è

- **Bandit**: Pythonå®‰å…¨æ¼æ´æ‰«æå™¨
- **Safety**: ä¾èµ–åŒ…å®‰å…¨æ£€æŸ¥
- **PyT**: Pythonå®‰å…¨ç±»å‹æ£€æŸ¥
- **Semgrep**: è¯­ä¹‰ä»£ç åˆ†æ
- **SonarQube**: ä»£ç è´¨é‡å’Œå®‰å…¨åˆ†æ

---

**æŠ¥å‘Šç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026-02-24
**å®¡è®¡å‘˜**: Claude Code Security Audit
**ä¸‹æ¬¡å®¡è®¡**: 2026-03-24
