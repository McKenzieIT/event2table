# ç¼“å­˜ç³»ç»Ÿå¼€å‘è€…æŒ‡å—

> **é¢å‘**: åç«¯å¼€å‘è€…
> **ç›®æ ‡**: æ·±å…¥äº†è§£ç¼“å­˜ç³»ç»Ÿæ¶æ„å’Œé«˜çº§ç”¨æ³•
> **ç‰ˆæœ¬**: 1.0

---

## ğŸ“š ç›®å½•

1. [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
2. [æ ¸å¿ƒæ¨¡å—](#æ ¸å¿ƒæ¨¡å—)
3. [è£…é¥°å™¨è¯¦è§£](#è£…é¥°å™¨è¯¦è§£)
4. [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
5. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
6. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
7. [æµ‹è¯•æŒ‡å—](#æµ‹è¯•æŒ‡å—)

---

## ç³»ç»Ÿæ¶æ„

### ä¸‰çº§åˆ†å±‚ç¼“å­˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   åº”ç”¨å±‚                              â”‚
â”‚  @cached, @cache_invalidate è£…é¥°å™¨                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              HierarchicalCache                       â”‚
â”‚  (L1: æœ¬åœ°å†…å­˜) â†â†’ (L2: Redis) â†â†’ (L3: æ•°æ®åº“)       â”‚
â”‚  å“åº”æ—¶é—´: ~1ms       ~50ms        ~500ms             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               å¢å¼ºæ¨¡å—å±‚                              â”‚
â”‚  â€¢ BloomFilter - é˜²æ­¢ç¼“å­˜ç©¿é€                         â”‚
â”‚  â€¢ CacheWarmer - æ™ºèƒ½é¢„çƒ­                            â”‚
â”‚  â€¢ DegradationStrategy - ç¼“å­˜é™çº§                     â”‚
â”‚  â€¢ CapacityMonitor - å®¹é‡ç›‘æ§                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµå‘

**è¯»å–æµç¨‹**:
```
1. åº”ç”¨è¯·æ±‚ â†’ HierarchicalCache.get(key)
2. L1ç¼“å­˜å‘½ä¸­ â†’ è¿”å›æ•°æ® (~1ms)
3. L1æœªå‘½ä¸­ â†’ L2ç¼“å­˜å‘½ä¸­ â†’ å›å†™L1 â†’ è¿”å›æ•°æ® (~50ms)
4. L2æœªå‘½ä¸­ â†’ L3æ•°æ®åº“æŸ¥è¯¢ â†’ å†™å…¥L2+L1 â†’ è¿”å›æ•°æ® (~500ms)
```

**å†™å…¥æµç¨‹**:
```
1. åº”ç”¨å†™å…¥ â†’ @cache_invalidate è£…é¥°å™¨
2. è‡ªåŠ¨æ¸…ç†ç›¸å…³ç¼“å­˜
3. ä¸‹æ¬¡è¯»å–æ—¶é‡æ–°åŠ è½½æœ€æ–°æ•°æ®
```

---

## æ ¸å¿ƒæ¨¡å—

### 1. è£…é¥°å™¨æ¨¡å— (decorators.py)

**ä½ç½®**: `backend/core/cache/decorators.py`

#### @cached è£…é¥°å™¨

```python
from functools import wraps
from backend.core.cache.cache_hierarchical import HierarchicalCache

cache = HierarchicalCache()

def cached(ttl: int = 3600, key_prefix: str = None):
    """
    ç¼“å­˜è£…é¥°å™¨

    Args:
        ttl: ç¼“å­˜ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰
        key_prefix: ç¼“å­˜é”®å‰ç¼€ï¼ˆå¯é€‰ï¼‰

    Example:
        @cached(ttl=1800)
        def get_events(game_gid: int):
            return fetch_all_as_dict('SELECT * FROM log_events')
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = _generate_cache_key(func, args, kwargs, key_prefix)

            # å°è¯•ä»ç¼“å­˜è·å–
            cached_data = cache.get(cache_key)
            if cached_data is not None:
                return cached_data

            # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)

            # å†™å…¥ç¼“å­˜
            cache.set(cache_key, result, ttl=ttl)

            return result
        return wrapper
    return decorator
```

#### @cache_invalidate è£…é¥°å™¨

```python
def cache_invalidate(func):
    """
    ç¼“å­˜å¤±æ•ˆè£…é¥°å™¨

    åœ¨æ•°æ®ä¿®æ”¹åè‡ªåŠ¨æ¸…ç†ç›¸å…³ç¼“å­˜

    Example:
        @cache_invalidate
        def update_event(event_id: int, data: dict):
            execute_update('UPDATE log_events SET ...')
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        # æ‰§è¡Œå‡½æ•°ï¼ˆä¿®æ”¹æ•°æ®ï¼‰
        result = func(*args, **kwargs)

        # è‡ªåŠ¨æ¸…ç†ç›¸å…³ç¼“å­˜
        _invalidate_related_cache(func, args, kwargs)

        return result
    return wrapper
```

### 2. å±‚çº§ç¼“å­˜ (cache_hierarchical.py)

**ä½ç½®**: `backend/core/cache/cache_hierarchical.py`

```python
class HierarchicalCache:
    """ä¸‰çº§åˆ†å±‚ç¼“å­˜: L1(å†…å­˜) + L2(Redis) + L3(æ•°æ®åº“)"""

    def __init__(self):
        from backend.core.cache.lru_cache import LRUCache
        self.l1_cache = LRUCache(max_size=1000)
        self.l2_cache = redis.Redis(
            host=REDIS_HOST,
            port=REDIS_PORT,
            db=REDIS_DB,
            decode_responses=True
        )

    def get(self, key: str):
        """ä¸‰çº§ç¼“å­˜æŸ¥æ‰¾"""
        # L1: æœ¬åœ°å†…å­˜ç¼“å­˜
        data = self.l1_cache.get(key)
        if data:
            return data

        # L2: Redisç¼“å­˜
        data = self.l2_cache.get(key)
        if data:
            # å›å†™L1
            self.l1_cache.set(key, data, ttl=600)
            return data

        # L3: æœªå‘½ä¸­ï¼Œè¿”å›None
        return None

    def set(self, key: str, value: any, ttl: int = 3600, l1_ttl: int = 600):
        """å†™å…¥L1å’ŒL2ç¼“å­˜"""
        self.l1_cache.set(key, value, ttl=l1_ttl)
        self.l2_cache.setex(key, ttl, pickle.dumps(value))

    def delete(self, key: str):
        """åˆ é™¤L1å’ŒL2ç¼“å­˜"""
        self.l1_cache.delete(key)
        self.l2_cache.delete(key)
```

---

## è£…é¥°å™¨è¯¦è§£

### ç¼“å­˜é”®ç”Ÿæˆç­–ç•¥

**è§„åˆ™**:
```
æ ¼å¼: {prefix}:{module}:{function}:{args_hash}

ç¤ºä¾‹:
- "cache:events:get_events:game_gid=10000147"
- "cache:games:get_game:game_id=123"
```

**è‡ªå®šä¹‰é”®å‰ç¼€**:
```python
@cached(ttl=3600, key_prefix="custom:games")
def get_active_games():
    pass
```

### TTLé€‰æ‹©æŒ‡å—

| åœºæ™¯ | æ¨èTTL | ç†ç”± |
|------|---------|------|
| é™æ€é…ç½® | 7200-86400ç§’ | å‡ ä¹ä¸å˜ |
| æ¸¸æˆåˆ—è¡¨ | 3600ç§’ | å°æ—¶çº§å˜åŒ– |
| äº‹ä»¶åˆ—è¡¨ | 1800ç§’ | 30åˆ†é’Ÿçº§å˜åŒ– |
| å®æ—¶ç»Ÿè®¡ | 60ç§’ | æ¥è¿‘å®æ—¶ |
| ç”¨æˆ·ä¼šè¯ | 600ç§’ | å®‰å…¨æ€§è€ƒè™‘ |

**åŠ¨æ€TTL**:
```python
import random

@cached(ttl=3600 + random.randint(0, 300))  # é˜²æ­¢ç¼“å­˜é›ªå´©
def get_events(game_gid):
    pass
```

---

## é«˜çº§åŠŸèƒ½

### 1. Bloom Filter é˜²æ­¢ç¼“å­˜ç©¿é€

**åœºæ™¯**: é˜²æ­¢æŸ¥è¯¢ä¸å­˜åœ¨çš„æ•°æ®å¯¼è‡´æ¯æ¬¡éƒ½æŸ¥è¯¢æ•°æ®åº“

```python
from backend.core.cache.bloom_filter_enhanced import BloomFilterCache

cache = BloomFilterCache()

def get_event_with_bloom_filter(event_id: int):
    """ä½¿ç”¨Bloom Filteré˜²æ­¢ç©¿é€"""
    cache_key = f"events:{event_id}"

    # å…ˆæ£€æŸ¥Bloom Filter
    if not cache.exists_in_bloom(cache_key):
        # Bloom Filterç¡®å®šä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        return None

    # Bloom Filterè¯´å¯èƒ½å­˜åœ¨ï¼ŒæŸ¥è¯¢ç¼“å­˜/æ•°æ®åº“
    event = cache.get(cache_key)
    if event:
        return event

    # æŸ¥è¯¢æ•°æ®åº“
    event = fetch_one_as_dict('SELECT * FROM log_events WHERE id = ?', (event_id,))

    if event:
        # å­˜åœ¨ï¼ŒåŠ å…¥ç¼“å­˜
        cache.add_to_bloom_filter(cache_key)
        cache.set(cache_key, event, ttl=1800)
    else:
        # ä¸å­˜åœ¨ï¼ŒåŠ å…¥Bloom Filteré˜²æ­¢é‡å¤æŸ¥è¯¢
        cache.add_to_bloom_filter(cache_key)

    return event
```

### 2. æ™ºèƒ½é¢„çƒ­ (Cache Warmer)

**åœºæ™¯**: åº”ç”¨å¯åŠ¨æ—¶é¢„åŠ è½½å¸¸ç”¨æ•°æ®

```python
from backend.core.cache.intelligent_warmer import CacheWarmer

warmer = CacheWarmer()

@warmup_on_startup(priority=1)
def warmup_popular_games():
    """é¢„çƒ­çƒ­é—¨æ¸¸æˆ"""
    games = fetch_all_as_dict('SELECT * FROM games WHERE active = 1 ORDER BY popularity DESC LIMIT 100')
    for game in games:
        cache.set(f"games:{game['gid']}", game, ttl=3600)
    return len(games)

@warmup_on_startup(priority=2)
def warmup_common_params():
    """é¢„çƒ­å¸¸ç”¨å‚æ•°"""
    params = fetch_all_as_dict('SELECT * FROM event_params WHERE is_common = 1')
    cache.set("params:common", params, ttl=7200)
    return len(params)
```

### 3. ç¼“å­˜é™çº§ç­–ç•¥

**åœºæ™¯**: Redisä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§åˆ°L1ç¼“å­˜

```python
from backend.core.cache.degradation import DegradationStrategy

cache = DegradationStrategy()

def get_with_fallback(key: str, query_fn, ttl: int = 3600):
    """å¸¦é™çº§çš„ç¼“å­˜æŸ¥è¯¢"""
    # å°è¯•L2ç¼“å­˜ï¼ˆRedisï¼‰
    try:
        data = cache.get_l2(key)
        if data:
            return data
    except RedisConnectionError:
        # Redisä¸å¯ç”¨ï¼Œé™çº§åˆ°L1
        print("Redis unavailable, falling back to L1 cache")

    # å°è¯•L1ç¼“å­˜
    data = cache.get_l1(key)
    if data:
        return data

    # éƒ½æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
    data = query_fn()
    cache.set_l1(key, data, ttl=600)  # ä»…ç¼“å­˜L1
    return data
```

### 4. å®¹é‡ç›‘æ§å’Œä¿æŠ¤

**åœºæ™¯**: é˜²æ­¢ç¼“å­˜å ç”¨è¿‡å¤šå†…å­˜

```python
from backend.core.cache.capacity_monitor import CapacityMonitor

monitor = CapacityMonitor()

def set_with_protection(key: str, value: any, ttl: int = 3600):
    """å¸¦å®¹é‡ä¿æŠ¤çš„ç¼“å­˜å†™å…¥"""
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨
    if monitor.is_memory_critical():
        # å†…å­˜ä¸è¶³ï¼Œæ‹’ç»å†™å…¥
        raise MemoryError("Cache memory critical")

    # æ£€æŸ¥å¯¹è±¡å¤§å°
    if monitor.is_object_too_large(value):
        # å¯¹è±¡è¿‡å¤§ï¼Œæ‹’ç»ç¼“å­˜
        raise ValueError(f"Object too large: {len(pickle.dumps(value))} bytes")

    # æ­£å¸¸å†™å…¥
    cache.set(key, value, ttl)
```

---

## æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

**1. ä½¿ç”¨è£…é¥°å™¨ç»Ÿä¸€ç®¡ç†ç¼“å­˜**
```python
@cached(ttl=3600)
def get_events(game_gid):
    return fetch_all_as_dict('SELECT * FROM log_events WHERE game_gid = ?', (game_gid,))

@cache_invalidate
def update_event(event_id, data):
    execute_update('UPDATE log_events SET ...')
```

**2. åˆç†è®¾ç½®TTL**
```python
# æ ¹æ®æ•°æ®æ›´æ–°é¢‘ç‡è®¾ç½®TTL
@cached(ttl=3600)  # é™æ€æ•°æ®
def get_games():
    pass

@cached(ttl=1800)  # ä¸­ç­‰å˜åŒ–é¢‘ç‡
def get_events(game_gid):
    pass

@cached(ttl=60)    # å®æ—¶æ•°æ®
def get_online_users():
    pass
```

**3. ä½¿ç”¨ç¼“å­˜Tagsè¿›è¡Œæ‰¹é‡æ¸…ç†**
```python
# è®¾ç½®ç¼“å­˜æ—¶æ·»åŠ tag
cache.set("events:10000147", data, ttl=3600, tags=["games:10000147"])
cache.set("params:10000147", data, ttl=3600, tags=["games:10000147"])

# æ¸…ç†æ‰€æœ‰ç›¸å…³ç¼“å­˜
cache.delete_many(tags=["games:10000147"])
```

### âŒ é¿å…çš„åæ¨¡å¼

**1. ç¼“å­˜å¤§å¯¹è±¡**
```python
# âŒ é”™è¯¯: ç¼“å­˜æ•´ä¸ªå¤§è¡¨
@cached(ttl=3600)
def get_all_logs():
    return fetch_all_as_dict('SELECT * FROM logs')  # å¯èƒ½æœ‰ç™¾ä¸‡è¡Œ

# âœ… æ­£ç¡®: åˆ†é¡µç¼“å­˜
@cached(ttl=600, key_prefix="logs:page")
def get_logs_page(page: int, size: int = 100):
    return fetch_all_as_dict('SELECT * FROM logs LIMIT ? OFFSET ?', (size, page * size))
```

**2. ç¼“å­˜é¢‘ç¹å˜åŒ–çš„æ•°æ®**
```python
# âŒ é”™è¯¯: ç¼“å­˜å®æ—¶ç»Ÿè®¡æ•°æ®
@cached(ttl=3600)  # TTLå¤ªé•¿
def get_realtime_stats():
    return fetch_one_as_dict('SELECT COUNT(*) FROM online_users')

# âœ… æ­£ç¡®: ç¼©çŸ­TTL
@cached(ttl=60)  # 1åˆ†é’Ÿ
def get_realtime_stats():
    return fetch_one_as_dict('SELECT COUNT(*) FROM online_users')
```

**3. å¿˜è®°æ¸…ç†ç¼“å­˜**
```python
# âŒ é”™è¯¯: æ›´æ–°æ•°æ®åä¸æ¸…ç†ç¼“å­˜
def update_event(event_id, data):
    execute_update('UPDATE log_events SET ...')
    # ç¼“å­˜æœªæ¸…ç†ï¼Œå¯¼è‡´æ•°æ®ä¸ä¸€è‡´

# âœ… æ­£ç¡®: ä½¿ç”¨@cache_invalidate
@cache_invalidate
def update_event(event_id, data):
    execute_update('UPDATE log_events SET ...')
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–

```python
def get_games_batch(game_gids: list[int]) -> dict[int, dict]:
    """æ‰¹é‡è·å–æ¸¸æˆï¼Œä¼˜å…ˆä½¿ç”¨ç¼“å­˜"""
    result = {}
    missed_gids = []

    # å…ˆä»ç¼“å­˜è·å–
    for gid in game_gids:
        cached = cache.get(f"games:{gid}")
        if cached:
            result[gid] = cached
        else:
            missed_gids.append(gid)

    # æ‰¹é‡æŸ¥è¯¢æœªå‘½ä¸­çš„æ¸¸æˆ
    if missed_gids:
        placeholders = ','.join(['?' for _ in missed_gids])
        games = fetch_all_as_dict(
            f'SELECT * FROM games WHERE gid IN ({placeholders})',
            missed_gids
        )

        for game in games:
            gid = game['gid']
            result[gid] = game
            cache.set(f"games:{gid}", game, ttl=3600)

    return result
```

### 2. å¹¶å‘è¯»å–ä¼˜åŒ–

```python
from concurrent.futures import ThreadPoolExecutor

def get_events_with_params(game_gid: int):
    """å¹¶å‘è·å–äº‹ä»¶å’Œå‚æ•°"""
    with ThreadPoolExecutor(max_workers=2) as executor:
        # å¹¶å‘æŸ¥è¯¢
        events_future = executor.submit(get_events, game_gid)
        params_future = executor.submit(get_params, game_gid)

        events = events_future.result()
        params = params_future.result()

    return {"events": events, "params": params}
```

### 3. ç¼“å­˜é¢„çƒ­ç­–ç•¥

```python
def warmup_cache_strategy():
    """æ™ºèƒ½é¢„çƒ­ç­–ç•¥"""
    # 1. é¢„çƒ­çƒ­é—¨æ•°æ®
    popular_games = get_popular_games(limit=100)
    for game in popular_games:
        cache.set(f"games:{game['gid']}", game, ttl=3600)

    # 2. é¢„çƒ­æœ€è¿‘è®¿é—®çš„æ•°æ®
    recent_access = get_recent_access_keys(limit=1000)
    for key in recent_access:
        data = query_from_db(key)
        cache.set(key, data, ttl=1800)

    # 3. åå°å®šæ—¶é¢„çƒ­
    schedule.every(1).hours.do(warmup_cache_strategy)
```

---

## æµ‹è¯•æŒ‡å—

### å•å…ƒæµ‹è¯•

```python
import pytest
from backend.core.cache.decorators import cached

@pytest.fixture(autouse=True)
def clear_cache():
    """æ¯ä¸ªæµ‹è¯•å‰æ¸…ç†ç¼“å­˜"""
    cache.flush_all()
    yield
    cache.flush_all()

def test_cached_decorator():
    """æµ‹è¯•ç¼“å­˜è£…é¥°å™¨"""
    call_count = 0

    @cached(ttl=3600)
    def get_data():
        nonlocal call_count
        call_count += 1
        return {"data": "value"}

    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œæ‰§è¡Œå‡½æ•°
    result1 = get_data()
    assert call_count == 1

    # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼Œä»ç¼“å­˜è¯»å–
    result2 = get_data()
    assert call_count == 1  # æ²¡æœ‰å¢åŠ 
    assert result1 == result2
```

### é›†æˆæµ‹è¯•

```python
def test_cache_invalidation():
    """æµ‹è¯•ç¼“å­˜å¤±æ•ˆ"""
    @cached(ttl=3600)
    def get_events(game_gid):
        return fetch_all_as_dict('SELECT * FROM log_events WHERE game_gid = ?', (game_gid,))

    @cache_invalidate
    def create_event(game_gid, name):
        execute_insert('INSERT INTO log_events (game_gid, name) VALUES (?, ?)', (game_gid, name))

    # ç¬¬ä¸€æ¬¡æŸ¥è¯¢
    events1 = get_events(10000147)
    assert len(events1) == 10

    # åˆ›å»ºæ–°äº‹ä»¶
    create_event(10000147, "new_event")

    # å†æ¬¡æŸ¥è¯¢ï¼Œåº”è¯¥è¿”å›æ–°æ•°æ®
    events2 = get_events(10000147)
    assert len(events2) == 11
```

### æ€§èƒ½æµ‹è¯•

```python
import time

def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½æå‡"""
    @cached(ttl=3600)
    def get_data():
        # æ¨¡æ‹Ÿæ…¢æŸ¥è¯¢
        time.sleep(0.5)
        return {"data": "value"}

    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
    start = time.time()
    get_data()
    duration1 = time.time() - start

    # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    start = time.time()
    get_data()
    duration2 = time.time() - start

    # ç¼“å­˜å‘½ä¸­åº”è¯¥å¿«100å€ä»¥ä¸Š
    assert duration2 < duration1 / 100
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹æŒ‡å—](../quickstart/5-minute-guide.md)
- [æ•…éšœæ’é™¤æ‰‹å†Œ](../operations/troubleshooting.md)
- [éƒ¨ç½²è¿ç»´æ–‡æ¡£](../operations/deployment.md)
- [APIå¿«é€Ÿå‚è€ƒ](./api-reference.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026-02-25
**ç›¸å…³æ–‡æ¡£**: [å¿«é€Ÿå¼€å§‹](../quickstart/5-minute-guide.md) | [æ•…éšœæ’é™¤](../operations/troubleshooting.md)
